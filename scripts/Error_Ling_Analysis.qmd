---
title: "Statistical Inconsistencies in Experimental Linguistics"
shorttitle: "Statistical Inconsistencies"
author:
  - name: Timo Roettger
    corresponding: true
    orcid: 0000-0000-0000-0001
    email: timo.roettger@gmail.com
    affiliations:
      - name: University of Oslo
        department: Department of Linguistics & Scandinavian Studies
        city: Oslo
        country: Norway
        postal-code: 0175
author-note:
  status-changes: 
    affiliation-change: ~
    deceased: ~
  disclosures:
    study-registration: ~
    data-sharing: ~
    related-report: ~
    conflict-of-interest: ~
    financial-support: ~
    gratitude: ~
    authorship-agreements: ~
abstract: "This document is a template."
keywords: [keyword1, keyword2, keyword3]
bibliography: bibliography.bib
format:
  apaquarto-docx: default
  apaquarto-html: default
  apaquarto-pdf:
    documentmode: man
---

```{r libraries}
#| echo: false
#| output: false

# load in relevant libraries, install if not installed
if (!require("pacman")) install.packages("pacman")
pacman::p_load(rstudioapi, 
               tidyverse, 
               ggpubr, 
               broom, 
               statcheck,
               janitor,
               # brms,
               # cmdstanr,
               # tidybayes,
               patchwork
               )

# install.packages("cmdstanr", repos = c('https://stan-dev.r-universe.dev', getOption("repos")))

```

```{r data}

#| echo: false
#| output: false

## load in data from location of script
#current_working_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
#setwd(current_working_dir)

## list all journal units
files <- list.files("../Journals", recursive = TRUE, pattern = "\\.pdf")

## how many?
length(files)
# 5804

## summary table
files_wrangled <- as.data.frame(files) %>%
  mutate(year = substring(files, 5, 8)) %>%
  filter(year != 2024) %>%
  mutate(journal = substring(files, 13, 15)) %>%
  group_by(journal) %>%
  summarise(n.art = length(unique(files)))

## view
files_wrangled

## double check
sum(files_wrangled$n.art) == length(files)

n_articles = length(files)

```

```{r statcheck_extraction}

#| echo: false
#| output: false

## read pdfs in /Journals with statcheck, checks for one tailed tests
## can only be run with access to original articles, bulk sharing is not prohibited by the journals
#stat <- checkPDFdir("Journals", OneTailedTxt = TRUE)

## write statcheck data to csv
#write.csv(stat, "../data/statcheck_data.csv", row.names = FALSE)

xdata <- read.csv("../data/statcheck_data.csv")

```

```{r wrangle}

#| echo: false
#| output: false

# split strings into year and journal, drop NAs
xdata <- xdata %>% 
  mutate(year = strtoi(substring(source, 1, 4)),
         journal = substring(source, 9, 11)) %>%
  drop_na(reported_p) %>%
  drop_na(computed_p) %>%
  filter(year != 2024)

```

```{r general_summary}

#| echo: false
#| output: false


## summary table counts
journal_summary_counts <- xdata %>% 
  group_by(journal) %>% 
  summarise( 
            checked_articles = length(unique(source)),
            checked_results = n(),
            errors = sum(error),
            gross_errors = sum(decision_error)
          ) %>% 
  full_join(files_wrangled) %>% 
  adorn_totals(name = "Total") %>% 
  select(journal, n.art, checked_articles, checked_results, errors, gross_errors)

colnames(journal_summary_counts) <- c("Journal", "eligible articles", "assessible articles",
                                      "assessible results", "inconsistencies", "decision inconsistencies")

#journal_summary_counts

```

```{r}

#| echo: false
#| output: true

knitr::kable(journal_summary_counts) 

```

```{r}

#| echo: false
#| output: false

## summary table proportions
journal_summary_prop <- xdata %>% 
  group_by(journal) %>% 
  summarise( 
            checked_articles = length(unique(source)),
            checked_results = n(),
            errors = sum(error),
            gross_errors = sum(decision_error),
            prop_errors = errors / checked_results,
            prop_gross = gross_errors / checked_results
          ) %>% 
  full_join(files_wrangled) %>% 
  group_by(journal) %>% 
  mutate(prop_articles =  checked_articles / n.art) %>% 
  select(-checked_articles, -checked_results, -errors, -gross_errors, -n.art) %>% 
  adorn_totals(name = "Mean") %>%
    mutate(across(where(is.numeric), 
          ~ replace(., n(), .[n()]/(n()-1)))) 

## now proportion of checkable articles that contain 1 or more errors and 1 or more decision errors
 per_article <- xdata %>% 
  group_by(journal, source) %>% 
  summarise(checked_results = n(),
            errors = sum(error),
            gross_errors = sum(decision_error),
            has_error = ifelse(errors > 0, 1, 0),
            has_gross = ifelse(gross_errors > 0, 1, 0)
          ) %>% 
   ungroup() %>% 
   group_by(journal) %>% 
   summarise(prop_has_error = mean(has_error),
             prop_has_gross = mean(has_gross)
             )
 
```


```{r proportions_per_article}

#| echo: false
#| output: true

# into long format for plot
per_article_long <- per_article %>% 
  pivot_longer(!journal, names_to = "type", values_to = "proportion")

# plot as stacked barplot
ggplot(per_article_long) +
  geom_bar(data = per_article_long,
           aes(x = journal, 
               y = 50,
               fill = type),
           stat = "identity")  +
   geom_bar(data = per_article_long,
           aes(x = journal, 
               y = 50),
           fill = "grey",
           stat = "identity")  + 
   geom_bar(data = per_article_long %>% filter(type == "prop_has_error"),
           aes(x = journal, 
               y = proportion * 100,
               fill = type),
           fill = "#6002ee",
           stat = "identity") +  
  geom_text(data = per_article_long %>% filter(type == "prop_has_error"),
           aes(x = journal, 
               y = 30,
               label = paste0(round(proportion * 100, 0), "%")),
           color = "white") +
   geom_bar(data = per_article_long %>% filter(type == "prop_has_gross"),
           aes(x = journal, 
               y = proportion * 100),
           fill = "#ee6002",
           stat = "identity") +
  geom_text(data = per_article_long %>% filter(type == "prop_has_gross"),
           aes(x = journal, 
               y = 5,
               label = paste0(round(proportion * 100, 0), "%")),
           vjust = 0,
           color = "white") +
  scale_fill_manual(name = "",
                     values = c("prop_has_error" = "#6002ee", "prop_has_gross" = "#ee6002"),
                     labels = c("inconsistencies", "decision inconsistencies")) +
  labs(x = "\njournal",
       y = "proportion of articles \nwith at least one inconsistency\n") + 
  scale_y_continuous(limits = c(0,100)) +
  theme_minimal() 

```


```{r proportions_time}

#| echo: false
#| output: true

# aggregate for proportion over year
year_summary_prop <- xdata %>% 
  group_by(year) %>% 
  summarise( 
            checked_articles = length(unique(source)),
            checked_results = n(),
            errors = sum(error),
            gross_errors = sum(decision_error),
            prop_errors = errors / checked_results,
            prop_gross = gross_errors / checked_results
          ) 

# aggregate for proportion over year per journal
year_journal_prop <- xdata %>% 
  group_by(year, journal) %>% 
  summarise( 
            checked_articles = length(unique(source)),
            checked_results = n(),
            errors = sum(error),
            gross_errors = sum(decision_error),
            prop_errors = errors / checked_results,
            prop_gross = gross_errors / checked_results
          ) 

# plot prop over time
year_plot <- 
  ggplot(year_summary_prop) + 
  geom_point(aes(x = year, 
                 y = prop_errors * 100),
             pch = 21,
             size = 2,
             color = "black",
             fill = "#6002ee") +
  geom_path(aes(x = year, 
                 y = prop_errors* 100),
             color = "#6002ee") +
  geom_point(aes(x = year, 
                 y = prop_gross * 100
                 ),
             pch = 21,
             size = 2,
             color = "black",
             fill = "#ee6002") +
  geom_path(aes(x = year, 
                 y = prop_gross* 100),
             color = "#ee6002") +
  annotate("segment", 
           x = c(2000, 2000), xend = c(2004, 2004),
           y = c(100,90), yend = c(100,90),
           color = c("#6002ee", "#ee6002"),
           cex = 2) +
  annotate("text", 
           x = c(2005, 2005), 
           y = c(100,90), 
           label = c("inconsistency", "decision inconsistency"),
           hjust = 0) +
  labs(x = "\nyear of publication",
       y = "proportion of inconsistencies per article in %\n") +
  scale_y_continuous(limits = c(0, 100)) +
  scale_x_continuous(breaks =  c(2000, 2005, 2010, 2015, 2020, 2023)) +
  theme_minimal() + 
  theme(legend.position = "Top right")

# plot prop over time per journal
year_journal_plot <- 
ggplot(year_journal_prop) + 
  geom_path(aes(x = year, 
                 y = prop_errors* 100),
             color = "#6002ee") +
  geom_path(aes(x = year, 
                 y = prop_gross* 100),
             color = "#ee6002") +
  facet_wrap(~ journal, ncol = 2) +
  labs(x = "\nyear of publication",
       y = "") +
  scale_y_continuous(limits = c(0, 100),
                     breaks = c(0,50,100)) +
  scale_x_continuous(breaks =  c(2000, 2023)) +
  theme_minimal() + 
  theme(legend.position = "Top right",
        panel.spacing.x = unit(1.5, "lines"))

year_p <- year_plot + year_journal_plot
year_p

```

```{r}
1 + 1
```

```{r}
1 + 1
```

## Running Code

When you click the **Render** button a document will be generated that includes both content and the output of embedded code. You can embed code like this:

```{r}
1 + 1
```

You can add options to executable code like this

```{r}
#| echo: false
2 * 2
```

The `echo: false` option disables the printing of code (only output is displayed).
