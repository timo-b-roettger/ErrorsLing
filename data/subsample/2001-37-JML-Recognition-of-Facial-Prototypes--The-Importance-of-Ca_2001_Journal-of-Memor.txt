Journal of Memory and Language 44, 443-474 (2001)
doi:10.1006/jmla.2000.2723, available online at http://www.academicpress.com on

Recognition of Facial Prototypes: The Importance of Categorical Structure
and Degree of Learning
Donald Homa, Carson Smith, Claudette Macak, Jennifer Johovich, and Doris Osorio
Arizona State University
The importance of categorical structure in the recognition and classification of realistic face prototypes, following a variable number of learning trials, was investigated in four experiments. Subjects either classified or observed well-defined (Experiments 1-3) or ill-defined (Experiment 4) faces belonging to three categories for one
or nine trial blocks, followed by a transfer test. Recognition performance following classification (Experiment 1)
and observational (Experiments 2 and 3) training was virtually the same: Oldness judgments were highest for the
category prototypes and old instances and were least for new and random instances, with these tendencies increased following nine learning trials. When features were made ill defined (Experiment 4), oldness judgments
decreased for the category prototype following nine learning trials. Multidimensional scaling (Experiment 5) revealed that the category structure for the well-defined and ill-defined faces was globally similar, and therefore, the
disparate recognition of the category prototype was not due to a radical reorganization of the stimulus space.
These results suggest that false recognition of the category prototype is at least partially based on type of category
structure, and that prior studies using false recognition of the category prototype as evidence of an earlier abstraction process are probably misguided. Rather, false recognition is more likely due to erroneous combinations
of features, with category influences playing less of a role. (c) 2001 Academic Press
Key Words: category; concept; learning; ill-defined; well-defined; prototype; recognition; classification.

A growing body of literature suggests that
people often falsely recognize events, i.e., they
identify an event or object as previously experienced when in fact it never occurred. Roediger and McDermott (1995) summarize numerous findings that demonstrate this effect ranging
from domains as diverse as schema recall or
recognition (e.g., Bower, Black, & Turner, 1979),
eye witness accuracy (Loftus & Hoffman, 1989;
Mitchell & Zaragoza, 1996), and childhood
memories (Garry, Manning, Loftus, & Sherman,
1996) to recall of associatively related words
(Deese, 1959; Underwood, 1965) and prose
(Sulin & Dooling, 1974), and recognition of
Portions of Experiment 2 were presented to the Western
Psychological Association, April, 1993 (Phoenix); portions
of Experiment 3 were presented to the Western Psychological Association, April, 1998 (Albuquerque). We thank Gil
Dowd for reading an earlier version of this manuscript, and
Richard Vanek of the Tempe Police Department for providing us with their Identikit collection.
Address correspondence and reprint requests to Donald
Homa, Department of Psychology, Arizona State University,
Tempe, AZ 85287. E-mail: donhoma@asu.edu.

the category prototype in concept formation
(Hayes-Roth & Hayes-Roth, 1977; Neumann,
1974, 1977; Nosofsky, 1991; Solso & Raynis,
1979).
To illustrate one such effect, Roediger and
McDermott (1995) initially exposed subjects to
15 associatively related words and found that
subjects tended to recall and recognize as old
the "prototype" of that list, i.e., a word that was
not part of the study set but which was strongly
associated to each word in the study set. These
authors suggest that a critical factor for producing false recognition in much of this research is
the activation of implicit associative responses
to studied items that converge upon a central,
but nonpresented, item.
In the domain of category learning and representation, numerous models have been developed which can, under suitable conditions,
predict the false recognition of new but centrally
located events such as the category prototype.
Models based on pattern integration (Knapp &
Anderson, 1984), trace blending (Metcalfe,
1991), or the storage of retrieved, integrated

443

0749-596X/01 $35.00
Copyright (c) 2001 by Academic Press
All rights of reproduction in any form reserved.

444

HOMA ET AL.

traces (Hintzman, 1986) also predict that the
prototype should be falsely recognized as old
following learning. For example, the prototype
enhancement effect in Knapp and Anderson's
(1984) model arises from the integration of individual pattern traces at the centroid of these related traces, which can exceed the activation
level of any individual trace. The related PDP
model of McClelland (1995) also predicts false
recognition when massive patterns of activation
cannot disentangle the actual source from other
sources that could produce this outcome.
We recently reported an interesting exception
to these predictions using ill-defined, form patterns (Homa, Goldhardt, Burruel-Homa, & Carson, 1993). In this study, false recognition of the
category prototype was highest following a single study trial, with tendencies to falsely recognize the prototype as old decreasing, rather than
increasing, following additional study trials. Indeed, the false recognition of the category prototype is often reported in paradigms using a single study trial or minimal learning prior to
transfer (e.g., Franks & Bransford, 1971; Metcalfe & Fisher, 1986; Neumann, 1974, 1977;
Solso & McCarthy, 1981a, 1981b; Solso & Raynis, 1979). Since we have evidence from other
studies that prototype abstraction occurs only
following extended learning, especially with
larger category sizes (e.g., Homa, Dunbar, &
Nohre, 1991), we concluded that false recognition of the category prototype after a single
learning trial (when knowledge of categories is
typically minimal, as determined by near-chance
levels of classification of old and new patterns)
was probably due to factors other than category
knowledge or abstraction. Furthermore, the reduced, rather than elevated, tendencies to falsely
recognize the category prototype after extended
learning in our study suggested that the category
prototype functioned more as a novel ideal point
rather than a familiar one. Regardless, these results are inconsistent with the premise that category coherence alone promotes false recognition of a central event.
How the abstracted prototype in our study escaped false recognition is unclear, although the
prototype, being featurally unique, error-free,
and, according to anecdotal evidence (Galton,

1879), more handsome than its "distortions,"1
might engender extraexperimental influences
that give rise to its unfamiliarity. Rhodes, Proffitt, Grady, and Sumich (1998) recently provided experimental support for this hypothesis,
demonstrating that symmetrical faces were
judged as more attractive than less symmetrical
faces, with judgments of attractiveness decreasing with distortion from the prototype (Rhodes
& Tremewan, 1996). Lakoff (1987), who proposes that prototype effects arise from "cognitive models" might also predict the reduced,
rather than elevated, tendencies to call the prototype old with increased learning, since facets
other than the familiarity of specific instances
could be used to influence judgments of oldness.
In the present study, we attempted to demonstrate in the category domain that false recognition of the category prototype is at least partially
due to the structure of categories, i.e., whether
the categories are well defined or ill defined.
Unlike our earlier study, which used only ill-defined stimuli, the present study explicitly manipulated ill-definedness and well-definedness.
The original definition of these terms is
adopted in the present study (Neisser, 1967)--a
category is ill defined if its members are infinitely variable and its dimensions are obscure,
and it is well-defined if its members are composed of a fixed or finite set of features drawn
from clearly identifiable dimensions. A second
purpose is to show that false recognition of the
category prototype for categories that are well

1
Galton, who photographically superimposed the faces of
various groups noted that the resulting handsomeness of the
composite photograph even held for criminals convicted of
murder or manslaughter: ". . . the features of the composites
are much better looking than those of the components. The
special villainous irregularities in the latter have disappeared, and the common humanity that underlies them has
prevailed. They represent, not the criminal, but the man who
is liable to fall into crime. All composites are better looking
than their components, because the averaged portrait of
many persons is free from the irregularities that variously
blemish the looks of each of them" (p. 135). A similar comment is made by M.L. Austin, in a letter enclosed in this
same article: ". . . the faces blend into one in a most remarkable manner, producing in the case of some ladies' portraits,
in every instance, a decided improvement in beauty."

445

FACE CATEGORIES

defined can be demonstrated when category influences are minimal or absent. As such, false
recognition alone cannot be used to infer a prior
abstraction or categorization process; rather,
factors such as exemplar similarity (Nosofsky,
1988, 1991) or feature recombination (Reinitz,
Lammers, & Cochran, 1993) are probably responsible. In the General Discussion, a simple, descriptive feature model of well-defined categories
is presented that can produce the false recognition
of the category prototype when category influences are present and when they are not. In effect,
false recognition of the category prototype need
not be diagnostic of whether category knowledge
has been acquired. We also readdress the issue of
ill-definedness, since recent usage of this term has
clouded the distinction between ill-defined and
well-defined concepts, yet this distinction may
play a crucial role in category recognition. Finally,
the present study generalizes our earlier findings
to a more realistic class of materials--human
faces--rather than abstract but unfamiliar forms,
and it contrasts performance following a single
versus multiple learning trials, a control often
omitted in this area.
Three major hypotheses can be stated. First,
for well-defined faces, false recognition of the
category prototype was predicted to be high following a single trial and even higher with additional study trials. Second, this effect is modulated primarily by noncategorical influences.
Third, when faces are made ill defined, false
recognition of the category prototype would decrease, rather than increase, following additional learning trials. The latter prediction is especially important, since it would suggest that
most models of classification, which predict
prototype effects based on trace integration or
trace blending, wrongly predict false recognition of the category prototype.
The first three experiments explored recognition of well-defined face categories following
minimal or extended training. Experiment 1 used
a classification task, and Experiments 2 and 3
used an observational paradigm. Manipulating
the amount of training is generally omitted in
this domain even though this variable may clarify whether false recognition is greater when
pattern exposure is minimal or extensive. In Ex-

periment 4, the same faces were made ill defined via continuous distortion of the features,
but otherwise the procedure mirrored that of
Experiment 1. Contrasting category learning
(Experiments 1 and 4) and observational learning (Experiments 2 and 3) permitted an assessment of whether false recognition is determined by category cohesion or simple pattern
exposure. Experiment 5 provided a check of
whether the global category structure for the
well-defined categories (Experiments 1-3) was
generally maintained when the faces were made
ill defined (Experiment 4) by multidimensionally scaling the two types of faces.
EXPERIMENT 1
In our earlier study that used ill-defined forms
(Homa et al., 1993), the objective prototype pattern (the pattern used to generate the instances)
and the empirical prototype (the average of the
instances used in learning, e.g., Breen & Schvaneveldt (1986)) had to be different from any of
the training instances. This is because pattern
distortion occurs along continuous dimensions
of the objective prototype, and the likelihood
that any learning pattern (or pattern part) will
exactly match the prototype (or prototype part)
by chance alone is virtually zero. Specifically,
each vertex of the category prototype is defined
by an X and Y value, and pattern distortions of
each vertex are generated by sampling on a continuous scale, with each X and Y value of the
category prototype located at the center. The
likelihood of any instance exactly matching the
prototype values for even one of its vertices is,
therefore, effectively zero.
In contrast, when category instances are generated by sampling from a fixed pool of features, the prototype is composed of features
that exactly match those of its instances. In
fact, whether feature variation is finite or infinite
was one of the criteria originally proposed by
Neisser (1967) for well-defined and ill-defined
categories. This difference may be crucial in
reconciling previous findings. That is, when the
category prototype is composed of features
which exactly match those of its instances, then
false recognition of the category prototype may
be likely.

446

HOMA ET AL.

Experiment 1 was intended to mimic many of
the characteristics of our earlier study, but where
the feature pool was finite. Although Identikit
faces are highly realistic, formed by the overlaying of detailed feature transparencies onto a face
outline, the categories formed in the present
study are still constructed from a finite pool of
features. This constraint guarantees the construction of category instances, including the prototype, which have different combinations of identical features. Subjects viewed Identikit faces,
generated from three different prototype faces,
for either one or nine learning trials, followed
by a transfer test containing old, new, prototype,
and foil stimuli. To make learning nontrivial,
faces were formed from six dimensions (age
lines, chin, lips, nose, eye type, hair style), where
each dimension was represented by six feature
variations that were judged to form a rough continuum (e.g., lips varied from thin to thick). Unknown to the subjects, only the chin, eyes, and
lips were relevant to classification; the remaining
dimensions were irrelevant. Table 1 shows a
schematic representation of the learning and
transfer instances; Fig. 1 shows an example of
one prototype and three of the training stimuli.2
If false recognition of the category prototype
requires repeated sampling from the same feature set, then the results of Experiment 1 should
differ dramatically from those obtained in our
recent study (Homa et al., 1993). Alternatively,
if the uniqueness of the category prototype,
guaranteed when feature variation is essentially
infinite, is not responsible for the reduced recognition rates obtained previously, then the pattern
of responding in Experiment 1 should mirror
previous results; i.e., false recognition of the
category prototype may be high after an initial
study trial, but the rate of false alarming to the
2
The six features were sampled from an available pool
that contained upwards of 300 variations per feature. The
numbering of features shown in Table 1 is for expository
purposes only and does not correspond to the actual identification numbers used in the Identikit. Furthermore, the feature numbers shown in Table 1 (e.g., 1-6 for relevant features) do not correspond in an ordinal manner with any
physical scale. For example, the faces in category A did not
tend to have smaller chins, eyes, and lips than the faces in
category B.

prototype should decrease, not increase, with increased learning trials.
Method
Participants. A total of 40 Arizona State University undergraduates enrolled in an introductory psychology course served as subjects.
Materials and apparatus. Schematic faces,
constructed from Identikit features drawn from
six dimensions, served as stimuli. For each of the
six dimensions (A, Age lines; N, Nose; C, Chin;
E, Eyes; L, Lips; H, Hair style), six feature variations were selected that appeared to roughly
span a continuum. For example, the lips ranged
from thin to full, and noses from small-narrow
to large-thick. Face stimuli were constructed,
photographed onto 35-mm film, and mounted in
slides. During learning and transfer, stimuli were
projected by a Kodak 550 carousel projector
onto a white screen.
Stimulus construction. Each learning instance
was composed of six features, three drawn from
relevant dimensions and three from irrelevant
dimensions. The dimensions of Age lines, type
of Nose, and Hair style were irrelevant; the remaining dimensions of Chin type, Eyes, and
Lips were relevant in that classification could be
reliably based on values from these dimensions.
For example, for category A, the chin was represented only by values 1 or 2 in the learning set,
with value 1 occurring in four of the six learning
stimuli and 2 occurring in the remaining two
stimuli. For category B, the chin value was 3 for
four stimuli and 4 for the remaining two stimuli.
For category C, the chin value 5 occurred four
times and 6 occurred twice. A similar arrangement occurred for the other two relevant dimensions, eyes and lips (see Table 1).
Each of the six values for the three irrelevant
dimensions was represented exactly once in the
six instances for each of the three categories.
Therefore, these feature values were common to
the learning set but nondiscriminative among
the categories.
The transfer stimuli consisted of old instances, the category prototype, new patterns at
three levels of distortion (low, medium, high),
and foils. The category prototype always contained the most frequent feature values on the

447

FACE CATEGORIES
TABLE 1
Schematic Representation of Learning and Transfer Stimuli for Experiment 1
Category A

Old

New-L

New-M

New-H

Proto
Foils

Category B

Category C

A

N

C*

E*

L*

H

A

N

C*

E*

L*

H

A

N

C*

E*

L*

H

1
3
2
6
4
5
3
2
6
4
5
1
7
8
9
1
1
1
1
1
1

6
2
3
1
4
5
6
2
1
4
5
6
7
8
9
3
9
10
11
12
1

1
1
2
1
1
2
7
1
1
1
8
9
1
7
8
1
10
11
12
13
14

1
2
1
1
2
1
1
7
1
8
1
9
7
1
8
1
13
10
11
14
12

2
1
1
2
1
1
1
1
7
8
9
1
7
8
1
1
11
12
13
14
15

2
3
4
6
5
1
4
6
1
2
3
5
7
8
9
3
10
13
14
11
12

1
3
2
6
4
5
1
3
5
4
2
6
1
2
4
4

6
2
3
1
4
5
4
1
5
3
2
6
7
8
9
9

3
3
4
3
3
4
3
3
9
3
7
8
3
7
8
8

3
4
3
3
4
3
3
8
3
7
3
9
9
3
8
8

4
3
3
4
3
3
7
3
3
9
8
3
7
8
3
3

2
3
4
6
5
1
4
5
2
3
1
6
1
4
2
2

1
3
2
6
4
5
3
2
4
1
6
5
7
8
9
9

6
2
3
1
4
5
2
3
6
5
4
1
2
3
6
6

5
5
6
5
5
6
5
5
9
5
7
8
5
9
7
7

5
6
5
5
6
5
5
9
5
7
5
8
9
5
7
7

6
5
5
6
5
5
7
5
5
7
8
5
10
7
5
5

2
3
4
6
5
1
4
5
1
3
2
6
7
8
9
9

Note. A, Age lines; N, Nose; C, Chin; E, Eyes; L, Lips; H, Hair.
C, E, and L were relevant to classification; A, N, and H were irrelevant.

relevant dimensions. For example, for category
A, the category prototype contained the values 1
for chin, 1 for eyes, and 1 for lips; the values on
the irrelevant dimensions were randomly sampled from the learning set values. Note that the
feature combinations for each prototype were
unique, in that the values on these three relevant
dimensions never matched the values for any
learning stimulus. This outcome was guaranteed
by having each training stimulus represented
by the most frequent value for the two relevant
dimensions and the less frequent value on the
third relevant dimension. To the extent that subjects learn feature combinations or correlations
(e.g., Medin, Altom, Edelson, & Freko, 1982),
false recognition of the category prototype
might be expected to decrease with additional
learning trials.
New instances on the transfer test were at one
of three levels of distortion. The new-low patterns of a given category always had the most

frequent value for two of the three dimensions
and a unique value on the third relevant dimensions; the values on the irrelevant dimensions
were always common. The new-medium patterns always had the most frequent value on one
of the three relevant dimensions and unique values on the remaining two relevant dimensions;
the values on the irrelevant dimensions were
again always common. The new-high patterns
also had one relevant dimension represented by
the most frequent feature, with the values for
the remaining two relevant dimensions idiosyncratic. Unlike the new-medium, however, the
new-high had a random sampling of common
and idiosyncratic values for the irrelevant dimensions. In sum, feature-sharing on the relevant dimension was maximal for the category
prototype (three dimensions matched the learning set), moderate for the new-low (two matched
features), and minimal for the new-medium
and new-high (one matched feature). The only

448

HOMA ET AL.

FIG. 1.

An example of a prototype face (upper left) and three learning faces.

difference between new-medium and new-high
was that the former always matched the values
on the irrelevant dimensions (three matches),
whereas the new-high matched between 0, 1, or
2 dimensions. Each new pattern shared relevant
features with only one category, and classification on the transfer test was scored as correct if
the pattern was assigned to that category.
Procedure. Subjects were run in groups of
4-6. Instructions stated that the faces represented members of three different families called
A, B, and C. By carefully observing each face
and by listening to feedback, they should begin
to learn which faces belonged to family A, which
to family B, and which to family C. If there were
no questions, the learning phase commenced.

Each face was presented for 6 s. After 6 s, the
experimenter said "record"; if any subject had
not yet written their response (A, B, or C) onto
the prepared scoresheet, then they had to do so
immediately, guessing if necessary. One second
later, the experimenter verbally gave the correct
category name, paused 1 s, and presented the
next face. Each trial block contained 18 different
faces, 6 in each category, in a random order.
Three different random orders were rotated
across trials in the nine trial block condition.
The transfer test occurred immediately after
learning. A total of 53 different stimuli were presented, composed of the original 18 old (6 per
category), 27 new (9 per category), 3 category
prototypes, and 5 foils. The 27 new faces were

FACE CATEGORIES

equally represented by low, medium, and high
level distortions. Each stimulus was shown for
10 s, a double judgment (old/new with confidence, classification) was required, and no feedback was provided. The recognition judgment
required that the subject first identify the stimulus as old or new, followed by a confidence
judgment (1, guessing; 2, moderately certain; 3,
certain). The classification judgment required
that the subject assign the pattern either to one
of the original learning groups (A, B, or C) or to
a None category. The subjects recorded these
double judgments (e.g., O2, B refers to a moderately certain [2] judgment of Old, with the pattern assigned to category B) on prepared score
sheets. Half the subjects received one random
order of the transfer test, and half received a different random order.
Design. A mixed design was used, with number of learning trials (1, 9) functioning as the only
between-subjects variable, and type of transfer
item (old, new, prototype, foil) and distortion
level of new faces (low, medium, high) functioning as within-subject variables. Twenty subjects
were assigned to the 1 and 9 trial conditions.
Results
Learning. Accuracy of classification during
learning was 0.675 for subjects in the Trial 1
condition. For subjects in the Trial 9 condition,
learning rates were 0.586 and 0.956 on trials 1
and 9, respectively. Although the Trial 1 subjects
were somewhat better than the Trial 9 subjects
after the initial trial, analyses revealed that both
groups were equivalent following the initial
learning trial, t(38) = 1.50, p > .10, and that errors were reduced across learning trials for the
Trial 9 condition, t(19) = 11.01, p < .01.
Transfer: Classification. Proportion correct
classification (left panel) and mean oldness ratings (right panel) on the transfer test are shown
in Fig. 2, as a function of number of learning
trials (1, 9).
Overall, classification accuracy on the transfer test was improved for the subjects receiving
nine learning trials, F(1, 38) = 12.87, MSe =
51.13, p < .001, with performance best for the
old and prototype stimuli and worst for the
new instances, F(2, 76) = 77.76, MSe = 13.61,

449

p < .001. The Trials x Item Type interaction revealed that transfer accuracy improved most for
the old (0.222) and prototype (0.234) stimuli
and somewhat less for the new instances (0.064),
F(2, 76) = 4.76, MSe = 13.61, p < .02.
A second analysis restricted to the new instances showed that classification accuracy was
again better for subjects receiving nine learning
trials, F(1, 38) = 4.52, MSe = 2.26, p < .05. Distortion level was significant, F(2, 76) = 42.43,
MSe = 1.75, p < .01, with level of distortion
functioning in a lawful manner. The interaction
of distortion level with trials was not significant,
F(2, 76) = 1.49, MSe = 3.22, p > .20.
Transfer: Recognition. The recognition data
were converted to an oldness scale, with old-3 =
6, old-2 = 5, old-1 = 4, new-1 = 3, new-2 = 2,
and new-3 = 1. An analysis on the oldness ratings3 revealed that Item Type, F(2, 76) = 443.13,
MSe = 0.21, p < .001, as well as the Item Type x
Trials interaction, F(2, 76) = 84.81, MSe = 0.21,
p < .01, were each significant. Generally, old
and prototype instances increased in oldness
with increased learning trials (by 0.54 and 0.53
units, respectively), whereas new instances decreased in oldness (by 1.78 units); p < .01 in
each case. A separate analysis restricted to the
new instances showed that performance on distortion level was orderly, with the greatest oldness obtained for the low-level distortions and
the lowest oldness ratings obtained for the highlevel distortions, F(2, 76) = 54.62, MSe = 0.21,
p < .001.
The probabilities of an old response for old,
new-low, new-medium, new-high, prototype,
and foil faces were, after one learning trial, .844,
.606, .556, .406, .850, and .120, respectively.
The corresponding values following nine learning trials were .911, .261, .128, .039, .967, and
.010, respectively.
Conditional analyses. Table 2 shows accuracy
of classification on the transfer test, conditionalized upon the subject's recognition response,
shown separately for the learning trials 1 and 9
conditions.
3

Analyses based on recognition accuracy replicated the
findings based on oldness judgments, and, therefore, only
the oldness results are presented here.

450
HOMA ET AL.

FIG. 2. Transfer performance for each Item Type, as a function of learning trials, Experiment 1 (O, Old; P, Prototype; N-L, New-Low; N-M, New-Medium; N-H,
New High; F, Foil).

451

FACE CATEGORIES
TABLE 2
Conditional Probabilities, Experiment 1
Classification
Item type

Recognition

1 trial

9 trials

Old

Called old
Called new
Called old
Called new
Called old
Called new
Called old
Called new
Called old
Called new

0.678
0.643
0.642
0.475
0.430
0.350
0.384
0.271
0.627
1.000

0.939
0.438
0.915
0.609
0.435
0.414
0.571*
0.370
0.914
1.000*

New-L
New-M
New-H
Proto

Note. Asterisks indicate entries with <5 expected frequencies.

For the Trial 1 condition, there was no correspondence between correct recognition and correct classification, with the exception of newlow instances, X2(1) = 4.70, p < .05. In this latter
case, classification was more accurate if the subject incorrectly identified the instance as old.
For the Trial 9 condition, old instances were
classified more accurately if the item was also
correctly recognized as old, X2(1) = 38.80, p <
.01. Curiously, new-low instances were also
classified more accurately if they were (incorrectly) called old, X2(1) = 15.15, p < .01.
Whereas the relationship for old instances might
be expected, the latter relationship for new-low
is not, especially in light of the reduced overall
tendency to identify these instances as old following additional learning trials (0.606 after one
learning trial vs. 0.261 after nine learning trials).
There was no significant relationship between
classification accuracy and correct recognition
for the new-medium and new-high instances.4
Discussion
Generally, increasing the number of learning
trials from one to nine enhanced classification
on the transfer test for all item types, with old
4

Cautious interpretation of the null findings for some
cells is warranted, since the small number of observations in
many cells precludes a powerful test.

instances and the category prototypes classified better than new instances. Furthermore,
distortion level for new instances functioned in
a lawful manner after nine learning trials, with
low-distortions classified more accurately than
medium-level, and medium-level better than
high. These outcomes replicate the findings of
Homa et al. (1993) obtained with more abstract
stimuli.
However, our previous finding of reduced
oldness for the category prototype with increased learning (Homa et al., 1993) was not
found. Instead, the category prototype was rated
older, rather than newer, after nine learning trials. Furthermore, the category prototype was
rated older than any transfer pattern following
nine learning trials. Otherwise, the oldness ratings mirrored those found previously: new instances of smaller distortion were rated older
than those of higher distortion, and following
nine learning trials, all new items were rated less
old than they were following one learning trial.
Conditional analyses showed that old instances
were more likely to be correctly classified on the
transfer test if they were also correctly recognized
as old. Interestingly, those new instances of low
distortion were also classified better if called old
(a false recognition). A similar, but nonsignificant, relationship occurred for new instances of
medium- or high-level distortion.
Before the implications of these results are
considered, we will describe a second experiment based on observational training.
EXPERIMENT 2
The rationale for this experiment was straightforward: if categorization is responsible for the
patterning of results on the recognition test, then
performance on a recognition test following observational training should be quite different. In
particular, observational training provides ample
opportunity to become familiar with the stimuli
while minimizing the opportunity to learn the
categories. This is because subjects simply observe the faces in anticipation of a forthcoming
memory test, with instances from the three categories randomly presented during learning. No
mention of the three categories, or category feedback, is provided during the observational phase.

452

HOMA ET AL.

When feedback is omitted during learning, subjects cannot accurately identify the number of
categories in the set (Bersted, Brown, & Evans,
1969; Hartley & Homa, 1981; Homa & Cultice,
1984).5 Furthermore, subjects have difficulty
learning categories when feedback is omitted
except when categories are composed of minimal distortions (Aiken & Brown, 1971; Homa &
Cultice, 1984). The assertion that observational
training does not promote categories, at least for
these categories, is the focus of Experiment 3. In
the General Discussion, we address the spate of
recent claims of learning in an observation paradigm (e.g., Billman & Knutson, 1996).
Subjects again viewed the same 18 faces per
trial, with the 18 faces randomly presented on
each trial. Each face was shown for the same
time as in Experiment 1. Following one or nine
observational trials, subjects received a recognition test on the faces that were shown in
Experiment 1.
Method
Participants. The subjects were 40 Arizona
State University undergraduates from the same
pool as Experiment 1. None of the subjects in
Experiment 2 had appeared in Experiment 1.
Half the subjects were randomly assigned to
the one trial condition and half to the nine trial
condition.
Materials and apparatus. Same as in Experiment 1.
Procedure. As before, subjects were run in
small groups of 4-6. The major difference occurred in the training phase, where subjects were
instructed to simply observe each face in antici5
An apparent exception is the result of Fried and
Holyoak (1984), who found that no feedback subjects often
performed similar to feedback controls. The discrepancy
may arise from the simpler two-category discrimination
used by Fried and Holyoak and the range of training distortions used. Although they are labeled "low" and "high" distortions, it is unclear whether these labels have any correspondence to the "low" and "high" distortions used by
other researchers (e.g., Posner & Keele, 1968, 1970). It is
possible that even the "high" distortions used by Fried and
Holyoak (in which squares changed from white to black or
the reverse for 15% of the 100 squares) may be in the lowmoderate range relative to other studies, a range that was
learnable in other studies.

pation of a forthcoming memory test. In part,
subjects were told, "When a face is presented,
simply observe it as carefully as possible. . . .
Since a later memory test will follow, attend to
each pattern as carefully as possible." Each face
was shown for 5 s without category feedback.
For subjects in the Observation 1 condition,
each of the 18 faces was shown once in a randomized order. For subjects in the Observation 9
condition, the set of 18 faces was rotated around
three different random orders until the nine trials
were completed.
Immediately following observational learning, subjects were given a recognition test identical in nature and instructions to that given in
Experiment 1. The sole difference was that no
classification response was made following each
recognition judgment. Subjects were given 6 s
rather than 10 s to make each recognition judgment (10 s was used in Experiment 1 to accommodate the double recognition/classification
response).
Results
Figure 3 shows the mean oldness ratings as a
function of Item Type (Old, New-L, New-M,
New-H, Prototype, Foil) and Number of Learning Trials (1, 9) prior to transfer.
In general, the patterning of ratings mirrored
that of Experiment 1: Oldness ratings increased
across learning trials for the Old and Prototype
stimuli and decreased for the New and Foil
items. An analysis on the new instances (N-L,
N-M, N-H) and trials (1, 9) revealed that both
main effects were significant, F(1, 38) = 27.55,
MSe = 0.911, p < .01 and F(2, 76) = 88.11, MSe
= 0.258, p < .01, respectively. The interaction
fell far short of significance, p > .20. In general,
the oldness ratings decreased similarly across
the trials factor--for New-L, New-M, and NewH, this decrease in oldness was 0.83, 1.10, and
0.82, respectively.
A separate analysis with Item Type (Old,
New, Prototype) and Trials as factors revealed
that Item Type was significant, F(2, 76) =
210.08, MSe = 7.609, p < .01, as was the interaction with trials, F(2, 76) = 19.54, MSe =
7.609, p < .01. The oldness ratings for the Old
and Prototype instances increased by 0.67 and

453

FACE CATEGORIES

more extreme for the new instances under the categorization training conditions; changes in oldness were approximately the same for the old and
prototype instances.
Discussion
The patterning of oldness ratings mirrored
that of Experiment 1: (1) oldness ratings were
highest for the old instances and the category
prototype; (2) oldness ratings for the new instances at the various levels of distortion functioned in a lawful manner; and (3) with additional learning, the old and prototype instances
were rated older, and the new instances at all levels of distortion were rated newer. The sole difference between the two experiments was slight
and confined to the new instances after nine
learning trials: oldness was reduced more following categorical training than observational
training.
EXPERIMENT 3
FIG. 3. Mean oldness for each Item Type, as a function
of learning trials, Experiment 2 (O, Old; P, Prototype; N-L,
New Low; N-M, New Medium; N-H, New High; F, Foil).

0.50 respectively; the oldness ratings for the
New instances decreased by 0.92.
The probability of an old response to Old,
New-L, New-M, New-H, Prototype, and Foil
faces after one observation trial was .817, .617,
.322, .244, .800, and .030, respectively; after
nine trials, the corresponding values were .944,
.383, .144, .106, .933, and .010, respectively.
Since the learning and transfer materials were
identical in Experiments 1 and 2, a final analysis
was done comparing oldness ratings for the Old,
New, and Prototype items across trials, with Experiments (Experiment 1--Categorization Training; Experiment 2--Observational Training) as a
third factor. This analysis revealed that Training
condition was not a significant main effect, nor
did it interact with either Trials or Item Type,
both ps > .10. However, the three-way interaction
was significant, F(2, 152) = 3.76, MSe = 0.300,
p < .05. This slight difference is due to the fact
that the changes in oldness across trials were

Although we have asserted that subjects
likely learned no categories following observation training (Experiment 2), it remains possible
that this claim is incorrect, that the comparable
recognition performance following classification (Experiment 1) and observational (Experiment 2) training is due to subjects (implicitly or
explicitly) learning the category structure to a
similar degree under each training method.
To test whether subjects learned categories
following observation training, we again used
the well-defined face stimuli (Experiments 1
and 2), but degree of category knowledge following observation training was directly evaluated. Specifically, subjects received 0, 3, or 6
prior observation trials followed by the standard
category learning procedure. If subjects acquire
categorical knowledge, either partial or complete, from the observation task, then positive
transfer should occur when these same faces are
then grouped, with feedback, into categories on
a learning task. A reasonable prediction supporting this claim would be the finding of positive
transfer on learning following 3 observation trials and even stronger positive transfer following
6 observation trials, relative to the group receiving 0 prior observation trials. In contrast, if our

454

HOMA ET AL.

original assertion regarding observation training
is true--that observation training promotes little
or no knowledge of categories--then observation training should provide no positive benefit
when these same patterns are used in the category learning phase. That is, subjects who receive 0 prior observation trials should learn the
categorical structure as rapidly as subjects who
receive either 3 or 6 prior observation trials.
Two additional tests of this hypothesis were
assessed. First, all subjects received, following
learning (either observation + classification or
0-observation + classification), a transfer test requiring the same recognition-then-classification
judgments of the previous experiments. Again,
if observation training does produce categorical
knowledge, then classification of the transfer
items should favor those subjects who received
the observation training. Alternatively, if observation training fails to provide knowledge of categories, then transfer should be equivalent for
the three groups.
The final test ensures that the observation
training we use is effective in altering memory
performance but not categorization judgments.
Specifically, if observation training has no influence on categorization but is effective in altering
recognition judgments, then we can conclude
that the patterning of results on the transfer test
is not due to the weakness or ineffectiveness of
the manipulation, i.e., that the observation manipulation was sufficiently weak to promote detectable changes on later tests. This possibility is
eliminated if we can show that observational
training significantly affects later recognition of
these faces. We hypothesized that this effect
should be manifested most strongly for the new
faces, since both the old and prototype faces
would likely be called old with high confidence,
regardless of number of prior observation trials.
In particular, the new faces should appear
"newer" to those subjects receiving many, as opposed to zero, observation trials.
Method
Participants. A total of 81 subjects, none of
whom had participated in the earlier experiments, were drawn from the same subject pool
as before. A total of 30 subjects were in the 0-

Observational condition, 24 in the 3-Observational condition, and 27 in the 6-Observational
condition.
Materials and apparatus. Same as in Experiments 1 and 2.
Procedure. Subjects in the 3- and 6-Observational conditions saw the same 18 faces in either
three or six different random orders, respectively,
at a rate of 5 s per face. As in Experiment 2,
subjects were encouraged to simply observe
each face as carefully as possible in anticipation
of a later memory test. Following the observational phase, all subjects were treated identically
in the later category learning and category transfer phases. Subjects were run in groups of 5-10.
After half of the observational subjects were
run, the remaining subjects received the same
faces but with different random orders. At the
conclusion of the observation task, each subject
was asked to estimate the number of different
groups or families they thought were represented in the observational set.
The common learning phase was identical to
that used in Experiment 1--briefly, a face was
shown for 5 s, subjects recorded their category
response (A, B, or C), feedback was provided,
and the next slide was presented. For subjects in
the 0-Observation condition, this was their first
exposure to the faces; for subjects in the 3- and
6-Observation conditions, these 18 faces were
identical to those in the observation phase.
These subjects were explicitly told that all faces
were identical to those seen earlier, and that
their task now was to learn to group the faces
common to a family with the same label (A, B,
or C). All subjects received 18 faces per trial,
and all subjects received six learning trials.
Following learning, all subjects received the
same transfer instructions and transfer test, as
specified in Experiment 1, e.g., a face was
shown for 10 s, a double-response was required
(Old/New with confidence + classification into
A, B, or C), and no feedback was provided. Two
sets of different random orders were used on the
transfer test, with approximately equal numbers
of subjects receiving one of the two orders. As
before, subjects were told that some faces were
old--they had appeared in the learning phase--
and some were new.

FACE CATEGORIES

Results
Learning. The mean error rate for subjects in
the 0-, 3-, and 6-Observation conditions is
shown in the left-hand panel of Fig. 4, as a function of number of learning trials. As is clear
from the figure, no differences in learning among
the three groups occurred, either on the initial
learning trial or averaged across the six learning
trials. The mean error rates for the 0-, 3-, and 6Observation conditions were 0.135, 0.130, and
0.153, respectively, F(2, 78) = 0.41, MSe =
18.80, p > .20; the interaction between Number
of Prior Observation Trials (0, 3, 6) and Number
of Category Learning Trials (1-6) also failed to
reach statistical significance, F(10, 390) = 1.20,
MSe = 3.30, p > .20. As expected, the main
effect of Number of Category Learning Trials
was significant, F(5, 390) = 65.76, MSe = 3.30,
p < .01, with an overall mean error rate of 0.306
on Trial 1 and declining to an error rate of 0.057
by Trial 6.
Following observation training and prior to
category learning, subjects in the Obs 3 and Obs
6 conditions were asked to estimate the number
of different groups or families in the observation
set. The median estimate was 5 for the Obs 3
subjects and 6 for the Obs 6 subjects, which
overestimated the actual number of families by a
factor of about 2.
Transfer: Classification. The right panel of
Fig. 4 shows the proportion of correct classifications for Old, New-Low, New-Med, New-High,
and Prototype faces, separately for the Observation 0, 3, and 6 conditions. The mean accuracy
in classifying faces in the transfer set, following
0, 3, or 6 observation trials, was 0.733, 0.724,
and 0.723, respectively, F(2, 78) = 0.59, MSe =
20.20, p > .20. The interaction between Item
Type and Prior Number of Observational Trials
(0, 3, 6) was also not significant, F(4, 156) =
1.07, MSe = 5.16, p > .20. The main effect of
Items (Old, New, Prototype) was, as expected,
significant, F(2, 156) = 366.71, MSe = 5.16, p <
.01 and reflected the sizable differences in accuracy in classifying these items (Old = 0.933;
New = 0.633; Proto = 0.953).
A separate analysis on the new faces only as a
function of Number of Prior Observational Trials (0, 3, 6) and Distortion Level (Low, Med,

455

High) revealed no difference among the conditions (Obs 0 = 0.631; Obs 3 = 0.639, Obs 6 =
0.628), F < 1, p > .20, but a significant effect of
distortion level, F(2, 156) = 70.45, MSe = 1.23,
p < .01. The interaction between condition and
distortion level was not significant, F < 1, p > .20.
Transfer: Recognition. Separate analyses on
the proportion of recognition errors and on the
mean oldness ratings produced equivalent statistical outcomes; as such, only analyses based on
mean oldness ratings are reported. Figure 5
shows the mean oldness ratings for each item
type (Old, New-Low, New-Medium, New-High,
Prototype) as a function of Number of Prior Observation Trials (Obs 0, 3, 6).
An analysis of the mean oldness ratings for the
New instances only revealed a significant interaction between Distortion Level (Low, Medium,
High) and Number of Prior Observation Trials (0,
3, 6), F(4, 156) = 2.52, MSe = 2376, p < .05. Inspection of this analysis revealed large differences between the Obs 0 versus Obs 3 + Obs 6
conditions, especially for the Low (Obs 0 = 2.91;
Obs 3 = 2.68; Obs 6 = 2.40) and Medium distortions (Obs 0 = 1.95; Obs 3 = 1.62; Obs 6 = 1.62),
and minimal differences for the High distortions
(Obs 0 = 1.59; Obs 3 = 1.34; Obs 6 = 1.57). Orthogonal contrasts confirmed that the oldness
ratings for Obs 0 versus (Obs 3 + Obs 6)/2 were
significantly higher for the Low and Medium
distortions, F(1, 78) = 4.06, MSe = 0.6355 and
F(1, 78) = 5.48, MSe = 0.3751, respectively,
both ps < .05. None of the remaining contrasts
were significant. These outcomes were also mirrored in the false alarm rates: for Obs 0, 3, and 6,
the false alarm rates were 0.196, 0.133, and
0.139, respectively.
As in the previous experiments, the mean oldness ratings for the Old and Prototype faces
were highest, with oldness ratings for the New
items considerably lower (Old = 5.69; New =
1.96; Prototype = 5.27). Differences among the
observation conditions for the Old and Prototype faces were not significant, p > .20 in each
case.
The probabilities of an old response to Old,
New-Low, New-Medium, New-High, and Prototype faces were, for the Obs 0 subjects, .959,
.356, .152, .081, and .933, respectively. For the

456
HOMA ET AL.

FIG. 4. Mean error rate in learning (left panel) and subsequent transfer on the classification test (right panel) for subjects receiving a variable number of prior observation trials (Obs = 0, 3, 6), Experiment 3.

457

FACE CATEGORIES

strengthen the memorial traces for later recognition.6 Under these conditions, the category
prototype was falsely recognized as old about
90% of the time, a rate similar to that obtained
in Experiments 1 and 2.
The results from the first three experiments,
therefore, support the conclusion that false recognition of the category prototype need not be
dependent upon the formation of categories. If
the oldness ratings of the category prototype are
determined by the type of category (ill-defined
versus well-defined), then the face prototype
from an ill-defined category should be rated as
newer, rather than older, with additional learning trials. This was the focus of Experiment 4.
EXPERIMENT 4
The purpose of Experiment 4 was to determine if Identikit faces, made ill defined, would
function like other ill-defined stimuli in classification and recognition. In particular, would the
category prototype be judged as newer, rather
6

FIG. 5. Mean oldness ratings for each Item Type (O,
Old; P, Prototype; N-L, New Low; N-M, New Medium; N-H,
New High) as a function of Number of Prior Observation
Trials, Experiment 3.

Obs 3 subjects, these values were .944, .287,
.083, .028, and .847, respectively. For the Obs
6 subjects, the corresponding values were .963,
.255, .082, .078, and .889, respectively.
Discussion
Prior observational training had no effect on
the subsequent category learning of these stimuli and no effect on the subsequent classification of old and new faces on the later transfer
test. Estimates of the number of families following observational training by subjects were
inflated by a factor of 2, an outcome also inconsistent with any learning of these categories.
However, prior observational training did impact later recognition judgments, mostly by
making foils less amenable to false alarming.
Taken as a whole, these outcomes are consistent
with our view that observation training provides
little benefit to category formation but does

In response to one of the reviewer's comments that subjects may have learned categories but not the experimental
ones (listed in Table 1), we also ran a Mandler (1967) sorting task as a check. A total of 19 subjects sorted the 18 learning faces into 2-7 categories, with the stipulation that they
continue with the task until they have achieved identical
sorts on two, consecutive trials. Each face was affixed to a
card, shuffled, and handed to the subject. After each sort, the
assignment of faces was recorded, and the cards were collected, shuffled, and handed back to the subject. The only instruction was to use "piles" that reflected a naturalness for
them. Overall, subjects needed 4.05 sorts to reach criterion,
using an average of 3.95 piles. To determine whether the criterion sort reflected the experimental categories, a measure
of purity (Homa, Goldhardt, & Burruel, 1987) was calculated. This measure reflects the tendency to sort only members of one category per pile, where a random sort or a sort
based on irrelevant dimensions (e.g., sorting by hairstyle)
results in a purity value of 0.333; a perfect sort, where only
members from the same (experimental) category are placed
within the same pile, produces a purity value of 1.00. The
obtained mean purity value for the subjects was 0.681, with
only four subjects sorting at 0.333. A z-approximation to a
binomial revealed that the sorting consistency was significant, z = 13.67, p < .001. This measure probably underestimates how well subjects mirrored the experimental structure, since the purity measure penalizes the perfect joining
of two categories into one, which a number of subjects did.
Nonetheless, it is clear that most subjects readily selected
the experimental, rather than trivial or alternative, categories
when given an unconstrained instruction to sort the faces.

458

HOMA ET AL.

than older, following nine learning trials, an outcome opposite to that found in Experiments 1-3.
Faces were distorted by a program called
Adobe Photoshop. This program provides a number of ways to distort a stimulus, including spherical distortions of the entire stimulus (which contracts or expands the face along both axes or a
chosen axis) and selective distortions of any
part/feature of a stimulus. For the latter types of
distortion, it is first necessary to select the feature for distortion by outlining it. Following this,
a range of distortion values (along a continuous
scale from +100 to -100) can be entered. The
actual distortion values used in Experiment 4 are
shown in Table 3.
For example, stimulus face Al had the chin
enlarged by +70, the eyes increased by +70, and
the lips reduced by -70. Following this, the entire face was spherically reduced (by -30) along
both vertical and horizontal axes. Distortions
were constructed with four considerations: (a)
For the dominant features (i.e., those that occur
among four instances of each category, indicated by asterisk), the mean distortion was 0. (b)
For the remaining relevant features, the mean
distortion was 0. (c) All faces had at least one
large (0.70) distortion of a dominant feature. (d)
Global spherical distortions of the head had a
mean value of 0. This procedure ensured that
each of the dominant features was unique, because each feature type (i.e., a particular type of
eyes) occurred in learning with four variations
(+0.70, +0.30, -0.30, -0.70), which were then
further distorted by a unique spherical distortion
along both the horizontal and vertical axes.7
The distortions applied to the features/head
shown in Table 3 for category A were then duplicated for categories B and C; the transfer set
was not distorted and was identical to that used
in Experiments 1-3. In particular, the prototype
used in Experiment 4 was identical to that used
in Experiments 1-3. With a few minor exceptions, the design and procedure were otherwise
identical to those of Experiment 1.
7

The numbers 30 and 70 do not refer to the percentage
contraction/expansion of the feature. As best we can tell, a
distortion associated with 30 produced an increase of about
10-15%; a value of 70 increased that feature by about
25-30%.

TABLE 3
Distortion Values for Faces of One Category, Experiment 4
Relevant dimension
Face

Chin

Eyes

Lips

Head

A1
A2
A3
A4
A5
A6

+70*
-30*
+70
-70*
+30*
-70

+70*
-70
-70*
+30*
+70
-30*

-70
+70*
-30*
+70
+30*
-70*

-30
-20
-10
+10
+20
+30

Note. Dominant features indicated by asterisks.

Method
Participants. The subjects were 36 Arizona
State University undergraduates enrolled in an
Introductory Psychology course, half receiving
one learning trial and half receiving nine learning trials. None of the subjects had participated
in Experiments 1-3.
Materials. The original learning set of faces
used in Experiment 1 was distorted in accord
with the values shown in Table 3. The exact procedure entailed that the original slides be first
optically read into a computer and then distorted
according to the procedures available in Adobe
Photoshop 3.0. Following the distortion of each
face, a hard copy of each face was printed. The
learning set consisted of booklets composed of
these distorted faces. For half the subjects, a
total of 18 faces comprised the learning set
(each of the 18 faces shown once); for the remaining subjects, three learning booklets of 54
faces (each of the 18 faces shown three times)
were constructed. This ensured that the type of
randomization in learning matched that used in
Experiments 1-3.
Procedure. The major procedural difference
in Experiment 4 was that subjects worked with
booklets rather than observed slides. Each face
in a booklet first appeared without any label; following the subject's recorded response (A, B, or
C) onto prepared booklets, the subject was instructed to turn to the next page, which contained the face just viewed with its associated
label. As before, the order of faces in any booklet was randomized. Subjects were encouraged

FACE CATEGORIES

to avoid snap, rapid judgments or overly lengthy
inspections; rather, they were urged to adopt a
strategy of observing each face for about 5 s before making a judgment. Subjects ran in groups
of 1-3, with each subject working in a selfpaced manner with his or her own booklet. Virtually all subjects took 2-3 min to complete the
study phase in the one-trial condition and between 20 and 30 min in the nine-trial condition,
times comparable to these in Experiments 1-3.
For the transfer test, each subject again
worked with booklets, feedback was omitted,
and the subject again made a double response
(recognition with confidence, followed by classification). The composition of the transfer set
was otherwise identical to that in previous experiments. Three random orders of the transfer
test were constructed, with six subjects in each
condition (one versus nine learning trials) receiving one of the test versions. Subjects were
again encouraged to avoid overly rapid or slow
judgments--rather, they were urged to carefully
inspect each face for about 5 s before making
their judgments. Most subjects took about 10 min
to complete this phase, a time comparable to the
transfer test in Experiment 1.
Results
Learning. Subjects in the one-trial learning
condition classified faces with an accuracy of
0.506; for subjects in the nine-trial learning condition, the classification rates were 0.503 after
one trial and 0.852 after nine trials. Statistical
tests revealed no difference after one trial for the
one-trial and nine-trial condition subjects, p >
.05, and subjects in the nine-trial condition significantly improved from the first to ninth trial,
p < .01. Therefore, the two groups of subjects
were roughly equal, and subjects significantly
improved their classification following nine
learning trials.
Transfer: Classification. Proportion correct
classification (left panel) and mean oldness ratings (right panel) on the transfer test are shown
in Fig. 6, as a function of Number of Learning
Trials (1, 9). Classification results largely mirrored those of Experiment 1: classification accuracy improved following nine learning trials,
F(1, 34) = 11.09, MSe = 204.56; performance
was best for the old and prototype stimuli and

459

worst for the new instances, F(2, 68) = 25.14,
MSe = 73.19; and Number of Prior Learning
Trials interacted with item types, F(2, 68) =
4.61, MSe = 73.19, all ps < .05. The latter interaction was also similar to that observed in Experiment 1, with performance improving more
for the old (0.275) and prototype (0.185) stimuli
and less for the new instances (0.050).
Furthermore, classification of the new instances was lawfully modulated by distortion
level, consistent with Experiment 1, F(2, 68) =
43.11, MSe = 0.238, p < .01; mean error rates on
the New low-, medium-, and high-level distortions were 0.444, 0.574, and 0.698, respectively.
Transfer: Recognition. As before, the recognition data were converted to an oldness scale.
The right panel of Fig. 6 shows the mean oldness as a function of Number of Learning Trials
(1, 9) for each of the item types (Old, New-L,
New-M, New-H, Prototype, Foil). As before,
the main effect of Item Type and the Item Type
x Number of Trials interaction were both significant, F(2, 68) = 116.45, MSe = 0.54 and
F(2, 68) = 27.72, MSe = 0.54, both ps < .01.
The major difference from Experiment 1 concerned the category prototype, which became
less, rather than more, old after nine learning
trials, t(34) = 1.70, p < .05, one-tailed test. Otherwise, the recognition performance was quite
similar to Experiment 1: following nine learning trials, old items became older and new items
became newer.
The probabilities of an old response to Old,
New-L, New-M, New-H, Prototype, and Foil
faces were, after one learning trial, .747, .506,
.463, .290, .833, and .133, respectively. The
corresponding values following nine learning
trials were .972, .247, .123, .043, .667, and .011,
respectively.
The discrepancy between the recognition results for Experiments 1 and 4 can be highlighted
by noting the mean change in oldness following
one and nine learning trials, shown separately for
each item type, for the two experiments. Figure 7
shows this contrast, with the dependent measure
as Mean Oldness Difference following one and
nine learning trials.
The obvious discrepancy between the two experiments is clearly revealed--the mean oldness
differences for all item types following one and

460
HOMA ET AL.

FIG. 6. Transfer performance for each Item Type, as a function of learning trials, Experiment 4 (O, Old; P, Prototype; N-L, New Low; N-M, New Medium;
N-H, New High; F, Foil).

461

FACE CATEGORIES

FIG. 7. Mean oldness difference between Trial 9 and
Trial 1 performance for each Item Type, as a function of Experiment (OLD, Old; PROTO, Prototype; N-L, New Low;
N-M, New Medium; N-H, New High).

nine learning trials were similarly affected by
the change from Experiment 1 to Experiment 4,
except for the category prototype. A three-way
Anova for the factors of Learning Trials (1, 9),
Item Type (Old, New, Prototype), and Experiments (Exp 1 versus Exp 3) revealed a significant Experiment X Number of Trials X Item
Type interaction, F(2, 144) = 10.03, MSe = 0.37,
p < .01. An alternative way to view this outcome
is to note how learning trials modify the likelihood of a false alarm to the category prototype;
in Experiment 1, the likelihood of a false alarm
to the category prototype increased by 14% following nine trials (Trial 1 = 0.850; Trial 9 =
0.967). In Experiment 4, the likelihood of a false
alarm decreased by 20% following nine learning trials (Trial 1 = 0.833; Trial 9 = 0.667). For
additional contrast, the likelihood of a false
alarm to the category prototype in Experiment 2
increased by 17% following nine learning trials
(Trial 1 = 0.800; Trial 9 = 0.933), an outcome
similar to that in Experiment 1.

One other difference emerged between Experiments 1 and 4. In Experiment 4, the correlation
between the number of errors on the final learning trial for the nine-trial condition was positively correlated with the mean oldness rating of
the category prototype on the recognition transfer test, r(16) = .47, p < .05. This correlation was
not significant for the subjects receiving a single
learning trial (r = -.28) or for either learning
condition in Experiment 1 (for one trial, r = -.07;
for nine trials, r = .00). In effect, the better the
learning, the greater the likelihood the prototype
was assigned a low oldness rating on transfer.
No such relationship existed in Experiment 1.
Conditional analyses. Table 4 shows the accuracy of classification on the transfer test, conditionalized upon the subject's recognition response, shown separately for the one-trial and
nine-trial conditions. For only one contrast was
there a significant relationship between the subject's response of judging an item as old or new
and its subsequent classification into the appropriate category: for the Learn 9-trial condition,
New-Medium transfer items were classified
more accurately if they were (erroneously)
called "old," X2(1) = 7.56, p < .01.
Discussion
When the categories were made ill defined via
the continuous distortion of features, the likelihood of false alarming to the category prototype

TABLE 4
Conditional Probabilities, Experiment 4
Classification
Item type

Recognition

1 trial

9 trials

Old

Called old
Called new
Called old
Called new
Called old
Called new
Called old
Called new
Called old
Callled new

0.525
0.463
0.506
0.532
0.453
0.333
0.319
0.296
0.556
0.667

0.784
0.778
0.700
0.557
0.750
0.423
0.429
0.297
0.778
0.722

New-L
New-M
New-H
Proto

462

HOMA ET AL.

decreased, rather than increased, with additional
learning trials, an outcome similar to that obtained previously with ill-defined forms (Homa
et al., 1993). The difference is not small--false
recognition of the category prototype in Experiment 4 dropped from 83 to 67% after nine trials;
in Experiments 1 and 2 combined, the corresponding rates were about 83% to 95%. This difference is especially striking given that the prototype itself was not changed in these experiments.
Finally, we reiterate that even in Experiment 4,
the high rate of false alarming to the category
prototype occurred after one learning trial, a manipulation that produced correct classification of
the category prototype (and other patterns) that
was only slightly higher than chance.
EXPERIMENT 5
The final experiment contrasted the structure
of the well-defined faces used in Experiments
1-3 with the ill-defined faces used in Experiment 4. An important concern is that the manipulation of making the faces ill defined, i.e., generating feature-distortions along continuous,
rather than discrete, dimensions did not also
alter other factors of little interest that might
explain the recognition findings. For example,
the reduced rates of false recognition of the
prototype might occur if the ill-defined categories lost their structure and/or the category
prototype was displaced from its likely, central
location within the category to a more peripheral location.
To address these concerns, the ill-defined and
well-defined faces were separately scaled using
multidimensional scaling (Kruskal, 1964; Shepard, 1962). This permitted the measurement of a
number of important, derived measures such as
the degree of clustering in multidimensional
space and the distance of the prototype from the
centroid of its members. A sensitive measure of
category structure is its structural ratio (Homa,
Rhodes, & Chambliss, 1979), which is operationally defined by the ratio of within-category
to between-category distances. The structural
ratio varies from 0.00 to 1.00, where 0.00 occurs
for a perfectly structured space, 1.00 occurs for
a random space (since average within-category
distances equal average between-category dis-

tances), and values between 0.00 and 1.00 reflect degrees of category clustering. This measure can be computed for individual stimuli as
well as for the entire space.
We predicted that the modifications of the
various features in the ill-defined categories
would not disrupt the category structure, and
that, for both well-defined and ill-defined faces,
the category prototype would remain central to
its members. In multidimensional space, these
outcomes would be revealed by similar category
clusters, with the category prototype closer to
the centroid of its category than its members.
We anticipated one difference: if changing discrete-valued features to continuous variation
also increases pattern complexity, then the welldefined face categories should be fit somewhat
better in the lower dimensions.
A final check was to compute the overall similarity of the well-defined and ill-defined multidimensional spaces. This was accomplished by
using a program called Congru (Cliff, 1966). This
program rotates one multidimensional space into
optimal congruency with another space, generates the coordinates for each of the stimuli in
each space, and computes a correlation between
the two spaces.
Method
Participants. The subjects were 30 subjects
from the same pool used for the other experiments, equally divided into the well-defined
and ill-defined conditions.
Materials and apparatus. Two face conditions were constructed, a well-defined and an illdefined set. In each condition, a total of 30 faces
were selected, 10 from each of the three face
categories. The 10 faces in each category contained the category prototype, the 6 learning
faces, and one each at the low-, medium-, and
high-distortion (see Table 1). Each face was
scanned into a computer, and all judgments
were made to face-pairs presented horizontally
on a computer screen. The dimensions of each
face were about 3 in horizontal and 5 in vertical,
with about 1 in separating each face. Below each
face was a scale, with 1 = minimal similarity and
9 = maximal similarity. All judgments were
made in sound-attenuated booths.

FACE CATEGORIES

Procedure. Each subject was led to a soundattenuated chamber and told he would be rating
face-pairs for their similarity. Prior to making the
ratings, each subject was provided a packet containing the 30 faces in a random order, and the
subject was then allowed to briefly inspect each
face. Following this, if no questions remained,
the experiment proper commenced. Each of the
435 possible pairs was shown in a random order,
and the procedure was self-paced. Each face-pair
remained on the screen until the similarity judgment was made (by depressing a number on a
standard keyboard). Following the subject's
judgment, the face-pair was removed and replaced 1 s later by the next face-pair. Each face
occurred about equally often on the left and right
sides of the screen. Although the procedure was
self-paced, subjects were encouraged to avoid
snap judgments (less than 1 s) as well as overly
ponderous judgments (greater than 10 s), and to
try to use as much of the scale as possible. Most
subjects completed the task in 20-30 min.
Results
The stress values (Kruskal's (1964) Stress
formula 1) for the well-defined faces were, in dimensions 1-5, 0.337, 0.214, 0.144, 0.105, and
0.079, respectively; for the ill-defined faces, the
corresponding stress values were 0.435, 0.251,
0.174, 0.126, and 0.093. The three-dimensional
solution was selected for all further analysis,
since it provided a reasonable fit in the highest
dimensionality that could be visualized.
A number of measures were selected to assess
the nature of the structure in each MDS space.
The structural ratio (SR) is the ratio of the average within-category distance to average between-category distance, and the Centroid (C)
measures the distance of various faces from the
geometric center of its cluster.
First, as determined by the SRs, the welldefined and ill-defined face conditions were
moderately structured. For the well-defined
faces, each of the 30 faces had an SR < 1, indicating that each face was closer to its intended
category than to faces from other categories. A
similar situation existed for the ill-defined faces,
with 29 of the 30 faces having a SR < 1. Second,
the prototype for each category had an SR that

463

was smaller than the average of the 6 learning
faces or the full complement of patterns of that
category (for well-defined, the SRs = 0.510 for
the prototype, 0.601 for the learning faces, and
0.697 for the average of the remaining 9 faces;
for ill-defined, the SRs = 0.615 for the prototype, 0.757 for the 6 learning faces, and 0.760
for the remaining patterns). Although the welldefined face categories were slightly more structured than the ill-defined faces, each space was
moderately structured with the category prototype having the smallest SR.
A second measure is how close the prototype
of each category is to the centroid of that category. For the well-defined categories, the average distance from the prototype to the centroid
was 0.429; for the remaining patterns, it was
0.697; for the ill-defined faces, these values
were 0.515 versus 0.781.
Finally, Congru revealed that the two spaces
in three dimensions were moderately correlated,
r = .682. Since Congru finds a final solution in
which the axes are maximally aligned, it is possible to correlate the 30 patterns in each space
along each axis. For axes 1-3, r(28) = .76, .74,
and .49, respectively, p < .01 in each case.
Figure 8 provides a visual comparison between
the well-defined and ill-defined faces in three dimensions for one of the three categories, with the
numbers 1-10 representing the well-defined faces
and 11-20 representing the corresponding ill-defined faces. Here, 1 = prototype, 2-7 = learning
patterns, and 8-10 = low, medium, and high distortions; the numbers 11-20 represent the corresponding ill-defined faces. Thus, patterns 1 and
11 represent the prototypes for the well-defined
and ill-defined categories, respectively, patterns
2-7 and 12-17 represent the 6 learning patterns in
the corresponding categories, etc.
Discussion
The results of Experiment 5 suggested that
making the faces ill-defined did not disrupt the
essential structure of these categories. Importantly, the ill-defined and well-defined spaces
were clustered by category, the category prototype maintained its central position within each
cluster, and the two spaces were positively correlated. Two slight differences did emerge--the

464

HOMA ET AL.

FIG. 8. Multidimensional scaling of faces 1-20 in three dimensions, for the well-defined and illdefined categories, following axis alignment, Experiment 5.

ill-defined faces were associated with somewhat
higher stress values, and the well-defined categories were slightly more structured, as measured by the structural ratio. The higher-stress
values obtained for the ill-defined face space
might have been expected, since making the discrete-valued features continuous probably increases the complexity of the ill-defined space.
Still, no qualitative changes were apparent, and
the location of the category prototypes remained
lawful for each space.
GENERAL DISCUSSION
Four results are clear. First, the oldness ratings in Experiments 1 and 2 are similar to those
obtained previously (Homa et al., 1993) except
for the category prototype. Here, the category
prototype was rated older with additional learning trials (categorical or observational), rather
than newer as in our previous study. Performance on the remaining stimuli functioned in a
manner similar to that in our previous study: old
instances became older with additional study trials, and new instances, including foils, became
newer. The performance difference for the cate-

gory prototype is, however, a dramatic departure
from our earlier finding and suggests that the
type of category may be critically important in
determining the memorial status of the category
prototype.
Second, recognition performance for well-defined faces following classification (Experiment
1) or observational (Experiment 2) training was
nearly identical, both initially after a single learning exposure (one trial) or after substantial exposure (nine trials). In particular, the category prototype was rated as old as the training stimuli even
after a single learning trial, regardless of training
technique. Following either training technique,
the category prototype (as well as the old instances) became older with additional study trials, and new instances became newer, with performance on the latter modulated in an orderly
fashion by distortion level. It is worth stressing
that the category prototype was falsely recognized as old over 80% of the time after an initial
trial, and over 93% of the time following nine
learning trials, regardless of training paradigm.
Third, prior observational training (Experiment 3) did not result in the formation, either

FACE CATEGORIES

explicitly or implicitly, of categories. Had categories been formed during observational training, positive transfer to the subsequent category
learning phase and/or category transfer test
should have occurred. The prior observational
training was not without impact, since it did
affect later recognition judgments, mostly by
making the new faces seem even newer and
less likely to be falsely recognized. As a consequence, the comparable recognition performance in Experiments 1 and 2 was probably not
due to subjects learning the categorical structure
to similar degrees; rather, whatever mechanism
was involved in recognition was likely independent of (or weakly dependent upon) the formation of categories during learning.8 This is
not to claim that categories were not formed
during category learning--rather, that the formation of categories is mute with regard to later
recognition.
Finally, we were able to replicate our previous recognition data (Homa et al., 1993) by
making the faces ill defined (Experiment 4). In
particular, removing identical features from the
learning set, by distorting each feature type, resulted in the category prototype being recognized as old less often after nine learning trials.
Interestingly, this outcome was also associated
with learning; the better the learning, in terms of
classification errors after 9 trials, the greater the
likelihood of calling the prototype new. This relationship was not found in Experiment 1 or following a single learning trial in Experiment 4.
A Signal Detection Model for Recognition
The results of Experiment 1 (Category training) and 2 (Observational training) suggest that
high rates of false alarming to the category prototype need not be dependent upon "cohesive"
8
Nosofsky (1991), for example, has also shown that recognition and classification are often weakly correlated. However, his explanation is that classification uses the summed
similarity of exemplars to stored items of that category, relative to the summed similarity to all learned categories.
Recognition is based only on the latter. Thus, in his model, it
is possible to dissociate recognition and classification, even
though a common component is involved in each decision.
We do not mean to dispute this explanation; rather, we claim
that recognition need not be influenced by prior classification.

465

activity (Roediger & McDermott, 1995). Rather,
the recognition results can be explained most
simply and parsimoniously by assuming that the
subject stores pattern features during learning,
with the type of learning (category versus observation) possibly affecting the distribution, but
not the frequency, of features. To make this point
clear, consider Fig. 9, which shows the corresponding feature sets and their frequency after a
single trial, using the values shown in Table 1.
The upper left panel shows this distribution following observational learning and the remaining
panels show this distribution following categorical learning. Following observational training,
each feature type (e.g., Age Lines, Nose Type,
etc.) and value (1-6) is represented by its frequency of occurrence after one trial. The distribution for these same features is modified under
categorical learning, in that features are grouped
by category. We assume, for simplicity, that each
feature is accurately counted under each condition; if encoding and/or forgetting of feature values occurred equally under each condition, the
conclusions to be drawn are unchanged.
Three types of stimulus probes (an old face, a
new face with low distortion, and the prototype)
are shown in Fig. 10. At the time of recognition,
the subject matches the number of features between the probe with the corresponding feature
distribution, regardless of training condition. In
this example, the number of exactly matched
features, regardless of whether the faces were
categorized or observed during learning (for
each learning condition, old = 19, new-low = 17,
prototype = 21), would determine the likelihood
and confidence of calling the probe old. The
only difference between the observation and
category conditions is that this count is computed directly from the observation distribution
and derived via summing across categories following category learning. With additional training trials, the features are cumulated, and the
disparity among the probe types (old and prototype versus new faces) will grow. The assumed
representation of faces following observational
training, as depicted in Fig. 9, thus predicts
recognition performance while also precluding
an accurate estimate of number of categories in
the training set, an outcome obtained in this

466

HOMA ET AL.

FIG. 9.

Hypothetical feature distribution following one trial of observation and category learning.

study. We should note that we have no adherence to this simple storage/matching model; it is
perhaps the simplest of all classification/recognition models involving relatively few processing assumptions; rather, we only assert that co-

hesive activity (e.g., Roediger & McDermott,
1995) or category knowledge is unnecessary to
explain the comparable recognition performance following categorical and observational
training.

FACE CATEGORIES

FIG. 10.

467

Hypothetical characteristics of transfer probe for Old, New-Low, and Prototype faces.

A simple decision mechanism, such as a criterion cutoff for calling a probe old as in signal
detection theory (Green & Swets, 1966), should
then be able to simulate the results. Each transfer item is assumed to have a familiarity value
on a familiarity continuum, derived from sum-

ming the frequency counts for each matching
feature, and it is assumed that the subject establishes a criterion for judging an item as old. A
single criterion on this continuum should exist
which predicts the rate of judging each of the
items as old. Table 5 shows, for Experiments 1

468

HOMA ET AL.
TABLE 5
A Signal Detection Analysis of the Recognition Performance, Experiments 1 and 2
1 learning trial
Classification

9 learning trials
Observational

Classification

Observational

Item

FAM

Obs

Pred

FAM

Obs

Pred

FAM

Obs

Pred

FAM

Obs

Pred

Old
New-L
New-M
New-H
Proto
Foil
Crit
SD
MAD

5.03
4.03
3.74
2.99
5.12
1.68
3.50
1.74
0.020

0.844
0.606
0.556
0.406
0.850
0.120

0.811
0.618
0.556
0.386
0.824
0.147

4.83
3.75
3.00
2.47
4.76
1.24
3.45
1.28
0.032

0.817
0.617
0.322
0.244
0.800
0.030

0.860
0.591
0.363
0.221
0.846
0.042

5.57
2.43
1.72
1.28
5.65
1.09
3.30
1.30
0.022

0.911
0.261
0.128
0.039
0.967
0.010

0.960
0.251
0.111
0.061
0.965
0.045

5.50
2.92
1.90
1.65
5.27
1.18
3.30
1.25
0.015

0.944
0.383
0.144
0.106
0.933
0.010

0.961
0.382
0.131
0.093
0.943
0.045

Note. Crit, Criterion; SD, Standard Deviation; MAD, Mean Absolute Difference between observed and predicted values.

and 2, such a criterion, along with the predicted
rates of old judgments for each of the item
types. This analysis assumed that the distributions were normal with each item type having
the same variance. In each of the conditions, the
mean absolute difference between observed and
predicted rates averaged about 0.02. The impact
of additional learning trials would further separate the oldness ratings for the old and prototype
items versus the remaining items. Surprisingly,
neither the criterion nor the estimated distributional variances change very much. Importantly,
the estimated parameters (mean and variance)
for the observation and classification conditions
are very similar.9

9

We have also fit the classification data to a mixed model
of classification (Busemeyer, Dewey, & Medin, 1984; Homa
et al., 1991), which indexes the relative contribution of exemplar and prototype influences to classification. In this analysis, the prototype contribution to classification was zero following one learning trial in Experiments 1 and 4. However,
following nine learning trials, each experiment resulted in a
small prototype contribution to classification. The results of
this analysis are available upon request. For this and other
reasons, we cannot dismiss a prototype contribution to classification, even in Experiment 1. Rather, we stress that the results following classification and observational training are
nearly identical, regardless of the number of learning trials,
where the latter task is likely mute with regard to prototype
influences.

We agree with other researchers (e.g., Reinitz,
Lammers, & Cochran, 1992; Underwood,
Kapelak, & Malmi, 1976) that false recognition
may involve miscombination of features, perhaps
at the time of retrieval. Reinitz et al. demonstrated, for example, that false recognition can
occur to novel stimuli that contain erroneous
combinations of familiar features. Since these
outcomes were obtained in a memory paradigm
devoid of categorical influences, false recognition
of a category prototype could occur without categorization playing a role. Our results differ in a
fundamental way, however. Reinitz et al. found
no change in false alarm rates for new items that
contained a mixture of old and new features versus those that contained only new features. All
experiments reported here found a graded effect
for this variable: new-low, new-medium, and
new-high faces had 1, 2, and 5 new features (out
of 6 possible), respectively, and oldness judgments decreased systematically across distortion
level. As such, their claim that oldness decisions
are based only on miscombinations of old features is inconsistent with the present data.
Interpretation of Experiment 4, with its learning of ill-defined faces, is more complicated,
since recognition of the category prototype following nine trials was reduced, not increased,
relative to one learning trial. The distortion of
individual features in the learning set resulted in

FACE CATEGORIES

recognition performance nearly identical to our
earlier study using distorted forms (Homa et al.,
1993). Therefore, the criticality of well-defined
versus ill-defined categories in prototype recognition receives support. In short, the prototype
stimulus is featurally unique under this manipulation, and it is this property that presumably
helps to insulate it against it being falsely recognized as old. In a previous experiment (Goldman
& Homa, 1977), subjects preferred, as most representative, a modal prototype under some conditions and an averaged-feature prototype under
others. For that reason, we suggested that subjects may "count" features under some conditions and average them under others. Perhaps
subject strategies are further modified by the illdefinedness of the categories to be learned. That
is, once the subject realizes that features are
being repeated, the prototype becomes that pattern having modal feature values; in contrast,
once the subject becomes aware that none of the
features are repeated, the prototype becomes that
pattern having averaged feature values. A related
view was suggested by Regehr and Brooks
(1993), who found that categorical structure may
promote varying degrees of analytical and nonanalytical processing. One factor, which these
authors called feature versus holistic individuation, is defined as whether the feature occurs in
identical or variable form in different members
of the category. Whether this concept can be related to the recognition of the category prototype
as old or new is unclear, since only classification
strategies were analyzed in their study. Regardless, the trends reported here--an increasing tendency to call the prototype old with additional
trials when the categories are well defined and
the opposite trend with ill-defined categories--
would likely be magnified with yet additional
learning. With extensive learning of ill-defined
categories, the prototype would rarely be recognized as familiar.
Ill-Defined and Well-Defined Categories
Although other interpretations may be possible, our finding of reduced rates of false alarming to the category prototype following additional learning is, we believe, at least partially
due to the ill-definedness of the categories. The
multidimensional scaling of the faces made ill

469

defined did not corrupt the intrinsic structure of
these categories, nor did it result in the category
prototype being less central to its category. As
such, it seems unlikely that this outcome was
produced by simply making the prototype more
distinctive. Indeed, the multidimensional scaling of these categories may have underestimated
the terminal level of categorical structure, since
additional learning typically enhances categorical structure (Homa et al., 1979), yet the likelihood of false recognition in the present study
was lower following nine trials rather than just
one. It is unlikely that the category prototype
was associated with a reduced rate of false recognition because the prototype was noncentral
or because it became more distinctive.
Why ill-definedness should produce these effects is less clear. We noted earlier that Galton's
(1879) observation than a composite face is
more handsome than its particulars and the more
recent finding that judged attractiveness of category members is a monotonically decreasing
function of distance from the prototype may
provide extraexperimental information that the
prototype is novel. Why this should occur for illdefined, rather than well-defined, categories is
left to conjecture, but one obvious candidate is
informational complexity. Ill-defined categories
are likely to have members that are sufficiently
rich in detail that no features are likely to exactly repeat, either singly or in combination or as
a higher-order Gestalt. Recent evidence suggests
that subjects are sensitive to informational nuance
when it is available. In speech perception,
Goldinger and his colleagues (e.g., Goldinger,
Palmeri, & Pisoni, 1993; Goldinger, 1996 ) have
amply demonstrated that subjects encode speaker
intonation, style, etc. A similar finding has been
reported in picture processing (e.g., Standing,
1973), including our own research with photographs and detailed line drawings that preserved
thematic content and which differed only in
nonessential detail (Homa & Viera, 1988). Pattern variance, when it is available, can be processed by human subjects. Pattern variance was
the original cornerstone of ill-definedness:
Ill-defined categories are the rule, not the
exception, in daily life. The visual distinctions between dogs and cats, or between

470

HOMA ET AL.

beauty and ugliness, are ill-defined, just like
the conceptual differences between creative
science and hack work, or health and neurosis. So are the EEG patterns which indicate
a particular stage of sleep, the X-ray shadows which suggest a tumor, the style of
painting which identifies a Picasso, or the
features which continue to characterize the
face of a friend through the years. (Neisser,
1967, p. 58)
For Neisser, this distinction was as crucial to
the earliest stages of perceptual processing as it
was to complex judgments, receiving its impetus from computer recognition of handscript and
speech. Whereas it was relatively trivial to develop programs that recognized machine print
by template-matching, no such program succeeded for handscripted letters. The problem
was one of unlimited variety, where both the dimensions and the boundaries of these categories (here, the 26 letters of the alphabet) were
largely unknown. Although token variance also
diminishes a subject's abilities to distinguish
between patterns, as in vowel discrimination
(e.g., Uchanski & Braida, 1998), such variation
poses far greater difficulties for computer recognition (Pisoni, 1990).
Unfortunately, the ill-defined/well-defined
distinction following Neisser became blurred --
categories, even when composed of members
whose features exhibited little or no variance
and whose dimensions were transparent, were
called ill defined or not well defined if membership could not be defined by a simple rule (e.g.,
Medin & Shaffer, 1978; Nosofsky, 1988), i.e., no
feature was singly necessary or sufficient to determine classification. Curiously, Neisser (1967)
claimed that subjects had little difficulty identifying the various handscripted letters, something
the computer programs could not accomplish accurately. In contrast, the types of patterns that
would be trivially easy for a computer to recognize or classify (e.g., eight binary-valued, geometric forms that belong to two categories) are
often associated with poor learning by human
subjects (over 40% of Medin and Schaffer's subjects were unable to classify 6-11 patterns into
two categories after 16-32 trials).

Current research indicates that the processing
of human faces, when presented with full detail
and nuance, may be remarkably complicated.
Hancock, Burton, and Bruce (1996) demonstrated that face recognition and identification is
predicted by complex analyses (principle components analysis) that use the range of continuous values in a face, and that different eigenvalues may predict whether faces are correctly
recognized or not. Levin (1996) has suggested
that speeded classification of faces may be mediated by contextual factors rather than simply
the density of category exemplars in a category.
In contrast, well-defined categories typically
have a paucity of features or a collection of features that exactly repeat. Given the limited pool
of features available for processing, the subject's strategy may be to simply tally the most
frequently occurring ones. That such strategies
are possible was demonstrated by Reinitz, Morrisey, and Demb (1994), who showed that the relational encoding of features in a face is dependent upon the attention-demands of the task.
In sum, a confluence of factors may dictate
whether subjects falsely recognize a category
prototype, whether the category is ill-defined,
the level of learning, whether categories were, in
fact, formed, and even subject strategies. Regardless, the assertion that false recognition of
the category prototype naturally arises from conceptual coherence is, we believe, wrong.
Observational Training, Concepts, and False
Recognition
Two final issues warrant comment. First, we
found little evidence of learning in the observation task (Experiment 3), a result consistent with
studies showing that concepts cannot be learned
in the absence of categorical feedback unless the
categories are highly structured (Aiken &
Brown, 1971; Homa & Cultice, 1984). For example, Aiken and Brown (1971) had subjects
classify, without feedback, 150 patterns into either of two polygon categories. When the patterns were low-level distortions, accuracy improved slightly across blocks of 50 trials; in
contrast, no significant improvement occurred
for subjects who classified either moderate- or
high-level distortions. A similar result was ob-

FACE CATEGORIES

tained by Homa and Cultice (1984), who used
nine-sided shapes. Here, subjects classified into
three categories, where the patterns were at one
of three precise levels of distortion (Posner,
Goldsmith, & Welton, 1967). Trial by trial analysis showed that the low-level distortions could
be classified accurately without feedback and
that performance improved across learning trials. However, the high-level distortions were not
associated with learning, and performance asymptoted only slightly above chance; minimal
but significant learning occurred for mediumlevel distortions, but again, asymptote was clearly
below 100% accuracy. All feedback control subjects learned to 100% or near-perfect levels.
These results appear to be at odds with a recent
spate of studies demonstrating learning in an observational paradigm (Billman & Knutson,
1996; Wattenmaker, 1993). However, it is unclear whether these claims would extend to more
complicated category learning situations. For
example, Billman and Knutson (1996) failed to
demonstrate knowledge of categories. Instead,
they showed that subjects, after exposure to a set
of undifferentiated stimuli, can be sensitive to
certain feature correlations. However, knowledge of feature correlations alone is insufficient
to determine categories, since related categories
will usually contain these same correlations,
e.g., noting that a set of animals had 4 legs and
2 eyes or that a set of objects with round dials
also had a rectangular face does not permit the
discrimination of dogs from frogs or radios from
ovens. The use of a subsequent categorization
task, rather than judgments of feature pairs,
might have shown whether categories had, in
fact, been formed. Furthermore, the stimulus set
used by Billman and Knutson was highly structured, i.e., subjects were only exposed to 27 of
2187 possible instances in which feature pairs
were perfectly correlated. Subjects' accuracy
varied from 65 to 75% (in their isolating and
structured conditions), where chance was 50%.
There is no dispute that highly structured categories having minimal feature variation can be
learned in the absence of feedback; rather, the
dispute evolves around the necessity of feedback for less-structured categories. Wattenmaker
(1993) similarly demonstrated sensitivity to fea-

471

ture correlations. However, the conditions explored, i.e., one category observation (Experiment 1), two categories with learning blocked
by category (Experiment 2), or learning two categories of size 4 (Experiments 3 and 4), with
stimuli composed of binary-valued features on
four or five dimensions, does, again, not address
the broader issue of whether categories can be
formed when complexity is increased, e.g., three
or more categories with larger numbers of instances drawn from a larger feature pool. Regardless, the results of our Experiment 3 were
clearly supportive of minimal category learning
under observational training.
Second, we are uncertain of how we should
position our results, relative to the wealth of
studies demonstrating false recognition effects
of the category prototype (e.g., Roediger &
McDermott, 1995). Since few studies demonstrating false recognition effects also manipulated level of learning,10 it seems plausible that
many of the effects are due to the false miscombination of weakly stored features at a
later time (e.g., Reinitz et al., 1993) and that
these effects would reverse with additional
learning, at least for ill-defined categories. In
our previous study (Homa et al., 1993), we
noted that the vast majority of category studies
investigating false recognition used a minimal
learning format. Even the false recognition obtained from the eye witness literature claims its

10

One of the reviewers objected to our characterization of
studies in false recognition (including the eyewitness accuracy experiments) as involving minimal learning. Although it
is true that distinctiveness of encoding reduces tendencies to
false alarm (e.g., Schacter et al., 1999), and that levels of processing may (Toglia, Neuschatz, & Goodwin, 1999) or may
not (Read, 1996) enhance these tendencies, each of these
studies still presented items within a single, brief (e.g., 1-4 s)
presentation. One notable exception was the study by McDermott (1996), which found reduced rates of false alarming
with increased study/test trials. In the eyewitness domain, the
critical event is typically shown once for a few seconds only.
Although the meta-analysis by Payne, Toglia, and Anastasi
(1994) demonstrated that the size of the misinformation effect is positively correlated with recognition accuracy, this
outcome was not based on variables that manipulated memory strength. As such, there is no way of knowing if false
alarming to a critical event would continue if greater exposure were provided.

472

HOMA ET AL.

support from minimal exposure to the original
event, e.g., the critical event may be shown for
2-3 s. Although researchers have demonstrated
that increased exposure to the misleading information tends to increase the likelihood of false
recognition (Mitchell & Zaragoza, 1996), researchers have not considered the role of increased exposure to the original event in later
false recognition. We would predict that the increased exposure to or greater learning of the
original event would again insulate it against
false recognition.
Finally, we believe the importance of illdefinedness versus well-definedness needs to be
clarified. The vast majority of studies in categorization theory have employed stimuli having repeating features, i.e., well-defined stimuli, yet it
is clear that our experiential input to patterns is
largely ill defined. For example, even snapshots
of the same face at different times produce features that are variable due to changes in facial expression and perspective. The argument that
"central" or prototype stimuli are recognized as
old or familiar may derive from an inadvertent
reliance on paradigms using minimal learning of
simple stimuli having repeating features.
REFERENCES
Aiken, L. S., & Brown, D. R. (1971). A feature utilization
analysis of the perception of pattern class structure.
Perception & Psychophysics, 9, 279-283.
Bersted, C. T., Brown, B. R., & Evans, S. H. (1969). Free
sorting with stimuli clustered in a multidimensional attribute space. Perception & Psychophysics, 6, 409-413.
Billman, D., & Knutson, J. (1996). Unsupervised concept
learning and value systematicity: A complex whole aids
learning the parts. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 22, 458-475.
Bower, G. W., Black, J. B., & Turner, T. J. (1979). Scripts in
memory for text. Cognitive Psychology, 11, 177-220.
Breen, T. J., & Schvaneveldt, R. W. (1986). Classification of
empirically derived prototypes as a function of category experience. Memory & Cognition, 14, 313-320.
Busemeyer, J. R., Dewey, G. I., & Medin, D. L. (1984).
Evaluation of exemplar-based generalization and the
abstraction of categorical information. Journal of Experimental Psychology: Learning, Memory, and Cognition, 10, 638-648.
Cliff, N. (1966). Orthogonal rotation to congruence. Psychometrika, 31, 33-42.
Deese, J. (1959). On the prediction of occurrence of particular verbal intrusions in immediate recall. Journal of Experimental Psychology, 58, 17-22.

Franks, J. J., & Bransford, J. D. (1971). Abstraction of visual
patterns. Journal of Experimental Psychology, 90,
65-74.
Galton, F. (1879). Composite portraits. Royal Anthropological Institute of Great Britain and Ireland, 8, 132-
144.
Garry, M., Manning, C. G., Loftus, E. F., & Sherman, S. J.
(1996). Imagination inflation: Imagining a childhood
event inflates confidence that it occurred. Psychonomic
Bulletin & Review, 3, 208-214.
Goldinger, S. D., Palmeri, T. J., & Pisoni, D. B. (1993).
Words and voices: Perceptual details are preserved in
lexical representations. In J. Ohala, T. Nearey, B. Derwing, M. Hodge, & G. Wiebe (Eds.), Proceedings of
the International Conference on Spoken Language Processing. Univ. of Alberta Press.
Goldinger, S. D. (1996). Words and voices: Episodic traces
in spoken word identification and recognition memory.
Journal of Experimental Psychology: Learning, Memory, and Cognition, 22, 1166-1183.
Goldman, D., & Homa, D. (1977). Integrative and metric
properties of abstracted information as a function of
category discriminability, instance variability, and experience. Journal of Experimental Psychology: Human
Learning and Memory, 3, 375-385.
Green, D. M., & Swets, J. A. (1966). Signal detection theory
and psychophysics. New York: Wiley.
Hancock, P. J. B., Burton, A. M., & Bruce, V. (1996). Face
processing: Human perception and principal components analysis. Memory & Cognition, 24, 26-40.
Hartley, J., & Homa, D. (1981). Abstraction of stylistic concepts. Journal of Experimental Psychology: Human
Learning and Memory, 7, 33-46.
Hayes-Roth, B., & Hayes-Roth, F. (1977). Concept learning
and the recognition and classification of exemplar.
Journal of Verbal Learning and Verbal Behavior, 16,
321-338.
Hintzman, D. L. (1986). Schema abstraction: In a multipletrace memory model. Psychological Review, 93, 411-
428.
Homa, D., & Cultice, J. (1984). Role of feedback, category
size, and stimulus distortion on the acquisition and utilization of ill-defined categories. Journal of Experimental Psychology: Learning, Memory, and Cognition,
10, 83-94.
Homa, D., Dunbar, S., & Nohre, L. (1991). Instance frequency, categorization, and the modulating effect of experience. Journal of Experimental Psychology: Learning, Memory, and Cognition, 17, 444-458.
Homa, D., Goldhardt, B., Burruel-Homa, L., & Smith, C.
(1993). Influence of manipulated category knowledge
on prototype classification and recognition. Memory &
Cognition, 21, 529-538.
Homa, D., Rhoads, D., & Chambliss, D. (1979). Evolution
of conceptual structure. Journal of Experimental Psychology: Human Learning and Memory, 5, 11-23.
Homa, D., & Viera, C. (1988). Long-term memory for pictures under conditions of thematically related foils.
Memory & Cognition, 16, 411-421.

FACE CATEGORIES
Knapp, A., & Anderson, J. A. (1984). Theory of categorization based on distributed memory storage. Journal of Experimental Psychology: Learning, Memory, and Cognition, 10, 616-637.
Kruskal, J. B. (1964). Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis. Psychometrika, 29, 1-27.
Lakoff, G. (1987). Cognitive models and prototype theory.
In U. Neisser (Ed.), Concepts and conceptual development. Cambridge: Cambridge Univ. Press.
Levin, D. T. (1996). Classifying faces by race: The structure
of face categories. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 22, 1364-1382.
Loftus, E. F., & Hoffman, H. G. (1989). Misinformation and
memory: The creation of new memories. Journal of Experimental Psychology: General, 118, 100-104.
McDermott, K. B. (1996). The persistence of false memories in list recall. Journal of Memory and Language, 35,
212-230.
Medin, D. L., & Schaffer, M. M. (1978). Context theory of
classification learning. Psychological Review, 85, 207-
238.
Metcalfe, J. (1990). Composite holographic associate recall
model (CHARM) and blended memories in eyewitness
testimony. Journal of Experimental Psychology: General, 119, 145-160.
Mitchell, K. J., & Zaragoza, M. S. (1996). Repeated exposure to suggestion and false memory: The role of contextual variability. Journal of Memory and Language,
35, 246-260.
Neisser, U. (1967). Cognitive psychology. New York: Appleton-Century-Crofts.
Newmann, P. G. (1977). Visual prototype formation with
discontinuous representation of dimensions of variability. Memory & Cognition, 5, 187-197.
Newmann, P. G. (1974). An attribute frequency model for
the abstraction of prototypes. Memory & Cognition, 2,
241-248.
Nosofsky, R. M. (1988). Exemplar-based accounts of relations between classification, recognition, and typicality.
Journal of Experimental Psychology: Learning, Memory, and Cognition, 14, 700-708.
Nosofsky, R. M. (1991). Tests of an exemplar model for relating perceptual classification and recognition memory. Journal of Experimental Psychology: Human Perception and Performance, 17, 3-27.
Payne, D. G., Toglia, M. P., & Anastasi, J. S. (1994). Recognition performance level and the magnitude of the misinformation effect in eyewitness accuracy. Psychonomic Bulletin & Review, 1, 376-382.
Pisoni, D. B. (1990). Effects of talker variability on speech
perception: Implications for current research and
theory. In Research on speech perception (Progress
Rep. 16, pp. 169-191). Bloomington: Univ of Indiana, Department of Psychology, Speech Research
Laboratory.
Posner, M. I., Goldsmith, R., & Welton, K. E., Jr. (1967). Perceived distance and the classification of distorted patterns. Journal of Experimental Psychology, 73, 28-38.

473

Posner, M. I., & Keele, S. W. (1968). On the genesis of abstract ideas. Journal of Experimental Psychology, 77,
353-363.
Posner, M. I., & Keele, S. W. (1970). Retention of abstract
ideas. Journal of Experimental Psychology, 83, 304-308.
Read, J. D. (1996). From a passing thought to a false memory in 2 minutes: Confusing real and illusory events.
Psychonomic Bulletin and Review, 3, 105-111.
Regehr, G., & Brooks, L. R. (1993). Perceptual manifestations of an analytic structure: The priority of holistic individuation. Journal of Experimental Psychology: General, 122, 92-114.
Reinitz, M. T., Lammers, W. J., & Cochran, B. P. (1992).
Memory-conjunction errors: Miscombination of stored
stimulus features can produce illusions of memory.
Memory & Cognition, 20, 1-11.
Reinitz, M. T., Morrissey, J., & Demb, J. (1994). Role of
attention in face encoding. Journal of Experimental
Psychology: Learning, Memory, and Cognition, 20,
161-168.
Rhodes, G., Proffitt, F., Grady, J. M., & Sumich, A. (1998).
Facial symmetry and the perception of beauty. Psychonomic Bulletin & Review, 5, 659-669.
Rhodes, G., & Tremewan, T. (1996). Averageness, exaggeration, and facial attractiveness. Psychological Science,
7, 105-110.
Roediger, H. L., & McDermott, K. B. (1995). Creating false
memories: Remembering words not presented in lists.
Journal of Experimental Psychology: Learning, Memory, and Cognition, 21, 803-814.
Schacter, D. L., Israel, L., & Racine, C. (1999). Suppressing
false recognition in younger and older adults: The distinctiveness heuristic. Journal of Memory and Language, 40, 1-24.
Shepard, R. N. (1962). The analysis of proximities: Multidimensional scaling with an unknown distance function:
I. Psychometrika, 27, 125-140.
Shiffrin, R. M., Huber, D. E., & Marinelli, K. (1995). Effects
of category length and strength on familiarity in recognition. Journal of Experimental Psychology: Learning,
Memory, and Cognition, 21, 267-287.
Solso, R. L., & McCarthy, J. E. (1981a). Prototype formation of faces: A case of pseudo-memory. British Journal of Psychology, 72, 499-503.
Solso, R. L., & McCarthy, J. E. (1981b). Prototype formation: Central tendency model vs. attribute-frequency
model. Bulletin of the Psychonomic Society, 17, 10-11.
Solso, R. L., & Raynis, S. A. (1979). Prototype formation of
imaged, kinesthetically and visually presented geometric forms. Journal of Experimental Psychology: Human
Perception and Performance, 5, 701-712.
Standing, L. (1973). Learning 10,000 pictures. Quarterly
Journal of Experimental Psychology, 25, 207-222.
Sulin, R. A., & Dooling, D. J. (1974). Intrusion of a thematic
idea in retention of prose. Journal of Experimental Psychology, 103, 255-262.
Toglia, M. P., Neuschatz, J. S., & Goodwin, K. A. (1999).
Recall accuracy and illusory memories: When more is
less. Memory, 7, 233-256.

474

HOMA ET AL.

Uchanski, R. M., & Braida, L. D. (1998). Effects of token
variability on our ability to distinguish between vowels.
Perception & Psychophysics, 60, 533-543.
Underwood, B. J. (1965). False recognition produced by implicit verbal responses. Journal of Experimental Psychology, 70, 122-129.
Underwood, B. J., Kapelak, S. M., & Malmi, R. A. (1976).
Integration of discrete verbal units in recognition

memory. Journal of Experimental Psychology: Human
Learning and Memory, 2, 293-300.
Wattenmaker, W. D. (1993). Incidental concept learning,
feature frequency, and correlated properties. Journal of
Experimental Psychology: Learning, Memory, and
Cognition, 19, 203-222.
(Received August 26, 2000)
(Revision received March 7, 2000)

