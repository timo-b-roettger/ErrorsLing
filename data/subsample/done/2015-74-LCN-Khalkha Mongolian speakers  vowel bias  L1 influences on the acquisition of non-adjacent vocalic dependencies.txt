Language, Cognition and Neuroscience

ISSN: 2327-3798 (Print) 2327-3801 (Online) Journal homepage: www.tandfonline.com/journals/plcp21

Khalkha Mongolian speakers' vowel bias: L1 influences
on the acquisition of non-adjacent vocalic dependencies
Amy LaCross
To cite this article: Amy LaCross (2015) Khalkha Mongolian speakers' vowel bias: L1
influences on the acquisition of non-adjacent vocalic dependencies, Language, Cognition and
Neuroscience, 30:9, 1033-1047, DOI: 10.1080/23273798.2014.915976
To link to this article: https://doi.org/10.1080/23273798.2014.915976

Published online: 06 May 2014.

Submit your article to this journal

Article views: 490

View related articles

View Crossmark data

Citing articles: 4 View citing articles

Full Terms & Conditions of access and use can be found at
https://www.tandfonline.com/action/journalInformation?journalCode=plcp21

Language, Cognition and Neuroscience, 2015
Vol. 30, No. 9, 1033-1047, http://dx.doi.org/10.1080/23273798.2014.915976

Khalkha Mongolian speakers' vowel bias: L1 influences on the acquisition of non-adjacent
vocalic dependencies
Amy LaCross*
Department of Linguistics, University of Arizona, Communication Bldg. Room 109, Tucson, AZ 85721, USA
(Received 30 June 2013; accepted 28 March 2014)
Native language (L1) phonology has been shown to play an important role in influencing humans' perception and
production of novel speech. Yet research examining the conditions which trigger humans to calculate transitional
probability between non-adjacent linguistic elements has not considered the potential influence of L1 phonology. For
example, previous artificial grammar learning (AGL) literature has shown that participants acquire certain non-adjacent
phonological dependencies only with difficulty. However, this previous research used only speakers of English or French,
languages which do not exhibit such dependencies. This paper investigates how L1 phonology influences participants'
acquisition of non-adjacent phonological dependencies in an AGL task. Five experiments were conducted with speakers of
Khalkha Mongolian, a language which exhibits a non-adjacent dependency, vowel harmony and with speakers of American
English, a language which exhibits no such dependencies. Khalkha Mongolian speakers successfully acquired non-adjacent
vocalic dependencies while American English speakers failed to do so under identical statistical conditions. Besides
providing further evidence that statistical learning is not limited to the acquisition of adjacent dependencies, these findings
suggest that L1 phonology plays an important role in biasing speakers' attention towards certain aspects of language.
Keywords: non-adjacent phonological dependencies; vowel harmony; artificial grammar learning; L1 phonology bias;
Khalkha Mongolian

In order to acquire language, infants are faced with the
formidable task of segmenting a continuous speech
stream into discrete elements - words. To do so, it is
necessary for infants to detect and learn the statistical
probability of the co-occurrence of not only adjacent, but
also non-adjacent phonemes. For example, it has been
shown that both infants and adults can detect highprobability transitions between non-adjacent consonants,
and based upon these high-probability co-occurrences
insert word boundaries (e.g., Bonatti, Pena, Nespor &
Mehler, 2005; Gonzalez-Gomez & Nazzi, 2012; Mehler,
Pena, Nespor, & Bonatti, 2006; Nazzi, Floccia, Moquet,
Butler, 2009; Newport & Aslin, 2004; Onnis, Monaghan,
Christiansen, & Chater, 2004; Toro, Nespor, Mehler, &
Bonatti, 2008).
Humans' ability to detect non-adjacent dependencies
(highly probable co-occurrences of non-adjacent phonemes) for the purposes of word segmentation has been
well studied. This literature has given rise to debate over
the types of non-adjacent dependencies which are easiest
to detect and learn. However, this previous literature,
which examines only native English or French speakers,
does not take into account the role of participants' first
language (L1) in influencing their ability to acquire nonadjacent dependencies (e.g., Bonatti et al., 2005; Mehler
et al., 2006; Newport & Aslin, 2004; Onnis, Christiansen,

*Email: lacross@email.arizona.edu
(c) 2014 Taylor & Francis

Chater, & Gomez, 2003; Onnis et al., 2004; Pena, Bonatti,
Nespor, & Mehler, 2002; Toro et al., 2008).
Claims about the universal difficulty or ease of acquisition for different types of non-adjacent dependencies are
problematic. Previous research has demonstrated that
humans' perception of novel speech input is influenced by
their L1. For instance, L1 phonological density can influence
word recognition response times (RT) in a novel speech
perception task (Garlock, Walley, & Metsala, 2001; Luce &
Pisoni, 1998; McClelland & Elman, 1986; Van Heuven,
Dijkstra, & Grainger, 1998; Vitevitch, Luce, Charles-Luce,
& Kemmerer, 1997; Ziegler, Muneaux, & Grainger, 2003).
The influence of an L1 on novel speech perception and
production has also been extensively demonstrated in
research on second language acquisition (SLA). A large
body of work has demonstrated that SLA is strongly
influenced (both facilitation and interference) by transfer
of L1 properties (Ellis, 2006; Hawkins, 2008; Odlin,
1989; O'Grady, 2008; Pajk, Fine, Kleinschmidt, &
Jaeger, 2014; Selinker, 1969; Schwartz & Eubank,
1996). For example, it is well known that L1 phonemic
categories can distort perception of non-native contrasts,
making the acquisition of new categories difficult (Best,
1993, 1994, 1995; Flege, 1988, 1992, 1995; Kuhl, 1992,
1994). It has also been found that listeners use implicit
knowledge about their L1 to make inferences about

1034

A. LaCross

potentially informative phonemic contrasts in novel languages. For example, speakers of a language with
contrastive vowel length are more likely to detect
consonant length contrasts in novel speech than speakers
of languages which do not contain contrastive length
(Pajk, 2012; Pajk, Creel, & Levy, 2012; Pajk &
Levy, 2012).
Difficulty in acquiring a second language extends
beyond the similarity/dissimilarity of L1 categories to L2
categories. In regard to statistical learning, it has been
shown that language learners' ability to segment words on
the basis of statistical cues in novel speech input is
impaired when novel statistical cues conflict with those in
learners' L1 (Finn & Hudson Kam, 2008). It has also been
demonstrated that L1 phonemic category cues can override statistical frequency cues in novel speech input
(Goudbeek, Cutler, & Smit, 2008).
In line with L1 phonotactic and statistical cue biases, it
is possible a speaker may also be biased by L1 phonological patterns and seeks the same patterns in novel speech.
It has been found that speakers of vowel harmonic
languages rely on implicit knowledge of harmonic structure and vowel co-occurrence patterns to segment words
in novel speech streams (Kabak, Maniwa, & Kazanina,
2010; Suomi, McQueen, & Cutler, 1997; Vroomen,
Tuomainen, & de Gelder, 1998). In regard to non-adjacent
dependency acquisition, it is possible that speakers of a
vowel harmonic language would be more likely to detect
and acquire non-adjacent vocalic dependencies than
speakers of a non-vowel harmonic language. Infants
acquiring a vowel harmonic language learn that attending
to vowel co-occurrence patterns is a productive statistical
mechanism for segmenting words from a speech stream.
Therefore, it is hypothesised that adult speakers of such
languages retain a bias towards this mechanism and attend
to non-adjacent vowels in novel speech input. Conversely,
infants acquiring a non-vowel harmonic language would
not benefit from such a strategy and thus adult speakers
would have no reason to attend to the co-occurrence
probabilities of vowels.
To test this hypothesis, five artificial grammar learning
(AGL) experiments were conducted. These experiments
test the ability of monolingual speakers of Khalkha
Mongolian, a language which exhibits vowel harmony,
and monolingual speakers of American English, a language which exhibits no such dependencies, to acquire
non-adjacent vocalic dependencies. It is hypothesised that,
due to the presence of vowel harmony in their L1,
Khalkha speakers will be biased to attend to non-adjacent
vowels in a novel speech input and thus will acquire nonadjacent vocalic dependencies. In contrast, American
English speakers will fail to acquire non-adjacent vocalic
dependencies because they have no such bias to attend to
non-adjacent vowels.

Previous cross-linguistic work
While it is hypothesised that speakers of a vowel
harmonic language are biased to acquire non-adjacent
vocalic dependencies, it is not claimed that it is impossible
for speakers of non-harmonic languages to acquire these
dependencies. Previous work has demonstrated, for
instance, that non-adjacent vocalic dependencies can be
acquired by both English and French speakers (Bonatti
et al., 2005; Newport & Aslin, 2004). However, it seems
that these participants could only acquire vocalic dependencies under certain circumstances involving high repetition levels of the vocalic dependency. For example,
Newport and Aslin (2004) demonstrate that native English
participants successfully acquired non-adjacent vocalic
dependencies in an AGL task.
In an AGL task, participants are exposed to a continuous
speech stream constructed from concatenated consonantvowel (CV) syllables, where specific triplets of nonadjacent segments or syllables exhibit high transitional
probability. All other transitional probabilities between both
adjacent and non-adjacent segments are low. Participants
are then tested on their acquisition of these high-probability
dependencies through a forced choice task between `words'
(items which contain high-probability vowel triplets) and
`part-words' (items which overlap two high-probability
triplets and thus display low-probability vowel strings)
taken from the training speech stream.
Bonatti et al. (2005) argue that participants in the study
of Newport and Aslin (2004) were only able to acquire
vocalic dependencies because the training stimuli exhibited a high level of repetition. Newport and Aslin (2004)
used two non-adjacent vocalic dependencies, exhibited by
eight words each. This meant that participants needed to
detect a small number of dependencies (only two) and that
each non-adjacent vocalic dependency was repeated at
least eight times each. Using another AGL task with
native French speakers, Bonatti et al. (2005) demonstrate
that their participants could only acquire non-adjacent
vocalic dependencies when conditions matched that of
Newport and Aslin (2004): two dependencies embedded
in eight items each. Participants in the study of Bonatti
et al. (2005) were unable to detect or acquire non-adjacent
vocalic dependencies when the number of vocalic dependencies was increased or the degree of repetition was
reduced, in this case to three vocalic dependencies
exhibited by four words each.
The importance of repetition as a cue to participants'
ability to detect non-adjacent vocalic dependencies is
unsurprising. Previous research conducted with native
English-speaking subjects (e.g., Gomez, 2002; Gomez &
Maye, 2005; Onnis et al., 2003, 2004) has shown the
variability of non-adjacent dependencies in comparison
with the frame material (elements intervening between nonadjacent dependencies) plays a crucial role in triggering

Language, Cognition and Neuroscience
participants' calculation of statistical probability of nonadjacent elements. It has been shown that participants in
AGL experiments are only able to detect the presence of
non-adjacent dependencies when either non-adjacent
dependencies or medial frame material exhibits high
variability (Onnis et al., 2003, 2004).
The findings of Gomez (2002), Gomez and Maye
(2005) and Onnis et al. (2003, 2004) offer strong support
to the argument that human cognition relies upon a variety
of statistical strategies, each invoked by a specific set of
statistical circumstances. These studies, which focused on
both adults and infants, provide convincing evidence that
when presented with a stimuli stream humans attend to the
transitional probability between adjacent segments. When
the transitional probability of adjacent segments, however,
fails to provide informative cues to word boundaries, both
adults and infants in these studies have been shown to
expand their statistical processing window and focus on
non-adjacent elements.
While these studies highlight the role of statistical
learning as a universal processing mechanism, interestingly they overlook the possibility that speakers' L1 may
also influence or bias the use of these mechanisms. One
exception (Onnis, Monaghan, Richmond, & Chater, 2005)
considers the possibility that L1 phonotactic constraints
may influence acquisition success of non-adjacent CV
syllables. Post hoc analyses in this study demonstrate that
participants were more likely to acquire non-adjacent
syllabic dependencies when these CV syllables' onsets
were phonotactically more probable as onsets in subjects'
L1 (English) (Onnis et al., 2005). Despite these findings,
the majority of this literature shares an implicit assumption that the human mind is predisposed to attend (or fail
to attend) to the same linguistic elements regardless of
whether a speaker's L1 exhibits such an element. This
assumption is problematic given the limited number of
languages tested. Therefore, by testing both Khalkha
Mongolian and American English speakers, the current
paper seeks to examine whether L1 phonological patterns
bias speakers' attention towards specific elements of novel
speech input, causing them to seek similar phonological
patterns.
Experiment 1 tests Khalkha Mongolian speakers'
ability to acquire disharmonic non-adjacent vocalic
dependencies. In Experiment 2, American English speakers' ability to acquire non-adjacent vocalic dependencies
is tested using Experiment 1 stimuli. Experiment 3 again
tests American English speakers' ability to acquire nonadjacent vocalic dependencies, but uses native inventory
stimuli. Experiments 4 and 5 examine the importance of
phonological similarity to participants' L1 by testing
Khalkha Mongolian speakers' ability to acquire nonadjacent dependencies which obey the restrictions of
Khalkha Mongolian vowel harmony.

1035

Khalkha Mongolian
Before introducing each of these experiments, it is helpful
to provide a brief description of Khalkha Mongolian1
(hereafter: Khalkha). Khalkha, a member of the Mongolic
language family, is spoken by approximately 2.3 million
speakers not only in Mongolia, but also in the areas of the
Russian Federation, Kyrgyzstan, and the USA (Lewis,
Simons, & Fennig, 2013). Khalkha is an agglutinative
vowel harmonic language.
Why Khalkha Mongolian?
In order to examine whether L1 phonology influences
subjects' ability to acquire non-adjacent vocalic dependencies, it is necessary to test speakers of a language which
exhibits such a dependency. As a vowel harmonic
language, Khalkha is an ideal case. Vowel harmony
restricts the co-occurrence of vowels according to the
agreement of a specific feature or features within a word, a
word and its affixes, or sometimes even across word
boundaries, essentially requiring that `two or more notnecessarily-adjacent segments must be similar in some
way' (Archangeli & Pulleyblank, 2007, p. 353; van der
Hulst & van der Weijer, 1995).
Khalkha exhibits progressive Advanced Tongue Root
vowel harmony (ATR; Rialland & Djamouri, 1984;
Svantesson, Tsendina, Karlsson, & Franzen, 2005), which
requires that vowels agree within a word and its affixes in
terms of the feature [ATR]. This means that words in
Khalkha either contain [+ATR] or [-ATR] vowels, but
may not contain both. It has also been argued that
Khalkha displays rounding harmony (e.g., Rialland &
Djamouri, 1984; Svantesson et al., 2005); however, recent
corpus analyses reveal that rounding harmony is irregular
and restricted to specific affixes (LaCross, 2014). Given
the irregularity of rounding harmony in Khalkha, it is
disregarded in the current study. The Khalkha vowel
inventory, divided according to the feature [ATR] shown
in Table 1, represents the two-vowel classes. (Note that all
phonemes here and throughout the paper are presented in
the International Phonetic Alphabet (IPA)).
Table 2 demonstrates the harmonic system in both
mono- and multimorphemic items. Note that items display
vowels from only one harmonic class. The addition of the
Table 1. Khalkha vowel inventory divided according to the
feature [ATR].
[-ATR]


a



aa

[+ATR]
i
i
ai

u
o
e
i

uu
oo
ee
ii

Source: Svantesson et al., 2005; Rialland & Djamouri, 1984.

ui
oi
ei

1036

A. LaCross

Table 2. Examples of Khalkha [ATR] harmony.
[-ATR]
`place'
`placeREFLEXIVE'
b [nthaG]
`homeland'
[nthaGaa] `homelandREFLEXIVE'
c [plr]
`crystal'
[plr]
`crystalREFLEXIVE'
a

[gatsar]
[gatsaraa]

[+ATR]
[eleg]
[elegee]
[une]
[uneee]
[pompog]
[pompogoo]

`liver'
`liverREFLEXIVE'
`truth'
`truthREFLEXIVE'
`ball'
`ballREFLEXIVE'

reflexive affix, a long vowel, must match in harmonic
class and thus is instantiated differently for each item. (It
should also be noted that for the sake of simplicity only
items which happen to display one vowel were selected.
Khalkha words can, and do, contain different vowels, but
crucially, only those vowels which belong to the same
harmonic class.)
It should be noted that the regularity of Khalkha [ATR]
harmony is qualified only by the transparent status of the
high vowel [i]. This vowel may occur in [-ATR]
harmonic domains, provided it occurs in a non-initial
syllable. However, the high degree of regularity exhibited
by Khalkha [ATR] vowel harmony renders it an ideal
language in which to examine native speakers' potential
predisposition to attend to non-adjacent vowels in an
AGL task.

Experiment 1: disharmonic vocalic dependencies
In Experiment 1, native Khalkha speakers listened to a
stream of concatenated CV syllables which contained
high-probability vowel triplets. Participants were then
asked to identify `words' (CVCVCV strings containing
the high-probability vowels) over `part-words' (CVCVCV
strings which contain low-probability vowels). To more
closely replicate Bonatti et al. (2005), vowel triplets in
Experiment 1 did not obey the rules of Khalkha harmony.
It is hypothesised that because Khalkha displays vowel
harmony, Khalkha speakers will be predisposed to attend
to non-adjacent vowels in the stimuli, harmonic or not.
Therefore, Khalkha participants' preference for words
over part-words should be significantly higher than chance
levels, indicating that subjects noted the presence of highprobability vowel pairs to segment words from a continuous stimuli stream.

(15 female and 5 male). In this and all subsequent Khalkha
experiments, all participants were adult native speakers of
Khalkha, ranging in age from 18 to 24 years of age,
typically in their second to fourth year of university. In this
and all subsequent experiments, no participant reported
any hearing or visual impairments. All participants identified themselves as monolingual. In order to avoid
familiarity effects, no subject, in this or any subsequent
experiment, participated in more than one experiment.
Stimuli materials
Following previous literature (Bonatti et al., 2005; Newport & Aslin, 2004), items were created using a sixmember subset of the consonantal inventory [p, m, th, s, g,
x] and a nine-member subset of the vocalic inventory [i, e,
o, u, a, , , ai, ei] (Svantesson et al., 2005). Consonants
were selected so that place of articulation (bilabial,
alveolar and velar) was evenly distributed (two from
each category). Further, none of the selected consonants
have positional restrictions (Khalkha phonology allows
them to occur anywhere within a word2) and thus will not
offer false word boundary cues (Svantesson et al., 2005).
The entire short vowel inventory was selected and in order
to have a large enough set to create vowel triplets, the two
diphthongs [ai] and [ei] were added.
Three Khalkha vowel `triplets' (three-vowel sequences)
were selected from the vocalic inventory. These triplets
were: [_e_ai_], [_a_ei_o] and [_i_u_]. None of these
vowel triplets obey the rules of Khalkha [ATR] harmony.
This more closely replicates stimuli from the study of
Bonatti et al. (2005). (However, harmonicity of triplet is a
potentially important variable. It is more carefully examined in Experiments 4 and 5.) Because triplets are
disharmonic, they do not occur in the language and are
unknown in this occurrence pattern to participants.
Triplets were incorporated in CVCVCV items, as seen in
Table 3.
As in previous literature (Bonatti et al., 2005; Newport &
Aslin, 2004), the selection of random consonant fillers was
constrained to two possible consonants in each consonantal
slot, as illustrated by the schema in Figure 1. Three possible
consonants could fill the intervening consonantal slots,
with two options per slot.
According to this stimulus schema, the transitional
probabilities both within a word and between words are
Table 3. Vowel triplets and items for Experiment 1.
_e_ai_

Method
Participants
Twenty students from the State University of Education
in Ulaanbaatar, Mongolia, participated in the experiment

pemait 
gesaix
pesaith
gemaix
h

_a_ei_o

_i_u_

h

thipum
xigus
thigum
xipus

mat eipo
saxeigo
maxeipo
satheigo

1037

Language, Cognition and Neuroscience
Table 4. Schema for target CV recording.

Figure 1. Item construction schema for Experiment 1 [adapted
from Newport and Aslin (2004, p. 140)].

controlled, such that the transitional probability between
non-adjacent vowels within words is 1.0, but at word
boundaries is 0.50. Adjacent transitional probabilities of
both consonants and vowels, both between and within
words, were always 0.50. These permutations resulted in
12 CVCVCV words for Experiment 1, all of which
belonged to one of three vowel triplet families, as
illustrated previously in Table 3.
The physical construction of the auditory stimuli
differed from previous literature. All previous literature
used artificially synthesised speech created with the use of
extant speech synthesisers for English or French (Bonatti
et al., 2005; Gomez, 2002; Newport & Aslin, 2004; Onnis
et al., 2004; Onnis et al., 2003). However, a Khalkha
speech synthesiser does not exist. Therefore, in order to
create items, all CV syllables were concatenated from the
recorded speech of a native Khalkha speaker.
All stimuli were auditory and were recorded in
Ulaanbaatar, Mongolia, with a Countryman head-mounted
microphone, using a digital portable Edirol recorder
(24 bit 96 KHz Wave/MP3 recorder: R-09Hr) and portable
pre-amp with phantom power. The speaker was a 28-yearold female native Khalkha speaker with no distinctive
regional dialectal markers. The recording took place in a
quiet classroom at the University of Technology and
Science.
Care was taken to ensure fluent and natural sounding
stimuli. Therefore, all permutations of possible CV
syllables were generated from the consonantal and vocalic
inventories [p, m, th, s, g, x] and [e, ai, , a, ei, o, i, u, ],
respectively. Each of these CV syllables, the target CV
syllables, was then embedded into a carrier CV_TARGET_CV frame. These frames were controlled such that
the second CV syllable member of the frame had one of
three places of articulation: bilabial, alveolar or velar. The
CV_TARGET_CV frames also agreed with the target CV
syllables in terms of harmonic class. These frames are
illustrated schematically in Table 4.
The speaker read these items from a list written in
Cyrillic orthography. So for example, in order to record
the target CV syllable [pu] in [+ATR] bilabial, alveolar
and velar environments, [tepupe], [tepute] and [tepuxe]
were presented to the speaker respectively as `A',
`A' and `A'.
Using Praat (Boersma & Weenink, 2008), each target
syllable was spliced out of their respective frames and

bilabial
alveolar
velar

[-ATR] target CV
syllables

[+ATR] target CV
syllables

te_CV_pe
te_CV_te
te_CV_xe

ta_CV_pa
ta_CV_ta
ta_CV_xa

concatenated into a stimulus item. To eliminate durational
differences which might be perceived as a stress cue,
each CV syllable's duration was altered to approximately
180 milliseconds. The resulting CVCVCV stimuli items
were approximately 540 milliseconds in duration. All
durational adjustments were done with the duration tier
feature in Praat (Boersma & Weenink, 2008).
Each stimulus item was concatenated such that place of
articulation of each CV syllable agreed with the place of
articulation of the subsequent CV syllable. For example,
to create the test item [pemaith], [pe] was spliced from
the recording item [tepepe] because it was recorded
preceding a bilabial. The second syllable [mai] was
spliced from a recording item [temaite] because it was
recorded preceding an alveolar. The final syllable [th]
was spliced from the recording item which agreed with the
subsequent stimulus item's first syllable's place of articulation. This care with the place of articulation of
subsequent consonants has the benefit of helping to
prevent the introduction of conflicting VC transition cues
that could slow processing or lead to misrecognition
(Marslen-Wilson, & Warren, 1994; McQueen, Norris, &
Cutler, 1999; Whalen, 1984).
Twelve CVCVCV stimuli items were concatenated into
six different pseudo-randomised lists, which resulted in a
stimuli stream of 72 CVCVCV items. This stimuli stream
was played at a rate of approximately 300 syllables per
minute [in line with the reported rate in Newport and
Aslin (2004)] and repeated 20 times. The resulting stimuli
stream was used as a training phase approximately
14 minutes in duration.
To avoid false word boundary cues, pitch variations
were removed using overlap-add resynthesis (formerly
known as Pitch Synchronous Overlap-Add (PSOLA)
resynthesis: Boersma & Weenink, 2008). A slightly falling
pitch contour was added to the complete string in order to
make it sound more natural. Following Pena et al. (2002),
who demonstrate that pauses between items in AGL tasks
can strongly influence participants' acquisition success, no
pauses between CV syllables were allowed, so the only
cues participants had about word boundaries came strictly
from the high transitional probabilities of the vowel
triplets and the low transitional probabilities between all
other adjacent and non-adjacent segments.
Test items were constructed using the same methods,
with the exception that two categories of items were

1038

A. LaCross
Participants could take as long as they wanted to
respond, but could not advance through the testing session
until they responded. (Pilot studies with limits on RT
resulted in blank data files as high numbers of participants
failed to respond quickly enough and timed out.) The total
experiment duration averaged 25-30 minutes.
Results

Figure 2. (a) `Words' are composed of high-probability vowel
triplets; (b) `Part-words' contain low-probability vowels.

constructed: `words' and `part-words'. Words consisted of
items which contain one of the high-probability vowel
triplets. Part-words were CVCVCV items whose syllables
overlapped two word boundaries, thus containing lowprobability vowels. Words and part-words are displayed in
Figure 2.
To determine that participants were not influenced by
the probability of summed bigram probabilities for words
versus part-words, all words' and part-words' bigram
probabilities were calculated. Bigram probability is the
joint probability with which one phoneme is followed by
an adjacent phoneme in a specific language (Andrews,
1992; Gernsbacher, 1984; Lee, 2003). A paired-sample
t-test analysis comparing the bigram probability (based on
bigram probabilities calculated from IPA transcriptions of
a Khalkha text: LaCross, 2011) of adjacent phonemes
within words and part-words did not indicate a significant
difference (t(79) = -0.099, p > 0.9), indicating that
participants were not influenced by adjacent phoneme
bigram probabilities.

Procedure
Participants sat in a quiet room at a Dell Mini laptop and
wore a pair of Audio-Technica headphones (ATH-M40fs).
Written instructions, auditory stimuli and the auditory test
phase were all presented on the laptop with E-prime 2.0
(Psychology Software Tools, Pittsburgh, PA). In this and
all subsequent Khalkha experiments, both written instructions within the experiment protocol and oral instructions
from the experimenter were in Khalkha. Participants
listened to a 14-minute training session followed by a
testing session. In the testing session, participants listened
to word pairs composed of a word and part-word,
separated by two seconds of silence. Participants were
instructed to select, by pushing keys on a keyboard, which
of the words they thought they'd heard in the training
session.

To normalise data in the absence of an RT cap, very quick
responses (RTs faster than 50 milliseconds) and very slow
responses (RTs slower than 6000 milliseconds) were
excluded from analyses. Exclusions accounted for less
than 5% of total data.
Participants' word preference level was 58.44% (SD:
6.56%). A one-sample t test indicated that participants'
word preference levels were significantly higher than
chance (50%; t(19) = 5.749, p < 0.001).
Discussion
Experiment 1 results indicate that Khalkha participants
successfully acquired non-adjacent vocalic dependencies
used in the experiment, as evidenced by a significant
preference for words over part-words. While Khalkha
speakers' word preference level was found to be significantly above chance, it should be noted that these levels
are comparatively low for an AGL task [e.g., word
preference levels range from 70-90% for non-adjacent
dependencies in the study of Newport and Aslin (2004)
and for adjacent dependencies, 65-80% in the study of
Saffran, Newport, and Aslin (1996)]. Given that the
current study is the first psycholinguistic study to have
been conducted in Mongolia, these comparatively low
preference levels may have been a result of the novelty of
the task for participants. Regardless, participants' successful acquisition of non-adjacent vocalic dependencies in
Experiment 1 directly contrasts with native French
participants' failure to do so under identical statistical
conditions in Experiment 2 in the study of Bonatti
et al. (2005).
However, methodologically Bonatti et al. (2005) differs
from the current experiment through their use of synthesised stimuli. It could be the case that the use of spliced
stimuli in the current experiment provided cues to aid
Khalkha speakers' success in choosing words over partwords. Therefore, Experiment 2, a replication of Experiment 1, was conducted with American English participants
as a comparison.

Experiment 2: replication of experiment 1 with
American English speakers
Using the same stimuli set from Experiment 1, it is
hypothesised that American English speakers will not

1039

Language, Cognition and Neuroscience
acquire non-adjacent vocalic dependencies, as evidenced
by word preference levels that do not differ significantly
from chance.
Method
Participants
Twenty students, ranging in age from 18 to 24 years of
age, from the University of Arizona in Tucson, Arizona,
participated in the experiment (15 female and 5 male). For
this and all subsequent experiments, the same number of
participants (20) is used in each experiment so that
statistical power for comparisons between experiments is
not an issue.
Stimuli material
Stimuli materials were the same as those used in Experiment 1. It should be noted that the phonemes used in the
Khalkha experiment largely overlap with native English
phonemes. The velar fricative [x] is a notable exception.
The use of native versus non-native phonemes is a
potentially important variable and will be addressed in
Experiment 3.
Procedure
Participants sat in a sound booth at a Dell Mini laptop and
wore a pair of Audio-Technica headphones (ATH-M40fs).
Written instructions, auditory stimuli and auditory test
phase were all presented with E-prime 2.0 (Psychology
Software Tools, Pittsburgh, PA). Written and oral instructions matched Khalkha instructions but were presented in
English. To match the Khalkha experimental conditions,
there was no limit to participants' RTs. Again, total
experiment duration averaged 25-30 minutes.
Results
As in Experiment 1, responses with RTs faster than 50
milliseconds and slower than 6000 milliseconds were
excluded from analyses (less than 3.1% of total data).
Participants' word preference level was 50.84% (SD:
6.31%). A one-sample t test indicated that participants'
word preference levels were not significantly higher than
chance (50%; t(19) = 0.597, p > 0.5). Further, a pairedsample t test indicated that Khalkha speakers' word
preference levels (58.44%) were significantly higher than
that of English speakers (t(38) = 3.577, p < 0.001).
Discussion
Though English speakers failed to acquire the nonadjacent vocalic dependencies in Experiment 1 stimuli, it
may be the case that the presence of the non-native
phoneme [x] was the cause of their failure. Furthermore, it

may also be the case that using phonemes recorded by a
native Khalkha speaker might introduce phonetic cues and
characteristics not typical of an American English speaker.
Therefore, Experiment 3 was conducted using stimuli
constructed from the English phonemic inventory
recorded by a speaker of American English.

Experiment 3: native inventory stimuli for American
English speakers
Again, it is hypothesised that American English speakers'
word preference levels will not be significantly different
from chance. Thus, despite the use of L1 phonemes, they
will fail to acquire non-adjacent vocalic dependencies
exhibited by experiment stimuli, as evidenced by word
preference levels which are not significantly different from
chance.
Method
Participants
Twenty students, ranging in age from 18 to 24 years of
age, from the University of Arizona in Tucson, Arizona,
participated in the experiment (12 female and 8 male).
Stimuli material
Stimuli construction was identical to Experiment 1. Items
were created using subsets of the American English
vocalic and consonantal inventories, respectively: [i, u, ,
, e, o, , ae, a] and [p, g, t, k, s, m] (Hammond, 1999). As
in Experiment 1, consonants were selected so as to
balance distribution of place of articulation and to avoid
any segments with positional restrictions (Hammond,
1999). Vowels were selected at random. Three vowel
triplets were selected from the vocalic inventory: [_i_e_],
[__u_a], and [_ae_o_]. As in Experiment 1, random
consonantal fillers were constrained to two possible
consonants in each consonantal slot. A total of 12
CVCVCV words were created, as shown in Table 5.
The physical construction of the auditory stimuli
matched that in Experiment 1. All CV syllables were spliced
and concatenated from the recorded speech of a 26-year-old
female native speaker of American English with no
distinctive regional dialectal markers. The recording took
place in a sound booth at the University of Arizona in
Table 5. Experiment 3 items and vowel triplets.
ae_o_
taemop
kaesog
kaemog
taesop

_u_a

i_e _

mpuka
mguta
spuka
sputa

pites
pikem
gites
gikem

1040

A. LaCross

Tucson, Arizona. Stimuli were recorded with a Countryman
head-mounted microphone using a digital portable Edirol
recorder (24-bit, 96-KHz Wave/MP3 recorder: R-09Hr)
and portable pre-amp with phantom power. The recording
list was presented in IPA to the speaker, a trained phonetician who was naive as to the purpose of the experiment.
As in Experiment 1, Praat (Boersma & Weenink, 2008)
was used for all splicing and concatenation, as well as pitch
and durational adjustments. Again, spliced target CV
syllables were concatenated to match according to the place
of articulation of a subsequent syllable. Durational differences were again eliminated by altering each CV syllable's
duration to approximately 180 milliseconds, resulting in
items approximately 540 milliseconds in duration.
The 12 items were concatenated into 6 different
pseudo-randomised lists, resulting in a stimuli stream of
72 CVCVC items. To be consistent between all experiments, this stimuli stream was played at a rate of
approximately 300 syllables per minute and repeated
20 times, which resulted in a training phase of approximately 14 minutes in duration. Pitch variations were
removed and a falling pitch contour was added (overlapadd resynthesis: Boersma & Weenink, 2008). No pauses
between CV syllables or words were allowed.
Test items were constructed using the same methods as
those described in Experiment 1. `Words' contained vowel
triplets while `Part-words' contained syllables which
overlapped two word boundaries. Again, no significant
difference in summed bigram probabilities was found
(based on American English bigram probabilities found in
the CMU Pronouncing Dictionary; Carnegie Mellon
University, 2000) between words and part-words (t(71) =
-2.001, p > 0.5).
Procedure
As in Experiment 2, participants sat in a sound booth at a
Dell mini laptop and wore a pair of Audio-Technica
headphones (ATH-M4ofs). The experiment was presented
using E-prime 2.0 (Psychology Software Tools, Pittsburgh, PA). Written and oral instructions were identical to
Experiment 2, but were presented in English. To match the
Khalkha experimental conditions, there was no limit to
participants' RTs. Total experiment duration averaged 25-
30 minutes.
Results
Again, responses with RTs faster than 50 milliseconds and
slower than 6000 milliseconds were excluded from
analyses (less than 2.9% of total data). Participants' word
preference level was 48.07% (SD: 7.91%). A one-sample
t test indicated that participants' word preference levels
were not significantly higher than chance (50%; t(19) =
0.361, p > 0.3). A paired-sample t test indicated Khalkha

speakers' word preference levels in Experiment 1 were
significantly higher than that of English speakers in
Experiment 3 (t(38) = 4.065, p < 0.01).
Discussion
The results of Experiments 1, 2 and 3 indicate that
Khalkha speakers successfully acquired non-adjacent vocalic dependencies, while English speakers failed to do so
under identical statistical conditions. Given that both
Khalkha- and English-speaking participants received the
same statistical information and yet performed differently
suggests that statistical information alone is not the only
factor in acquisition success. The importance of vowel cooccurrences in Khalkha phonology (and the lack of nonadjacent vocalic dependencies in English) lends support to
the notion that L1 phonology plays an influential role in
biasing speakers to attend to different aspects of the
speech stream, and subsequently the types of non-adjacent
dependencies noted.
Based on these results, however, it is unclear the extent
to which L1 phonological patterns might be generalised
by native speakers. It is possible that listeners would be
more successful when speech input more closely matches
L1 phonological patterns. For example, the vowel triplets
in Experiment 1 did not obey the rules of Khalkha [ATR]
harmony. If vowel triplets were harmonic, participants
would have two cues to identifying word boundaries,
statistical probability and mismatched harmonic boundaries. Previous research has demonstrated that harmonic
mismatch at word boundaries acts as a cue to aid word
segmentation (Kabak et al., 2010; Suomi et al., 1997;
Vroomen et al., 1998). In order to examine the extent of
an L1 bias and the potential role of harmonicity as a cue to
word boundaries, two additional AGL experiments were
conducted with Khalkha speakers.

Experiment 4: non-adjacent harmonic vowels
To further explore L1 influences on Khalkha speakers'
attention to non-adjacent vowels, Experiment 4 examines
the role of harmonicity in influencing participants'
acquisition of non-adjacent vocalic dependencies. In this
experiment all-vowel triplets are harmonic, closely following the same rules of phonology as participants' native
language, Khalkha. It is hypothesised that participants will
acquire these non-adjacent vocalic dependencies at a
higher rate of accuracy than in Experiment 1, where items
were not harmonic.
Method
Participants
Twenty students (17 female and 3 male) from the State
University of Education in Ulaanbaatar, Mongolia,

Language, Cognition and Neuroscience
participated in the experiment. An additional participant
was discarded due to high levels of background noise in
the experiment room.
Stimuli materials
Stimuli construction was identical to Experiment 1, with
the exception of the selection and number of the vowel
triplets. CV syllables were permutated from the same sixmember subset of the consonantal inventory [p, m, th, s,
g, x], but for Experiment 4 the vocalic sub-inventory was
expanded to 12 vowels [o, ei, u, i, ai, , e, ui, i, , i, a]
(Svantesson et al., 2005).
To more deeply examine the influence of L1 phonology on participants' success at acquiring non-adjacent
vocalic dependencies, stimuli for Experiment 4 obeyed
Khalkha rules of [ATR] harmony. So that subjects would
be exposed to equal numbers of [+ATR] and [-ATR]
items, two-vowel triplets from each harmonic class were
selected. Previous research demonstrated that Khalkha
speakers are sensitive to frequency of non-adjacent vowel
sequences (LaCross, 2011, 2012). Therefore, only harmonic vowel triplets that do not actually occur in Khalkha
were selected. These vowel triplets were: [_o_ei_u]
[_i_ai_], [_e_ui_i] and [__i_a]. Searches of a text
corpus of Khalkha (LaCross, 2011) confirmed that these
vowel triplets do not actually occur in Khalkha. As in
previous experiments, random consonantal fillers were
constrained to two possible consonants in each consonantal slot. A total of 16 CVCVCV items were created
(Table 6).
Note that [i], a [+ATR] segment, is included in both
harmonic classes as an individual segment and as a second
member of four diphthongs. Though the use of [i] in this
way is not ideal, Khalkha's vowel inventory size would
not allow the creation of four three-vowel harmonic
sequences without its inclusion. As [i] is transparent to
harmony in non-initial syllables, it was selected as the
best candidate to overlap harmonic classes (Rialland &
Djamouri, 1984; Svantesson et al., 2005). In Experiment 4,
as in Experiment 1, long vowels were excluded due
to positional restrictions and their role as stress cues
(Svantesson et al., 2005).
Items were concatenated into five pseudo-randomised
lists, which resulted in stimuli streams of 80 CVCVCV
Table 6. Experiment 4 items and vowel triplets.
[+ATR]
o_ei_u
pomeithu
goseixu
poseithu
gomeixu

[-ATR]
e_ui_i
methuipi
sexuigi
mexuipi
sethuigi

i_ai_
misaig
xipaith
mipaig
xisaith

_i_a
thpima
xgisa
thgima
xpisa

1041

items each. As in Experiments 1-3, these stimuli streams
were played at a rate of approximately 334 syllables per
minute and repeated a total of 20 times, which resulted in
a training phase of approximately 14 minutes. Because
items in this experiment were harmonic, items were
arranged such that harmonic class alternated between
each word. That is, a [+ATR] CVCVCV item followed a
[-ATR] item and so on. For example, the [+ATR] item
[goseixu] had to be followed by a [-ATR] item, like
[xpisa]. This arrangement provided another cue to the
locations of potential word boundaries. Therefore, participants in Experiment 2 had two cues to word boundaries:
transitional probabilities and harmonic mismatch at word
boundaries.
Physical construction of stimuli was identical to
Experiment 1. Recorded CV syllables were identically
concatenated into CVCVCV items, using the same
previously recorded CV syllables. Pitch variations were
also removed in the same way. Construction of test items
was also identical. Test pairs consisted of a word (a
CVCVCV item which contained one of the selected vowel
triplets) and a part-word which exhibited a low transitional
probability triplet. Due to the alternating harmonic class of
each item in the training stream, all part-words were
disharmonic. For example, for the two consecutive words
provided in the previous example, [goseixu] followed by
[xpisa], the resulting part-word [xuxpi] is disharmonic
according to the rules of Khalkha harmony.
As in Experiment 1, bigram analyses were conducted
on words and part-words to ensure that participants would
not be influenced by any bigram probability differences
between the two classes of items. A paired-sample t test
failed to reveal a significant difference between the two
types of items (t(79) = 0.086, p > 0.05), indicating that
participants will not be subject to an influence of differing
bigram probabilities in one item class over another.
Procedure
The procedure for Experiment 4 was identical to Experiment 1. Participants sat in a quiet room at a laptop and
read instructions on the laptop screen and then listened to
the 14-minute training phase over headphones. After the
training phase, participants were instructed to select one
word in each word pair, based on whether they thought
they had heard it in the training phase. Response times
were uncapped and the experiment did not advance until
participants responded. Average experiment duration was
approximately 25-30 minutes.
Results
As in all previous experiments, data were normalised
through the exclusion of responses with RTs faster than 50
milliseconds and slower than 6000 milliseconds (less than

1042

A. LaCross

3.9% of the data). Participants' word preference level was
55.19% (SD: 8.18%). A one-sample t test indicated that
participants' word preference levels were significantly
higher than chance (50%; t(19) = 2.84, p < 0.05).
Because participants' word preference level was lower
than expected, further analyses were conducted examining
preference levels within each harmonic class. Interestingly, a paired-sample t test indicated participants' word
preference level for [+ATR] triplets was significantly
higher than for [-ATR] triplets (60.16% versus 50.19%,
respectively) (t(19) = 2.149, p < 0.05; see Figure 3).
Indeed, participants' word preference levels for
[-ATR] triplets was not significantly different from
chance, indicating they failed to detect the non-adjacent
dependencies for this class of items at all (t(19) = 0.077,
p > 0.9). Conversely, preference for [+ATR] items was
significantly above chance (t(19) = 3.571, p < 0.01).
While participants' preference levels for [+ATR] items
were higher than Experiment 1 word preference levels, a
paired-sample t test indicated that this difference was not
statistically significant (t(19) = -0.554, p > 0.5).
Discussion
The results of Experiment 4 indicate that Khalkha participants again successfully acquired non-adjacent vocalic
dependencies, but surprisingly, only within the [+ATR]
harmonic class. Furthermore, though word preference
levels were higher for [+ATR] items than for Experiment
1 items, statistically, there was no significant difference
between the two experiments. These results suggest that
harmonicity of triplets did not aid participants in the task.
Before discussing potential explanations for this finding, it
is helpful to first eliminate one potential confound to
comparisons between Experiments 1 and 4.
Experiments 1 and 4 had different numbers of triplets.
Experiment 1 had three triplets, while Experiment 4 had
four. As mentioned, number of triplets and consequent

variability of stimuli have been shown to be influential in
acquisition success in AGL tasks (Bonatti et al., 2005;
Gomez, 2002; Onnis et al., 2003, 2004). Therefore,
Experiment 5, which uses an identical number of nonharmonic stimuli, was conducted to provide a better
comparison to Experiment 4.

Experiment 5: disharmonic vocalic dependencies
All-vowel triplets selected for Experiment 5 were disharmonic sequences. It is hypothesised that Khalkha participants will be biased to attend to the co-occurrence of
vowels in novel speech input due to L1 biases, as
evidenced by a significant preference for words over
non-words.
Method
Participants
Twenty students from the State University of Education in
Ulaanbaatar, Mongolia, participated in the experiment
(17 female and 3 male). Due to high levels of background
noise, an additional four participants were discarded.
Stimuli materials
Stimuli construction was identical to Experiment 4, with
the exception of the selection of the vowel triplets. Items
were created using the same 6-member consonantal subinventory [p, m, th, s, g, x] and the 12-member vocalic
sub-inventory [o, ei, u, i, ai, , e, ui, i, , i, a]
(Svantesson et al., 2005).
To match the stimuli numbers of Experiment 4, fourvowel triplets were selected to create 16 items. None of
these triplets occur in Khalkha. These vowel triplets were:
[_e_ai_] [_a_e_o], [_i_i_] and [_i_oi_u]. The resulting items and their respective vowel triplets are illustrated
in Table 7. Note that the same vowels used in Experiment
4 are used in Experiment 5. The only difference is the way
in which selected vowels have been arranged into vowel
triplets. It should also be noted that both [_e_ai_] and
[_a_e_o] were used in Experiment 1 and [_i_i_] and
[_i_oi_u] are new triplets (compare Tables 3 and 7).
Items were concatenated into five pseudo-randomised
lists, which resulted in stimuli streams of 80 CVCVCV
items each. As in Experiments 1-4, these stimuli streams
Table 7. Experiment 5 items and vowel triplets.
e_ai_

a_ei_o

pemait 
gesaix
pesaith
gemaix
h

Figure 3. Experiment 4 word preference levels according to
harmonic class. Error bars indicate 95% confidence interval
(normal).

h

mat eipo
saxeigo
maxeipo
satheigo

i_i_
h

t ipim
xigs
thigm
xips

i_oi_u
misoigu
xipoithu
mipoigu
xisoithu

Language, Cognition and Neuroscience
were played at a rate of approximately 334 syllables per
minute and repeated 20 times, which resulted in a training
phase of approximately 14 minutes. However, because
items in this experiment were not harmonic, it was not
possible to alternate harmonic class for adjacent items in
the training stream.
Physical construction of stimuli was identical to
Experiments 1, 2, 3 and 4. Similarly all splicing and
concatenation as well as manipulations of pitch and
duration were done using Praat (Boersma & Weenink,
2008). CV syllables were concatenated into CVCVCV
items using previously recorded CV syllables. Pitch
variations were again removed. Durations of CV syllables
were again adjusted to approximately 180 milliseconds,
resulting in CVCVCV items approximately 540 milliseconds in duration. Test pairs consisted of a word (a
CVCVCV item which contained one of the selected vowel
triplets) and a part-word (an item containing a lowprobability vowel triplet). Bigram analyses conducted on
words and part-words failed to reveal a significant
difference between the two types of items (t(79) = 0.152,
p > 0.16), indicating participants will not be subject to an
influence of differing bigram probabilities in one item
class over another.
Procedure
The procedure for Experiment 5 was identical to Experiments 1 and 4. Participants sat in a quiet room at a laptop
and read instructions on the laptop screen and then
listened to the 14-minute training phase over headphones.
After the training phase, participants were instructed to
select one word in each word pair, based on whether they
thought they'd heard it in the training phase. Again,
participants were not limited on response time and could
not advance through the experiment until they'd
responded. Experiment durations averaged approximately
25-30 minutes.
Results
Data were again normalised according to RT (responses
with RTs faster than 50 and slower than 6000 milliseconds
were discarded from analysis - only 3.2% of the data).
Again, participants preferred words over part-words.
Participants' word preference levels were 58.21% (SD:
10.49%) and were significantly higher than chance
(50%; t(19) = 3.499, p < 0.005).
Discussion
The results of Experiment 5 indicate that Khalkha
participants successfully acquired non-adjacent vocalic
dependencies. However, a paired-sample t test did not
reveal a significant difference in word preference levels

1043

between Experiments 4 and 5 (t(38) = 0.094, p > 0.9).
These findings indicate that harmonicity did not aid
participants' ability to detect non-adjacent vocalic
dependencies.
Further, the failure of participants to acquire [-ATR]
non-adjacent vocalic dependencies raises several questions. As demonstrated by Experiments 1 and 5, Khalkha
speakers were able to detect and acquire even disharmonic
non-adjacent vocalic dependencies. Yet, they were unable
to detect or acquire the [-ATR] triplets in Experiment 4,
despite two cues to word segmentation: high-probability
vowel triplets and alternating harmonic class between
vowel triplets. Furthermore, there was not a significant
difference in acquisition success between the harmonic
[+ATR] items in Experiment 4 and disharmonic items
from either Experiment 1 or 5.
A variety of explanations for this must be examined.
First, it may simply be the case that participants are not
aided by harmonicity of triplets. It may be that an L1
phonological pattern bias is more general and thus speakers are not aided by a close match to L1 phonology.
Indeed, previous work has proposed that general distributional cues in novel speech input are more relevant than a
precise match between L1 and L2 contrastive categories
(such as a direct match between L1 and L2 consonantal
length contrasts; e.g., Pajk et al., 2014). However, if this
is the case, Khalkha participants should still be biased to
attend to vowels, whether vowels are harmonic or not.
Instead participants failed to acquire an entire class of
items.
Another possibility is that the [-ATR] triplets [i_ai_]
and [_i_a] are simply not well formed according to
Khalkha phonotactics. Thus, words made using [-ATR]
triplets were dismissed as potential words by participants.
To investigate this possibility, an informal survey was
conducted with Khalkha Mongolian speakers, none of
whom had been participants in the reported experiments
(n = 4). They were asked to rate the well-formedness of all
Experiment 4 items on a scale of 1-7 (7 being the most
possible Khalkha word and 1 the least possible). Though
this did not result in enough judgements to conduct a
statistical analysis, these speakers rated [+ATR] items as
better formed than [-ATR] items (4.133 versus 3.526,
respectively).
To determine if there are significant phonotactic
differences between the two item classes, summed bigram
probabilities were also calculated for each test word in
Experiment 4. A significant difference was found between
[+ATR] and [-ATR] items (t(78) = -3.068, p < 0.005),
such that summed bigram probabilities for [-ATR] items
were significantly higher than [+ATR] items (8.6% versus
7.6%, respectively). While this difference in summed
bigram probabilities may seem small, it is clear from
previous research (e.g., information theory; Shannon,
1948) that small differences in probability, in terms of

1044

A. LaCross

their log-likelihood, can be important. This suggests that
words formed from [-ATR] triplets contained adjacent
segments (both CV and VC) significantly more likely to
co-occur than bigrams in the [+ATR] class items. The
presence of high-probability bigrams within [-ATR] items
represents a significant confound for Experiment 4. It is
also possible that the presence of such bigrams contributed to judgements that [-ATR] items were not as well
formed as [+ATR] items. Taken together, both the wellformedness ratings and the significant differences in
bigram frequency between the two item classes suggest
that conclusions about the extent to which speakers
generalise L1 phonological patterns cannot be supported
by the results of Experiment 4. Further work is required to
clarify how the similarity or dissimilarity of novel speech
to L1 phonological patterns influences speakers' acquisition success.

General discussion
The results from all five experiments provide support to
the hypothesis that L1 phonology plays an important role
in biasing speakers towards attending to certain aspects of
language over others. Khalkha speakers acquired nonadjacent vocalic dependencies, while English speakers
failed to do so under identical statistical conditions. As
illustrated in Figure 4, Khalkha speakers' word preference
levels were significantly higher than chance, while American English speakers' word preference level stayed at
chance, indicating a failure to acquire non-adjacent
vocalic dependencies.
These findings support the central hypothesis: Khalkha
speakers' bias towards attending to vowels allows them to
successfully acquire non-adjacent vocalic dependencies in
AGL tasks. Conversely, English speakers who should
have no reason for such a bias failed to acquire nonadjacent vocalic dependencies. Further, the failure of

English speakers to acquire non-adjacent vocalic dependencies is consistent with French speakers' performance in
the study of Bonatti et al. (2005). These findings suggest
that, in addition to L1 phonemic category biases found in
previous work (Pajk, 2012; Pajk, Creel, & Levy, 2012;
Pajk & Levy, 2012), speakers are biased by L1 phonological patterns and seek these patterns in novel speech
input.
One of the implications of these findings is that L1
phonology influences the way in which humans learn an
L2. While this is not a new proposal, the current findings
suggest that L1 influences are more than a transfer of
specific L1 properties. Beyond specific harmony patterns
or phonemic category biases which influence perception
of novel categories, speakers of vowel harmonic languages transfer a more general bias to attend to vowel cooccurrence probabilities. The extent to which such a bias
is generalised is, however, unclear. As previous work
(e.g., Pajk, 2012; Pajk, Creel, & Levy, 2012; Pajk &
Levy, 2012) has demonstrated, speakers of languages with
contrastive vocalic length were more sensitive to contrastive length in consonants in novel speech input, which
suggests that L1 biases may be distributional in nature. In
line with these findings, it could be hypothesised, for
instance, that speakers of languages which display any
non-adjacent phonemic dependencies would be biased to
attend to all non-adjacent phonemic dependencies, both
consonantal and vocalic. Further work remains to determine the extent to which speakers generalise and transfer
information about L1 phonological patterns to L2 acquisition processes.
In the light of these findings, interpretations of
previous research on humans' ability to acquire nonadjacent phonological dependencies in AGL tasks must
also be reconsidered. For instance, it has been suggested
that French-speaking participants' failure to acquire nonadjacent vocalic dependencies is evidence that universally

Figure 4. Summary of preference levels for all experiments. Error bars indicate 95% confidence interval (normal).

Language, Cognition and Neuroscience
humans attend to consonants rather than vowels for the
purposes of speech segmentation (Bonatti et al., 2005).
The findings of the current experiments suggest, instead,
that participants' failure or success at acquiring particular
non-adjacent dependency types is a function of L1
phonological biases. While it is clear that human cognition exploits a variety of statistical processing mechanisms
(i.e., adjacent as well as non-adjacent transitional probability) (Bonatti et al., 2005; Gomez, 2002; GonzalezGomez & Nazzi, 2012; Nazzi et al., 2009; Newport &
Aslin, 2004; Onnis et al., 2003, 2004), the results of the
current paper suggest that L1 phonological patterns are
used by speakers as another source of information as they
learn the statistical information in novel speech.
Future research on the statistical processing mechanisms employed by humans when faced with novel speech
input must take into account potential biases from L1
phonological structures. The rich body of previous
research examining the ways in which speakers abstract
information like phonological neighbourhood density,
phonotactic constraints, phonological frequency and transitional probability of not only adjacent but also nonadjacent phonemes provides a clear framework for analysing any potential biases of these L1 variables on perception
of novel speech input. Examination of L1 biases promises
to provide key insight into the ways in which human
cognition learns and exploits statistical information in both
an L1 and in an L2 or novel speech input.

Conclusion
In addition to providing much needed psycholinguistic
data on an understudied language, Khalkha Mongolian,
these findings provide evidence that L1 phonological
patterns bias speakers to seek similar patterns in novel
speech input. Much remains to be learned about the
influence of L1 phonology on the statistical processing
mechanisms speakers use to learn novel speech input. In
particular, the extent to which L1 phonological information is generalised has yet to be ascertained. Manipulation
of the degree of similarity to L1 phonological patterns
would be a highly informative innovation in AGL tasks.
Examining the ability of vowel harmonic language speakers to acquire not only identical harmonic structures but
also structures like non-adjacent consonantal dependencies would reveal much about the ways in which L1
phonological patterns bias speakers to seek similar
structures in novel speech input.
Acknowledgements
I am grateful to Diane Ohala, Adam Ussishkin, Mike Hammond,
Natasha Warner and Diana Archangeli for their extensive help
and guidance in conducting the research outlined in this paper.
Special thanks to Adam Ussishkin for generously sharing his
lab's resources during the running of the American English

1045

experiments. I am also grateful for the exceedingly helpful
feedback provided by anonymous reviewers.

Funding
This research was supported by a Research Fellowship from the
American Center for Mongolian Studies, a member of the
Council of American Overseas Research Centers (COARC) in
Ulaanbaatar, Mongolia.

Notes
1.
2.

Also known as Halh Mongolian.
It should be noted that the use of [g] as a consonant
represents a possible confound because [g] alternates with
the uvular consonant [G] according to harmonic class in
Khalkha (for a complete description see Svantesson et al.,
2005 or LaCross, 2011). However, the effect of [g] on
participants' responses was investigated, and though there
were not enough item numbers to generate a statistical
analysis, responses to [g]-initial items did not pattern
differently from other responses in Experiments 1, 4 and 5.

References
Andrews, S. (1992). Frequency and neighborhood effects on
lexical access: Lexical similarity or orthographic redundancy? Journal of Experimental Psychology: Learning, Memory, and Cognition, 18, 234-254. doi:10.1037/02787393.18.2.234
Archangeli, D., & Pulleyblank, D. (2007). Harmony. In P.
de Lacy (Ed.), The Cambridge handbook of phonology
(pp. 353-378). Cambridge: Cambridge University Press.
Best, C. T. (1993). Emergence of language-specific constraints in
perception of non-native speech: A window on early
phonological development. In B. de Boysson-Bardies, S. de
Schonen, P. Jusczyk, P. MacNeilage, & J. Morton (Eds.),
Developmental neurocognition: Speech and face processing
in the first year of life. (pp. 298-304). Dordrecht: Klewer.
Best, C. T. (1994). The emergence of native-language phonological influence in infants: A perceptual assimilation model.
In J. Goodman & H. Nusbaum (Eds.), The development of
speech perception: The transition from speech sounds to
spoken words (pp. 167-224). Cambridge: MIT Press.
Best, C. T. (1995). A direct realist view of cross-language speech
perception. In W. Strange (Ed.), Speech perception and
linguistic experience: Issues in cross language research
(pp. 171-204). Timonium, MD: York Press.
Boersma, P., & Weenink, D. (2008). Praat: Doing phonetics by
computer (version 5.0) [Computer Program]. Institute of
Phonetic Sciences, University of Amsterdam. http://www.
praat.org/
Bonatti, L., Pena, M., Nespor, M., & Mehler, J. (2005).
Linguistic constraints on statistical computations: The role
of consonants and vowels in continuous speech processing.
Psychological Science, 16, 451-459. doi:10.1111/j.09567976.2005.01565.x
Carnegie Mellon University. (2000). CMU pronouncing dictionary. Retrieved October 1, 2014, from http://www.speech.cs.
cmu.edu/cgi-bin/cmudict
Ellis, N. (2006). Language acquisition as rational contingency
learning. Applied Linguistics, 27, 1-24. doi:10.1093/applin/
ami038
Finn, A., & Hudson Kam, C. (2008). The curse of knowledge:
First language knowledge impairs adult learners' use of

1046

A. LaCross

novel statistics for word segmentation. Cognition, 108,
477-499. doi:10.1016/j.cognition.2008.04.002
Flege, J. E. (1988). The production and perception of foreign
language speech sounds. In H. Winitz (Ed.), Human communication and its disorders: A review - 1988 (pp. 224-401).
Norwood, NJ: Ablex.
Flege, J. E. (1992). The intelligibility of English vowels spoken
by British and Dutch talkers. In R. D. Kent (Ed.), Intelligibility in speech disorders: Theory, measurement, and management (pp. 157-232). Amsterdam: John Benjamins.
Flege, J. E. (1995). Second-language speech learning: Theory,
findings and problems. In W. Strange (Ed.), Speech perception and linguistic experience: Issues in cross-language
research (pp. 229-273). Timonium, MD: York Press.
Garlock, V., Walley, A., & Metsala, J. (2001). Age of acquisition,
word frequency and neighborhood density in spoken word
recognition by cihldren and adults. Journal of Memory and
Language, 12, 468-492. doi:10.1006/jmla.2000.2784
Gernsbacher, M. (1984). Resolving twenty years of inconsistent
interactions between lexical familiarity and orthography,
concreteness and polysemy. Journal of Experimental Psychology: General, 113, 256-281. doi:10.1037/0096-3445.
113.2.256
Gomez, R. (2002). Variability and detection of invariant structure. Psychological Science, 13, 431-436. doi:10.1111/14679280.00476
Gomez, R., & Maye, J. (2005). The developmental trajectory of
non-adjacent dependency learning. Infancy, 7, 183-206.
doi:10.1207/s15327078in0702_4
Gonzalez-Gomez, N., & Nazzi, T. (2012) Effects of prior
phonotactic knowledge on infant word segmentation: The
case of nonadjacent dependencies. Journal of Speech,
Language and Hearing Research, 56, 840-849. doi:10.10
44/1092-4388(2012/12-0138)
Goudbeek, M., Cutler, A., & Smit, R. (2008). Supervised and
unsupervised learning of multidimensionally varying nonnative speech categories. Speech Communication, 50, 109-
125. doi:10.1016/j.specom.2007.07.003
Hammond, M. (1999). The phonology of English. Oxford:
Oxford University Press.
Hawkins, R. (2008). The nativist perspective on second language
acquisition. Lingua, 118, 465-477. doi:10.1016/j.lingua.
2007.02.011
Kabak, B., Maniwa, K., & Kazanina, N. (2010). Listeners use
vowel harmony and word-final stress to spot nonsense
words: A study of Turkish and French. Laboratory Phonology, 1, 207-224. doi:10.1515/LABPHON.2010.010
Kuhl, P. K. (1992). Psychoacoustics and speech perception:
Internal standards, perceptual anchors, and prototypes. In
L. A. Werner & E. W. Rubel (Eds.), Developmental
psychoacoustics (pp. 293-332). Washington, DC: American
Psychological Association.
Kuhl, P. K. (1994). Learning and representation in speech and
language. Current Opinion in Neurobiology, 4, 812-822.
doi:10.1016/0959-4388(94)90128-7
LaCross, A. (2011). The role of language-specific phonology:
Tracking linguistic variables in Khalkha Mongolian (Unpublished doctoral dissertation). University of Arizona,
Tucson, AZ.
LaCross, A. (2012). Non-adjacent phonological dependency
effects on Khalkha Mongolian speech perception. In
J. Choi, A. Hogue, J. Punske, D. Tat, J. Schertz, &
A. Trueman (Eds.), Proceedings of the 29th West Coast
Conference on Formal Linguistics (WCCFL), 29, 143-151.

LaCross, A. (2014). Khalkha Mongolian rounding harmony: A
corpus study. Unpublished manuscript.
Lee, C. (2003). Evidence-based selection of word frequency
lists. Journal of Speech - Language Pathology and Audiology, 27, 172-175.
Lewis, M. P., Simons, G. F., & Fennig, C. D. (Eds.). 2013.
Ethnologue: Languages of the world, seventeenth edition.
Dallas, TX: SIL International. http://www.ethnologue.com
Luce, P., & Pisoni, D. (1998). Recognizing spoken words: The
neighborhood activation model. Ear and Hearing, 19, 1-36.
doi:10.1097/00003446-199802000-00001
Marslen-Wilson, W. D., & Warren, P. (1994). Levels of
perceptual representation and process in lexical access:
Words, phonemes, and features. Psychological Review, 101,
653-675.
McClelland, J., & Elman, J. (1986). The TRACE model of
speech perception. Cognitive Psychology, 18, 1-86. doi:10.
1016/0010-0285(86)90015-0
McQueen, J., Norris, D., & Cutler, A. (1999). Lexical influence
in phonetic decision making: Evidence from subcategorical
mismatches. Journal of Experimental Psychology, 25, 1363-
1389. doi:10.1037/0096-1523.25.5.1363
Mehler, J., Pena, M., Nespor, M., & Bonatti, L. (2006). The
"soul" of language does not use statistics: Reflections on
vowels and consonants. Cortex, 42, 846-854. doi:10.1016/
S0010-9452(08)70427-1
Nazzi, T., Floccia, C., Moquet, B., & Butler, J. (2009). Bias for
consonantal information over vocalic information in 30month-olds: Cross-linguistic evidence from French and
English. Journal of Experimental Child Psychology, 102,
522-537. doi:10.1016/j.jecp.2008.05.003
Newport, E., & Aslin, R. (2004). Learning at a distance I:
Statistical learning of non-adjacent dependencies. Cognitive
Psychology, 48, 127-162. doi:10.1016/S0010-0285(03)
00128-2
Odlin, T. (1989). Language transfer: Cross-linguistic influence
in language learning. Cambridge, UK: Cambridge University Press.
O'Grady, W. (2008). The emergentist program. Lingua, 118,
447-464. doi:10.1016/j.lingua.2006.12.001
Onnis, L., Christiansen, M., Chater, N., & Gomez, R. (2003).
Reduction of uncertainty in human sequential learning:
Evidence from artificial grammar learning. Proceedings of
the 25th Annual Conference of the Cognitive Science Society
(pp. 886-891). Malwah, NJ: Lawrence Erlbaum Associates.
Onnis, L., Monaghan, P., Christiansen, M., & Chater, N. (2004).
Variability is the spice of learning, and a crucial ingredient
for detecting and generalizing non-adjacent dependencies.
Proceedings of the 26th Annual Conference of the Cognitive
Science Society (pp. 1047-1052). Malhwah, NJ: Lawrence
Erlbaum Associates.
Onnis, L., Monaghan, P., Richmond, K., & Chater, N. (2005).
Phonology impacts segmentation in online speech processing. Journal of Memory and Language, 53, 225-237.
doi:10.1016/j.jml.2005.02.011
Pajk, B. (2012). Inductive inference in non-native speech
processing and learning (Unpublished doctoral dissertation).
University of California, San Diego, CA.
Pajk, B., Creel, S., & Levy, R. (2012). Can native-language
perceptual bias facilitate learning words in a new language?
In N. Miyake, D. Peebles, & R. P. Cooper (Eds.), Proceedings of the 34th Annual Conference of the Cognitive Science
Society (pp. 2174-2179). Austin, TX: Cognitive Science
Society.

Language, Cognition and Neuroscience
Pajk, B., Fine, A., Kleinschmidt, D., & Jaeger, F. (2014).
Learning additional languages as hierarchical probabalistic
inference: Insights from L1 processing. Manuscrupt submitted for publication.
Pajk, B., & Levy, R. (2012). Distributional learning of L2
phonological categories by listeners with different language
backgrounds. In A. K. Biller, E. Y. Chung, & A. E. Kimball
(Eds.), Proceedings of the 36th Boston University Conference on Language Development (pp. 400-413). Somerville,
MA: Cascadilla Press.
Pena, M., Bonatti, L., Nespor, M., & Mehler, J. (2002). Signaldriven computations in speech processing. Science, 298,
604-607. doi:10.1126/science.1072901
Rialland, A., & Djamouri, R. (1984). Harmonie vocalique,
consonantique et structures de dependance dans le mot en
Mongol Khalkha [Vowel and consonant harmony and
dependency structure in the word in Khalkha Mongolian].
Bulletin de la Societe de Linguistique de Paris, LXXIX,
333-383.
Saffran, J., Newport, E., & Aslin, R. (1996). Word segmentation:
The role of distributional cues. Journal of Memory and
Language, 35, 606-621. doi:10.1006/jmla.1996.0032
Schwartz, B., & Eubank, L. (1996). What is the `L2 initial state'?
Second Language Research, 12, 1-5. doi:10.1177/02676583
9601200101
Selinker, L. (1969). Language transfer. General Linguistics, 9,
67-92.
Shannon, C. (1948). A mathematical theory of communication.
The Bell System Technical Journal, 27, 379-423.
doi:10.1002/j.1538-7305.1948.tb01338.x
Suomi, K., McQueen, J., & Cutler, A. (1997). Vowel harmony
and speech segmentation in Finnish. Journal of Memory and
Language, 36, 422-444. doi:10.1006/jmla.1996.2495

1047

Svantesson, J.-O., Tsendina, A., Karlsson, A., & Franzen, V.
(2005). The Phonology of Mongolian. Oxford: Oxford
University Press.
Toro, J., Nespor, M., Mehler, J., & Bonatti, L. (2008). Finding
words and rules in the speech stream: Functional differences
between vowels and consonants. Psychological Science, 19,
137-144. doi:10.1111/j.1467-9280.2008.02059.x
van der Hulst, H., & van der Weijer, J. (1995). Vowel Harmony.
In J. Goldsmith (Ed.), The handbook of phonological theory
(pp. 495-534). Oxford: Basil Blackwell.
van Heuven, W., Dijkstra, T., & Grainger, J. (1998). Orthographic neighborhood effects in bilingual word recognition.
Journal of Memory and Language, 39, 458-483.
doi:10.1006/jmla.1998.2584
Vitevitch, M., Luce, P., Charles-Luce, J., & Kemmerer, D.
(1997). Phonotactics and syllable stress: Implications for
the processing of nonsense words. Language and Speech, 40,
374-408.
Vroomen, J., Tuomainen, J., & de Gelder, B. (1998). The roles of
word stress and vowel harmony in speech segmentation.
Journal of Memory and Language, 38, 133-149.
doi:10.1006/jmla.1997.2548
Whalen, D. (1984). Subcategorical phonetc mismatches slow
phonetic judgments. Perception & Psychophysics, 35, 49-
64. doi:10.3758/BF03205924
Ziegler, J., Muneaux, M., & Grainger, J. (2003). Neighborhood
effects in auditory word recognition: Phonological competition and orthographic facilitation. Journal of Memory and
Language, 48, 779-793. doi:10.1016/S0749-596X(03)
00006-8

