Discrimination of Speech Sounds
Based Upon Temporal Envelope
Versus Fine Structure Cues in
5- to 7-Year-Old Children
Josiane Bertoncini
Willy Serniclaes
Christian Lorenzi
Centre de la Recherche
Scientifique (CNRS), Paris, France

Purpose: To investigate the capacity of young children and adults with normal
hearing to discriminate speech on the basis of either relatively slow (temporal
envelope, E) or fast (temporal fine structure, TFS) auditory cues.
Method: Vowel-consonant-vowel nonsense disyllables were processed to preserve
either the E or the TFS information in 16 adjacent frequency bands. The band signals
were then recombined and resulting stimuli were presented for discrimination to
adults or 5-, 6-, and 7-year-old children using an odd-ball paradigm. Discrimination
scores (d ) and response latencies were measured in each listener. No training was
given to listeners.
Results: Overall, discrimination scores were high (d  1) in all speech-processing
conditions, and did not differ across age groups. Overall, and irrespective of age,
greater discrimination scores and shorter response latencies were observed for
E speech than for TFS speech.
Conclusions: These results suggest that normal-hearing children are able to encode
and use E and TFS speech cues at adult levels by the age of 5 years. TFS- and E-coded
speech stimuli might therefore prove to be a useful tool for the investigation of the
developmental time course of speech perception, and for the early diagnosis of
peripheral and central auditory processing disorders.
KEY WORDS: speech temporal cues, consonant discrimination, speech perception

R

ecent studies have suggested a new dichotomy in auditory perception between so-called "temporal envelope" and "temporal fine structure" cues (e.g., Drullman, 1995; Flanagan, 1980; Smith, Delgutte,
& Oxenham, 2002; Xu & Pfingst, 2003; Zeng et al., 2004, 2005). This
dichotomy stems from the fact that acoustic signals--such as speech
sounds--contain two forms of temporal information within each frequency band: fluctuations in the envelope (E; the relatively slow variations in amplitude over time) and fluctuations in the temporal fine
structure (TFS; the rapid variations with rate close to the center frequency of the band). From a signal-processing point of view, TFS corresponds to the "carrier" signal, whereas E corresponds to an amplitude
modulator applied to the carrier.
Electrophysiological and brain-imaging studies conducted with
humans and other mammalians have found neurons in the brainstem
and the auditory cortex sensitive to these two temporal features (e.g.,
Giraud et al., 2000; Hart, Palmer, & Hall, 2003; Joris, Schreiner, & Rees,
2004; Liegeois-Chauvel, Lorenzi, Trebuchon, Regis, & Chauvel, 2004;

682

Journal of Speech, Language, and Hearing Research * Vol. 52 * 682-695 * June 2009 * D American Speech-Language-Hearing Association
1092-4388/09/5203-0682

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

Luo, Wang, Poeppel, & Simon, 2006; Palmer, 1995; Schulze
& Langner, 1997). Audiological studies have shown that
damage to the peripheral auditory system (e.g., cochlear
lesions) degrades the ability to use TFS cues but preserves the ability to use E cues (Lorenzi, Gilbert, Carn,
Garnier, & Moore, 2006). Neuropsychological studies
have shown that central damage (e.g., lesions of the primary and secondary auditory cortices) and some forms
of language disorders (aphasia, developmental dyslexia;
e.g., Fullgrabe, Maillet, Moroni, Belin, & Lorenzi, 2004;
Lorenzi, Dumont, & Fullgrabe, 2000; Lorenzi, Wable,
et al., 2000; Rocheron, Lorenzi, Fullgrabe, & Dumont,
2002) or music perception disorders (amusia; e.g., Griffiths
et al., 2000; Hescot, Lorenzi, Debruille, & Camus, 2000)
are associated with a degradation in the ability to use
E cues. It is not clear from the existing literature (e.g.,
Griffiths et al., 2000) whether central damage alters the
ability to use E cues more than TFS cues. In addition, no
double-dissociation between the ability to use E and TFS
cues has been demonstrated to date. However, taken together, these neurophysiological, audiological, and neuropsychological data suggest the existence of separate
neural structures along the auditory pathway devoted
to E and TFS processing.
A number of psychoacoustical studies have investigated the role of these two temporal features in speech
identification tasks, using several signal-processing techniques (also called vocoders) preserving the signal's E
while removing TFS and vice versa. Speech sounds were
initially split into contiguous frequency bands. E cues
alone were presented to listeners by extracting the envelope in each band and using the envelope to modulate
the amplitude of a noise band or a pure tone centered at
the frequency of the band from which the envelope was
derived (Shannon, Zeng, Kamath, Wygonski, & Ekelid,
1995; van Tasell, Soli, Kirby, & Widin, 1987). These studies showed that with a limited number of bands (4-16),
E cues can yield high levels of identification for speech
presented in quiet (Loizou, Dorman, & Tu, 1999; Shannon
et al., 1995; Smith et al., 2002). TFS cues alone were
presented to listeners by using the Hilbert transform
(Hilbert, 1912) to extract the TFS in each band (e.g.,
Smith et al., 2002). The band signals were then recombined. When the number of bands was high enough
(16) and when listeners were trained for a few hours,
TFS cues also yielded high levels of speech identification
in quiet (Gilbert & Lorenzi, 2006; Lorenzi et al., 2006).
An additional finding of these psychoacoustical studies
is that much lower identification scores were obtained
in normal-hearing listeners in the absence of TFS cues
(i.e., with E cues alone) when a background sound such
as a competing talker or a fluctuating noise was present
(Fullgrabe, Berthommier, & Lorenzi, 2006; Nelson, Jin,
Carney, & Nelson, 2003; Qin & Oxenham, 2003; Stone &
Moore, 2003; Zeng et al., 2004). This revealed that the

normal auditory system can use both E and TFS cues to
achieve perfect identification in quiet but requires TFS
cues to optimally segregate speech from background
noise. This finding was of importance for the understanding of the speech perception deficits in noise typically observed in listeners with sensorineural hearing
impairment, as cochlear lesions selectively degrade the
ability to use TFS cues (Hopkins, Moore, & Stone, 2008;
Lorenzi et al., 2006).
Although auditory abilities and speech perception
are known to mature over the first 10-12 years (e.g.,
Boothroyd, 1968; Elliott, 1979; Hnath-Chilsom, Laipply,
& Boothroyd, 1998; Siegenthaler, 1969), little work has
been done to investigate the developmental time course
of the ability to use E and TFS speech cues. The only
study conducted with children (5-12 years) using noisevocoded speech stimuli demonstrated that the ability to
use E cues in speech matures before the age of 7 years,
and becomes similar to adults' capacities around the age
of 10 years (Eisenberg, Shannon, Schaefer Martinez,
Wygonski, & Boothroyd, 2000). However, information on
the developmental time course of the ability to use TFS
cues is lacking. Furthermore, the need to investigate and
compare the developmental time course of the ability to
use E and TFS cues is reinforced by the repeated demonstration of the role of prosodic cues (rhythm and pitch)
in language acquisition (Bertoncini, Floccia, Nazzi, &
Mehler, 1995; Jusczyk, Houston, & Newsome, 1999;
Kemler Nelson, Hirsh-Pasek, Jusczyk, & Cassidy, 1989;
Nazzi, Bertoncini, & Mehler, 1998; Nazzi, Floccia, &
Bertoncini, 1998; Nazzi, Iakimova, Bertoncini, Fredonie,
& Alcantara, 2006; Nazzi, Jusczyk, & Johnson, 2000),
given that E and TFS cues seem critical for syllabic
segmentation and pitch perception, respectively (e.g.,
Greenberg & Arai, 2001; Houtgast & Steeneken, 1985;
Rosen, 1992; Smith et al., 2002; Salomon, Espy-Wilson,
& Deshmukh, 2004). Whereas most studies investigated
the role of prosodic cues in infant speech perception, data
on the "late" development of underlying auditory processes
are still needed.
The present study was designed to investigate the
capacity to discriminate between meaningless speech
stimuli in three groups of French-speaking children aged
between 5 and 7 years (either preschoolers, first-, or
second-graders) and a group of French-speaking adults.
All listeners had normal hearing. The speech stimuli
were vowel-consonant-vowel (VCV) nonsense disyllables composed of one out of five French stops (/b/, /p/, /d/,
/m/, /v/) preceded and followed by the vowel /a/ and were
either left intact or processed in order to present either E
or TFS cues only. The discrimination of four phonetic
contrasts (voicing: /b/ vs. /p/; place of articulation: /b/ vs.
/d/; nasality: /b/ vs. /m/; and manner: /b/ vs. /v/) was investigated for each type of speech processing.

Bertoncini et al.: Temporal Cues in Speech Discrimination by Children

683

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

The Visual Reinforcement Infant Speech Discrimination (VRISD; Kuhl, 1985) procedure was used to assess speech discrimination in each group of listeners.
This procedure was chosen because it appeared particularly adaptable to the present purpose for the following three reasons. First, the VRISD procedure has been
used extensively in previous studies to explore early
speech perception capacities in infants (e.g., Kuhl, 1985;
Werker et al., 1998) because it is suited to the cognitive
and linguistic capacities of young children. Indeed, this
procedure does not require any verbal response nor any
previous knowledge of the stimuli presented (for a description of this procedure used with children wearing a
cochlear implant, see Bertoncini & Berger, 2004; Dawson,
Nott, Clark, & Cowan, 1998). Secondly, many developmental studies have demonstrated that infants' and children's performance in discrimination of speech sounds
is reliably related to speech perception development (for
a review, see Jusczyk, 1997) and phonological development (Werker & Curtin, 2005). It is also important to
note that what was largely demonstrated at the level of
age groups appears to be also reliably related at the level
of individuals (Tsao, Liu, & Kuhl, 2004). Finally, two outcome measures are provided by the VRISD procedure--
namely, a measure of precision and a measure of the
participant's confidence in his/her responses. Pilot studies conducted before the current project suggest that
latencies and discrimination scores (in percent correct)
in children correlate in the same way as was regularly
observed in adults: The more difficult the task, the higher
the number of errors (misses and false alarms) and the
longer the latencies of correct responses. However, latencies might still provide a measure more sensitive
to perceptual difficulty than number of errors, at least
within age groups.

Method
Participants
Performance and response latencies were measured
on three groups of French-speaking, normally hearing
children: (a) preschoolers (kindergarten; n = 35 children): M = 5;7 [years;months], SD = 3 months; (b) first
graders (n = 45 children): M = 6;9, SD = 6 months; and
(c) second graders (n = 39 children): M = 7;8, SD =
6 months. All children had no history of auditory or language disorders. All families were informed about the
goals of the current study and provided written consent
before their children's participation. For comparison, performance and responses latencies were also measured
in strictly identical conditions on a group of 10 Frenchspeaking, young adults with normal hearing and no history of language disorders (M = 23 years, SD = 2 years).
This study was carried out in accordance with the French

684

regulations governing biomedical research and was approved by the French Regional Ethics Committee CPP Ile
de France VI (07018-ID RCB: 2007-A00343-50).

Stimuli
Speech signals were 15 VCV items (i.e., three tokens
of five /aCa/ utterances with C = /b,p,d,m,v/). These items
were selected from a set of /aCa/ repetitions, including the 16 French consonants that were produced by a
female French speaker who was instructed "to speak
clearly." These stimuli were first recorded and then
selected for their acoustic qualities. Mean duration of the
selected tokens was 581 ms for /aba/ (range: 521-621 ms),
614 ms for /apa/ (range: 533-671 ms), 582 ms for /ada/
(range: 542-613 ms), 610 ms for /ama/ (range: 594-
622 ms), and 642 ms for /ava/ (range: 639-645 ms). The
fundamental frequency of the female voice was estimated
to be 216 Hz using the YIN algorithm (de Cheveigne &
Kawahara, 2002).
Speech signals were digitized (16-bit resolution) at a
44.1-kHz sampling frequency and were band-pass filtered using zero-phase, 3rd-order Butterworth filters
into 16 adjacent 0.35-octave wide frequency bands spanning the range 80-8020 Hz. The cutoff frequencies used,
and technical details regarding stimulus generation, are
given in Gilbert and Lorenzi (2006). These band-pass
filtered signals were then processed in three ways. In the
first (referred to as "Intact"), the signals were summed
over all frequency bands. These signals contained both
TFS and E information. In the second (referred to as
"E"), the envelope was extracted in each frequency band
using the Hilbert transform followed by low-pass filtering with a zero-phase, 6th-order Butterworth filter
(cutoff frequency = 64 Hz). The filtered envelope was
used to amplitude-modulate a sine wave with a frequency equal to the center frequency of the band and
with random starting phase. The 16 amplitude-modulated
sine waves were summed over all frequency bands. These
stimuli contained only E information. In the third (referred to as "TFS"), the Hilbert transform was used to
decompose the signal in each frequency band into its E
and TFS components. The E component was discarded.
The TFS in each band was multiplied by a constant equal
to the root-mean-square (RMS) power of the band-pass
filtered signal. This was achieved to avoid giving too
much weight to potentially irrelevant TFS information
(e.g., sampling noise) in frequency channels with little
or no signal-driven energy. The "power-weighted" TFS
signals were then summed over all frequency bands. These
stimuli contained TFS information only. In all conditions,
the global RMS value of each stimulus was equalized.
All stimuli were delivered binaurally via Sennheiser
HD-580 headphones at a comfortable listening level of
75 dBA. The effects of signal processing are illustrated in

Journal of Speech, Language, and Hearing Research * Vol. 52 * 682-695 * June 2009

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

Figure 1, showing waveforms (left panels) and spectrograms (right panels) of the Intact (top panels), E-coded
(middle panels), and TFS-coded (bottom panels) /aba/
stimuli. First, spectrograms in Figure 1 clearly show
that E- and TFS-coded stimuli preserve (as specified
previously) the long-term power spectrum of the speech
stimuli. In addition, formant transitions are preserved,

to some extent, in the E-coded stimuli because of the
high-frequency resolution used by the vocoder to encode
spectral cues (i.e., 16, 0.35-octave wide bands). Waveforms in Figure 1 also show that the gross pattern of
amplitude fluctuations of the disyllables is preserved in
E-coded stimuli and absent in the TFS-coded stimuli. On
the other hand, faster fluctuations corresponding to the

Figure 1. Waveforms (left panels) and spectrograms (right panels) of intact speech (top panels), E-coded speech (middle panels), and temporal fine
structure (TFS)-coded speech (bottom panels). The original VCV is one /aba/ occurrence pronounced by a French female speaker. E = temporal envelope.

Bertoncini et al.: Temporal Cues in Speech Discrimination by Children

685

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

fundamental frequency and the formant structure are
preserved in TFS-coded stimuli.
The potential role of each temporal cue (E and TFS)
in linguistic contrasts has been explored in previous work.
In a seminal study aiming to describe temporal information in speech signals, Rosen (1992) suggested that E
information mainly cues manner (fricatives vs. plosives),
whereas TFS information mainly cues place, voicing, and
nasality. Therefore, in the present study, the discrimination of four phonetic contrasts (voicing, place of articulation, nasality, and manner) was investigated in young
children for each type of speech processing (Intact, E,
and TFS speech) in order to explore the capacity of each
temporal cue to signal important phonetic distinctions.

Procedure
The procedure was adapted from the VRISD procedure (Kuhl, 1985), which is based on infants' head-turn
responses. Here, listeners (children and adults) were
asked to press a response button as accurately and as
fast as they could when (and only when) a change occurred in a continuously repeating sequence of speech
stimuli. The listener was facing a computer screen that
displayed colored patches (background figure) while hearing a repeating background stimulus (/aba/) presented
through headphones. The listener was instructed to get
ready with his/her hands above the response button.
Each trial was launched by the experimenter when the
listener was judged ready--that is, when the listener
was looking at the background figure. The experimenter
was unaware of the kind of trial ("change" or "no change")
to be delivered. The listener had to react to the occurrence of a contrasting stimulus within the duration of the
"change" trial that included three exemplars of one of the
disyllables /apa, ada, ama, ava/. The occurrence of a response, along with its latency, was recorded from the
beginning of the trial and was thus synchronized to the
beginning of the first occurrence of the item included in
the trial, either /aba/ or one of the four contrasting items
/apa, ada, ama, ava/. The silent interstimulus interval
varied randomly in duration between 450 and 1200 ms
during the presentation of the background stimulus as
well as during the presentation of both change and no
change trials. Thus, no disruption in stimulus duration
or in silent interval duration could be used to detect a
change in the repeating stimuli during change trials.
Correct responses were reinforced by the presentation of one picture of a colorful character (award figure)
on the screen; misses (no response) or false alarms (responses during a no change trial) were followed by a
"negative" emoticon. At the end of a trial, the repeating
stimulus /aba/ was restored.
Child and adult listeners were tested individually in
a quiet room (at school and in a sound-treated room,

686

respectively). They received the three conditions (Intact,
E, and TFS) during a single session that lasted around
15 min. For all age groups, the Intact condition was
presented first, as it was used as a baseline condition.
The Intact condition was also presented first because it
was particularly simple and unambiguous for the children who were only instructed to push the button when
the sound "changes." The order of the other two conditions was counterbalanced between listeners. In each
age group, half of the participants received E stimuli
and then TFS stimuli, and the other half received the
two types of stimuli in the reverse order. The 20 change
trials (5 trials x 4 contrasting stimuli) and the 5 no
change trials were presented in random order within
each condition. Data on correctness of discrimination
and response latencies were collected.
The discrimination responses collected for each of
the four feature contrasts (voicing: /aba/-/apa/; nasality:
/aba/-/ama/; manner: /aba/-/ava/; place of articulation:
/aba/-/ada/) were converted into d scores by taking the
difference between the normal deviate (z value) corresponding to the proportion of correct change detection
(i.e., the proportion of responses delivered to the occurrence of a stimulus different from the /aba/ background)
and the proportion of false alarms (i.e., the proportion of
responses delivered in no change trials). Before conversion into z values, extreme response scores (0 and 5) were
changed into the closest nonextreme estimates (0.25 and
4.75), assuming linear interpolation on some internal
response scale (0.25 and 4.75 correspond to the midpoint
between 0 and 0.5, and 4.5 and 5, respectively). Finally,
differences between the d obtained for TFS and E speech,
respectively, and those obtained for Intact speech were
computed for each participant and each feature, providing a measure of the consequence of eliminating either
TFS or E information on speech sound discrimination
(i.e., the decline in discriminating speech sounds involving mainly either E or TFS cues).
For mean latencies, only the correct response times
were considered, with at least three correct responses
among the five trials for a given contrast. In addition,
very short response times (fewer than 150 ms) were
eliminated and were considered as irrelevant (the motor
responses being likely to having been initiated before the
beginning of the contrasting item). Differences were also
computed between latencies for TFS and E, respectively,
and latencies to Intact speech sounds. Thus, we compared
the increase in reaction times to TFS and E vs. Intact.

Results
Response Accuracy
Figure 2 presents the mean discrimination data expressed in terms of d scores for each age group and type

Journal of Speech, Language, and Hearing Research * Vol. 52 * 682-695 * June 2009

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

Figure 2. Mean discrimination data (d') for each age group--
children 5 years of age (kindergarten, dark gray bars), 6 years of age
(1st graders, black bars), and 7 years of age (2nd graders, white
bars), and 23-year-old adults (light gray bars)--presented for each
type of signal processing (Intact, E, and TFS speech). Mean d' scores
are calculated across the four phonetic contrasts tested. Error bars
indicate  1 SD of the mean.

of signal processing. Here, d scores are averaged across
phonetic contrasts and listeners within each age group.
Figure 2 shows that maximum scores are obtained for
Intact speech (d E 2.8-3.0). The d decreases from about
2.0-2.9 for E speech to about 1.3-1.6 for TFS speech.
Overall, discrimination scores are fairly high and equivalent for all age groups in both the Intact speech condition and, more surprisingly, the TFS speech condition
(d  1). It is only in the E speech condition that adult
listeners appear to be more accurate than the three
groups of children.
In order to specify these effects, differences between
the ds obtained for TFS and E speech, respectively, and
those obtained for Intact speech were computed for each
participant and each feature. Figure 3 presents the mean
d differences (E-Intact and TFS-Intact) for each age
group and each type of signal processing according to
the two different testing orders E/TFS (top panel) and
TFS/E (bottom panel).
The d differences were entered in an Age (preschoolers vs. first graders vs. second graders vs. adults) x
Phonetic Feature (voicing vs. nasality vs. manner vs.
place) x Signal Processing (E-Intact vs. TFS-Intact) x
Order (E/TFS vs.TFS/E condition) repeated measures
analysis of variance (ANOVA). The variance-covariance
equality assumption was fulfilled for Feature [Mauchly's
test: c2(2, N = 1,032) = 6.81, p = .24)]. However, as this
assumption was not fulfilled for the Signal Processing x
Feature interaction, c2(20, N = 1,032) = 19.5, p < .01,
Greenhouse-Geisser corrected univariate tests were used

Figure 3. Mean difference in discrimination score (d') for E-Intact
speech (left) and for TFS - Intact speech (right) for each age group and
for each testing order (upper panel: E speech presented first; lower
panel: TFS speech presented first). Error bars indicate  1 SD of the
mean.

for testing this interaction and the upper-order interactions in which it was included.
The ANOVA on d differences (E-Intact vs. TFS-
Intact) revealed that the following interactions were significant: Order x Signal Processing x Feature, F(3, 363) =
8.50, p < .001, h2 = .066), Order x Signal Processing,
F(1, 121) = 4.37, p < .05, h2 = .035, and Feature x Signal
Processing, F(3, 329) = 19.9, p < .001, h2 = .141. Among
the main effects, significant effects were found for Signal
Processing, F(1, 121) = 72.6, p < .001, h2 = .375, and
Feature, F(3, 363) = 10.5, p < .001, h2 = .080. When tested
separately for each order, the effect of signal processing
was significant both for the E/TFS order, F(1, 62) = 16.5,
p < .001, h2 = .210) and for the TFS/E order, F(1, 59) =
77.5, p < .001, h2 = .568. The other interactions and main
effects were not significant: Feature x Signal Processing x
Age, F(8, 330) = 1.18, p = .32, h2 = .028; Feature x Age x
Order, F(9, 363) = 1.07, p = .39, h2 = .026; Signal
Processing x Age, F(8, 330) = 1.95, p = .12, h2 = .046; Age x
Order, F(3, 121) = 1.02, p = .39, h2 = .025; Age x Signal
Processing, F(3, 121) = 1.95, p = .13, h2 = .046; Feature x
Age, F < 1; Order x Feature, F < 1; Order, F(1, 121) = 1.25,

Bertoncini et al.: Temporal Cues in Speech Discrimination by Children

687

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

p = .26, h2 = .010; Age, F(3, 121) = 1.19, p = .32, h2 = .029.
Therefore, children between 5 and 7 years of age and
young adults show a similar ability to extract and use
temporal information, and small differences in processing E speech stimuli seemed to be neutralized when
children were first exposed to TFS stimuli and then to
E speech stimuli.
In Figure 4, the results relative to the different features are presented as differences in d  scores between
(a) either E speech or TFS speech and (b) Intact speech
(E-Intact and TFS-Intact) for the two different testing
orders (E/TFS and TFS/E). All differences are negative,
indicating a general degradation in phonetic feature

Figure 4. Mean difference in discrimination score (d') for E-Intact
speech (light gray bars) and for TFS-Intact speech (black bars) for
each feature (nasality, voicing, manner, and place) and for each
order (upper panel: E speech presented first; lower panel: TFS speech
presented first). Error bars indicate  1 SD of the mean.

discrimination. However, the amount of degradation
depends on the interplay between testing order, signal
processing, and feature (Order x Signal Processing x
Feature interaction, p < .001). As can be seen in Figure 4,
the increase in degradation between E and TFS speech
is larger for manner and place than for voicing and
nasality for both orders. Indeed, the Signal Processing x
Feature interaction is significant both for the E/TFS
order, F(2, 149) = 15.4, p < .001, h2 = .199, and for the
TFS/E order, F(3, 177) = 12.9, p < .001, h2 = .180. Moreover, for both orders, the difference between TFS and
E speech is larger for manner and place than for voicing and nasality--for the E/TFS order: F(1, 61) = 30.5,
p < .001, h2 = .330; for the TFS/E order: F(1, 62) = 24.7,
p < .001, h2 = .295. And yet, although qualitatively similar in both orders, the magnitude of these differences
depends on order. The difference between TFS and E
speech is larger for all the features in the TFS/E than in
the E/TFS order, but this is more noticeable for voicing
and manner than for nasality and place. Accordingly,
when tested with Feature x Signal Processing x Order
interaction contrasts, the differences are significantly
larger for voicing and manner vs. nasality and place,
F(1, 121) = 22.2, p < .001, h2 = .155. Thus, to sum up, the
amount of degradation depends more on signal processing for manner and place than for nasality and voicing,
but these effects are differentially affected by testing
order, given that the effect of order is larger for manner
and voicing than for nasality and place.
In summary, signal processing equally affects the
accuracy of the discrimination responses for the four age
groups in this study. However, there are both quantitative and qualitative differences in the effect of signal
processing, depending on the remaining information in
the signal (i.e., TFS vs. E cues), the order of presentation
of TFS and E speech stimuli, and the phonetic feature
being discriminated. Keeping only E cues is, overall, less
deleterious for phonetic feature discrimination than keeping only TFS cues. However, the advantage of E speech
over TFS speech is lesser for voicing and nasality than
for manner and place.

Response Latencies
Differences between the response latencies obtained
for TFS and E speech, respectively, and those obtained
for Intact speech for each participant and each feature
were computed. Figure 5 presents, separately for the two
testing orders, the mean latency differences for E and
TFS speech (E-Intact and TFS-Intact) in each age group.
As can be seen in Figure 5, the latency differences between E and Intact speech are smaller in the TFS/E than
in the E/TFS order. Conversely, as found for response
accuracy, the latency differences for TFS speech are
mostly unaffected by order of presentation.

688

Journal of Speech, Language, and Hearing Research * Vol. 52 * 682-695 * June 2009

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

Figure 5. Mean difference in response latencies for E-Intact speech (left) and for TFS-Intact speech (right)
for each age group and for each order (upper panel: E speech presented first; lower panel: TFS speech
presented first). Error bars indicate  1 SD of the mean.

The latency differences were entered in an Age (preschoolers vs. first graders vs. second graders vs. adults) x
Phonetic Feature (voicing vs. nasality vs. manner vs.
place) x Signal Processing (E-Intact vs. TFS-Intact) x
Order (E/TFS vs. TFS/E) repeated measures ANOVA.
The variance-covariance equality assumption was not
fulfilled for both the Feature effect, c2(5, N = 1,032) =
11.6, p < .05, and for the Signal Processing x Feature
interaction, c2(5, N = 1,032) = 18.3, p < .01. GreenhouseGeisser corrected univariate tests were used for testing
the Feature effect, the Signal Processing x Feature interaction, and the upper-order interactions in which they
were included.

p < .01, h2 = .170. The following main effects were significant: Signal Processing, F(1, 68) = 11.8, p = .001, h2 =
.148, and Feature, F(3, 181) = 9.00, p < .001, h2 = .117.
When tested separately for each order, the effect of signal processing was not significant for the E/TFS order
(F < 1), whereas it was significant for the TFS/E order,
F(1, 33) = 17.1, p < .001, h2 = .341. The other interactions and main effects were not significant: Age x
Signal Processing x Order, F < 1; Age x Feature x Order,
F < 1; Age x Signal Processing x Feature x Order,
F(8, 171) = 1.58, p = .14, h2 = .065; Age x Signal
Processing x Feature, F < 1; Age x Feature, F < 1;
Order, F(1, 68) = 1.95, p = .17, h2 = .028; Age, F < 1).

The following interactions were significant: Feature x
Signal Processing x Order, F(3, 170) = 3.06, p < .05, h2 =
.043; Feature x Signal Processing, F(3, 171) = 18.1,
p < .001, h2 = .211; Signal Processing x Order, F(1, 68) =
10.1, p < .01, h2 = .129; Feature x Order, F(3, 181) = 4.10,
p < .01, h2 = .057; Age x Order, F(3, 68) = 3.45, p < .05,
h2 = .132; Age x Signal Processing, F(3, 68) = 4.65,

We examined the contrasts relative to the significant interactions. Concerning Age x Signal Processing,
Figure 5 shows that adults--and, to a lesser extent, kindergarten children--exhibit larger differences between
E and TFS speech than do first and second graders.
The kindergarteners versus first and second graders versus adults differences were significant: Age x Signal

Bertoncini et al.: Temporal Cues in Speech Discrimination by Children

689

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

Processing interaction contrasts--F(1, 39) = 4.53,
p < .05, h2 = .104, and F(1, 29) = 11.6, p < .01, h2 = .285,
respectively--but the difference between first graders
and second graders was not significant (F < 1). Concerning Age x Order, only the kindergarteners versus
first graders difference was significant: Age x Order interaction contrast, F(1, 39) = 6.11, p < .05, h2 = .135; the two
other pairwise contrasts between adjacent age groups
were nonsignificant (both Fs < 1).
In Figure 6, the results relative to the different features are presented as differences in latencies (E-Intact
and TFS-Intact) for the two different testing orders. All
differences are positive, indicating a general slowing
down of discrimination responses. The main dissimilarity appears between voicing and the three other features: Although latency differences are generally higher

for TFS speech than for E speech, the opposite pattern
prevails for voicing, in the E/TFS order.
As found for response accuracy, the amount of latency differences depends on the interplay between testing order, signal processing, and feature (Order x Signal
Processing x Feature interaction, p < .05). As can be seen
in Figure 6, the increase in latencies for TFS compared
with E speech is larger for manner and place and smaller
for voicing and nasality (there are even more delayed
latencies for voicing in E speech condition, in the E/FTS
order).
When tested separately for each order, the Signal
Processing x Feature interaction was significant both
for E/TFS, F(2, 105) = 14.4, p < .001, h2 = .292, and for
TFS/E, F(3, 99) = 7.66, p < .001, h2 = .188. Moreover, for
both orders, the difference between E and TFS speech

Figure 6. Mean difference in response latencies for E-Intact speech (light gray bars) and for TFS-Intact
speech (black bars) for each feature (nasality, voicing, manner, and place) and for each testing order
(upper panel: E speech presented first; lower panel: TFS speech presented first). Error bars indicate  1 SD
of the mean.

690

Journal of Speech, Language, and Hearing Research * Vol. 52 * 682-695 * June 2009

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

is larger for manner and place than for voicing and
nasality--for the E/TFS order: F(1, 35) = 22.8, p < .001,
h2 = .405; for the TFS/E order: F(1, 33) = 14.0, p = .001,
h2 = .298. However, although qualitatively similar in
both orders, the magnitude of these differences depends
on order. The difference between TFS and E speech is
larger for all the features in the TFS/E than in the E/TFS
order, but this is more noticeable for voicing and manner
than for nasality and place. Accordingly, when tested
with Feature x Signal Processing x Order interaction
contrasts, these changes are significantly larger for voicing and manner versus nasality and place, F(1, 68) = 9.57,
p < .01, h2 = .123. To sum up, the increase in latencies for
TFS compared with E speech is larger for manner and
place than for nasality and voicing, but these effects are
differentially affected by the testing order, given that the
effect of order is larger for manner and voicing than for
nasality and place.

Interim Discussion

reach comparable discrimination scores for TFS speech
signals, suggesting that such a masking or distracting
phenomenon has similar effects on all groups of listeners. This is consistent with previous work showing
that background noise fluctuating periodically in amplitude at various rates (4, 32, and 128 Hz) produces
similar masking effects on syllable identification performance in normal-hearing children (8-13 years) and adults
(Fullgrabe et al., 2006; Ziegler, Pech-Georgel, George,
Alario, & Lorenzi, 2005). Secondly, Ghitza (2001) demonstrated that despite filtering or removal, E cues are
reconstructed at the output of peripheral (i.e., cochlear)
auditory filters in response to TFS speech signals and
may, therefore, be used by listeners. E reconstruction is
consequent to the fact that TFS and E information are
correlated. Involvement of E reconstruction in speech
identification has been empirically confirmed using either
sentences (Zeng et al., 2004) or VCV stimuli (Gilbert &
Lorenzi, 2006). In these studies, TFS signals were derived from the broadband speech signals. Envelopes
reconstructed at the output of a bank of gammachirp
auditory filters (Irino & Patterson, 1997) were then used
to amplitude-modulate either noise bands or pure tones
at the center frequency of the auditory filters. In agreement with Ghitza's (2001) predictions, the processedspeech stimuli were intelligible with 40%-60% mean
correct identification. Gilbert and Lorenzi (2006) also
showed that the reconstructed E cues did not play a
major role in consonant identification once the analysis
bandwidth of the TFS vocoder was narrower than four
times the bandwidth of a normal auditory filter (as in
the current study where 16, 2-ERBN-wide analysis filters were used to encode stimuli). Nevertheless, Gilbert
and Lorenzi's (2006) results were obtained for a speech
identification task. Therefore, it remains possible that,
despite the use of a 16-band TFS vocoder, reconstructed
E cues at the output of cochlear filters may have influenced the discrimination capacities of adults and children for TFS speech in the current study.

The current study indicates that children and adults
reach high and comparable discrimination scores for
TFS speech signals. However, potential artifacts may
have influenced these discrimination data for TFS speech.
First, signal processing used to generate TFS-coded speech
is equivalent to multiband compression with an infinite
compression ratio; whatever the original amplitude in a
given frequency band, the output amplitude is the same.
As a consequence, even very low-level recording noise
is amplified to the same level as the speech in that band,
so that frequency bands with no speech information at a
given time are filled with distracting noise. This may
pose a particular problem for discriminating the TFScoded speech stimuli to children and adult listeners who
may suffer from masking between frequency bands.
However, the current data show that children and adults

In a control experiment, an approach similar to that
used by Gilbert and Lorenzi (2006) was used to assess
the capacity of adult listeners to discriminate stimuli on
the basis of such putatively reconstructed E cues. The
TFS-coded signals used in the previous experiment were
passed through a bank of 30 gammachirp auditory filters, each 1-ERBN wide (Irino & Patterson, 1997), with
center frequencies ranging from 123 to 7743 Hz, and
spaced along an ERBN scale. In each band, the temporal
envelopes were extracted using the Hilbert transform
and low-pass filtered (cutoff frequency = 64 Hz, 72 dB/
octave rolloff ) using a Butterworth filter (forward and
backward filtering were used). These envelopes were then
used to amplitude-modulate sine waves having the same
frequencies as the original center frequencies of the
auditory filters but with random starting phase. The

In summary, keeping only E information (i.e., removing TFS cues) is less deleterious for response latency
overall than keeping only TFS information (i.e., removing E cues), as was also found for response accuracy.
Irrespective of the age group, the effect of signal processing on response latencies also depended on the feature to be discriminated. Discrimination responses are
more delayed for the voicing and nasality features than
for the others when only E information is kept in the
signal--again, as found for response accuracy. Conversely, reception of both manner and place features
is more affected than reception of nasality and voicing
when only TFS information is available. Importantly,
these results do not reveal any systematic variation
between children's and adults' latency differences in
either E or TFS vs. Intact speech comparison (Age x
Signal Processing x Order nonsignificant interaction).

Bertoncini et al.: Temporal Cues in Speech Discrimination by Children

691

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

30 modulated tones were finally summed over all frequency bands to produce so-called "RE-coded" (for reconstructed envelope) stimuli.
These RE-coded stimuli were, therefore, used to force
listeners to discriminate consonants primarily on the
basis of the reconstructed envelope cues. A new group of
11 French-speaking, young adults with normal hearing
and no history of language disorders (M = 23 years,
SD = 1 year) participated in this control experiment
conducted with the previous set of Intact, E-, and TFScoded VCV stimuli and the new set of RE-coded stimuli.
Apparatus, procedure, and presentation level were identical to those described in the previous experiment except that the number of change trials in the Intact, E,
and TFS conditions was reduced to 4, 12, and 12, respectively. However, the number of change trials in the
RE condition was identical to that used in the main experiment (i.e., 20 trials). In all signal-processing conditions,
the global RMS value of each stimulus was equalized.
Listeners were tested in the following order of processing conditions: Intact, E, TFS, and RE. Again, d  scores
were averaged across phonetic contrasts and listeners.
Discrimination scores (d ) were 3.07 (SD = 0) for Intact
speech, 2.93 (SD = 0.47) for E speech, 1.98 (SD = 1.07) for
TFS speech, and 0.29 (SD = 0.73) for RE speech. The
score for RE speech was significantly lower than the
one obtained for TFS speech: student t test, t(10) = 4.51,
p = .0001. The extremely poor discrimination score obtained for RE speech suggests strongly that reconstructed
E cues at the output of cochlear filters did not contribute
to the ability of children and adults to discriminate TFS
speech items in the previous experiment.

General Discussion
Overall, the results of the present study reveal robust and adultlike discrimination of consonants based
on temporal cues in normal-hearing children aged between 5 and 7 years. Irrespective of age, discrimination
is fairly good for each type of degradation applied to the
VCV signals (i.e., degradation of either temporal envelope or TFS speech cues). However, discrimination is
better when based on envelope cues compared with fine
structure cues, although the difference is not always
significant. When tested separately for each order, the
difference in d  between envelope and fine structure
stimuli was significant for each order. However, the
difference in latency between envelope and fine structure stimuli was only significant when the latter were
presented first. There are also qualitative differences
between the results obtained for the two kinds of degradation as a function of features to be discriminated.
Although consonant discrimination appears to be less
degraded with E than with TFS cues, this advantage of

692

E over TFS cues is larger for manner and place than for
voicing and nasality.
The patterns of information reception reported here
are globally consistent with previous work on adults.
Previous studies showed that E cues yielded higher
level of speech perception in quiet than did TFS speech
in the absence of training (see the introduction; Lorenzi
et al., 2006). Voicing and place information are conveyed
by E and TFS cues, respectively, as would be anticipated
from acoustic and phonetic considerations in Rosen's
(1992) descriptive study. We found poorer discrimination of voicing than for the other features with E speech
and better discrimination of voicing and nasality than
for other features with TFS speech. The lower reception
of voicing information in the E speech condition is consistent with the fact that one of the main cues signaling
voicing--namely, the presence of energy at fundamental frequency at voice onset (Haggard, Amber, & Callow,
1970; Haggard, Summerfield, & Roberts, 1981; Serniclaes,
1987)--is missing in E-coded speech stimuli. The ordering of feature reception in the TFS speech condition
(nasality > voicing > manner = place) is reminiscent
of the ordering of feature reception in masking noise
(Miller & Nicely, 1955). This pattern of information
reception may, therefore, reflect general aspects of robustness of phonetic cues signaled by TFS cues.
Previous studies conducted with normal-hearing
adults (e.g., Gilbert & Lorenzi, 2006; Lorenzi et al., 2006)
showed that nearly perfect identification could be obtained for each type of signal processing (i.e., for both
E and TFS speech) after training. However, the better
ability to use envelope cues than fine structure cues
reported here is not surprising, given that participants
were not given any specific training before performing
the discrimination tasks. Indeed, previous work indicates that a (much) longer training period is required for
TFS speech than for E speech to reach similar high levels
of identification (e.g., Lorenzi et al., 2006). In the present
study, adults were performing very well with E speech
stimuli in both testing orders, whereas children performed
better when E speech was presented after TFS speech
than in the reverse order (although only the kindergarten children's vs. adults' differences in response latencies
were significant). This could be taken as an indication
that even a short exposure (less than 5 min) to unfamiliar degraded sounds allows children to improve their
processing of E speech in both accuracy and latencies
in discrimination tasks. As children seem to reliably
benefit from such a very short experience with degraded
speech sounds, it would be of interest to test whether the
time necessary to improve in TFS reception is a function
of age. It seems likely that the ability to discriminate
TFS speech may be improved in our normal-hearing
children were they given a few hours of training with the
present stimuli.

Journal of Speech, Language, and Hearing Research * Vol. 52 * 682-695 * June 2009

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

Although children and adults' performance with
TFS speech was lower than with E speech, we conducted
a control experiment to check whether some reconstructed envelope cues could have contributed to the
relatively good level of adults' discrimination and/or to
the improvement of children performance with E speech
when tested after TFS speech. A control experiment conducted with adults demonstrated that this possibility is
very unlikely. Further experiments are needed to determine which characteristic of even such a short exposure with TFS speech sounds could have enhanced
children's ability to process E cues.
The comparison between adult and children listeners did indeed reveal some subtle effects of the order
of presentation of E and TFS conditions in children's
performance only. However, the absence of a main effect
of age is also a good indication that the capacity to process temporal information is adultlike in the 5- to 7-yearold-children. This result is not inconsistent with the
results of Eisenberg et al.'s (2000) study obtained with
a noise-excited band vocoder: Indeed, Eisenberg et al.
(2000) showed that speech (e.g., sentences, words, and
nonsense syllables) identification based on temporal
envelope cues improves before the age of 10 when spectral resolution is limited (i.e., when the number of frequency bands used to encode speech is lower than eight)
but is already at adult level when spectral resolution
approaches that of the normal auditory system (i.e.,
16 bands or more, as in the present study). In addition,
the observed consistency between accuracy and latencies in all groups of children suggests that response
latencies could be reliably used to reveal differences (at
least within age groups) in the difficulty of perceptual
tasks.
This general finding is important, as it suggests that
temporal auditory mechanisms involved in the perception of phonetic features, shown to be crucial for language acquisition in previous psycholinguistic studies
on infants (Bertoncini et al., 1995; Jusczyk et al., 1999;
Kemler Nelson et al., 1989; Nazzi, Bertoncini, & Mehler,
1998; Nazzi, Floccia, & Bertoncini, 1998; Nazzi et al.,
2000, 2006), are fully developed by 5 years of age. Further experiments will be necessary to determine whether
phonetic discrimination is similarly possible in younger
children and infants with either E or TFS speech.
High levels of discrimination were obtained for E
and TFS speech without any training. This observation is important because it opens the possibility of
developing new tests for the early screening of speech
discrimination--and, more generally, auditory discrimination capacities relevant to speech perception--in
children between 5 and 7 years of age. Previous work
indicates that in adults, cochlear lesions abolish the ability to encode and/or use TFS cues while preserving the

ability to encode and/or use E cues (e.g., Lorenzi et al.,
2006). Impaired perception of E cues has been reported
repeatedly in the case of central damage to the auditory
system and specific language acquisition disorders (e.g.,
Lorenzi, Dumont, & Fullgrabe, 2000; Lorenzi, Wable,
et al., 2000). The current framework, and further possible adaptations for 3- to 4-year-olds, may therefore prove
to be extremely useful for the diagnosis of peripheral or
central auditory processing disorders in young children.

References
Bertoncini, J., & Berger, B. (2004). Assessing speech perception capacities in young children with cochlear implants: A
psycholinguistic approach. International Congress Series,
1273, 296-299.
Bertoncini, J., Floccia, C., Nazzi, T., & Mehler, J. (1995).
Morae and syllables: Rhythmical basis of speech representation in neonates. Language and Speech, 38, 311-329.
Boothroyd, A. (1968). Developments in speech audiometry.
Sound, 3, 3-10.
Dawson, P. W., Nott, P. E., Clark, G. M., & Cowan, R. S. C.
(1998). A modification of Play Audiometry to assess speech
discrimination ability in severe-profoundly deaf 2- to 4-yearold children. Ear and Hearing, 19, 371-384.
de Cheveigne, A., & Kawahara, H. (2002). YIN, a fundamental frequency estimator for speech and music. The Journal
of the Acoustical Society of America, 111, 1917-1930.
Drullman, R. (1995). Temporal envelope and fine structure
cues for speech intelligibility. The Journal of the Acoustical
Society of America, 97, 585-592.
Eisenberg, L. S., Shannon, R. V., Schaefer Martinez, A.,
Wygonski, J., & Boothroyd, A. (2000). Speech recognition
with reduced spectral cues as a function of age. The Journal
of the Acoustical Society of America, 107, 2704-2710.
Elliott, L. L. (1979). Performance of children aged 9 to 17 years
on a test of speech intelligibility in noise using sentence
material with controlled predictability. The Journal of the
Acoustical Society of America, 66, 651-653.
Flanagan, J. L. (1980). Parametric coding of speech spectra.
The Journal of the Acoustical Society of America, 68, 412-419.
Fullgrabe, C., Berthommier, F., & Lorenzi, C. (2006). Masking release for consonant features in temporally fluctuating
background noise. Hearing Research, 211, 74-84.
Fullgrabe, C., Maillet, D., Moroni, C., Belin, C., & Lorenzi,
C. (2004). Detection of 1st- and 2nd-order temporal envelope
cues in a patient with left brain damage. NeuroCase, 10,
189-197.
Ghitza, O. (2001). On the upper cutoff frequency of the auditory critical-band envelope detectors in the context of speech
perception. The Journal of the Acoustical Society of America,
110, 1628-1640.
Gilbert, G., & Lorenzi, C. (2006). The ability of listeners to
use recovered envelope cues from speech fine structure. The
Journal of the Acoustical Society of America, 119, 2438-2444.
Giraud, A. L., Lorenzi, C., Ashburner, J., Wable, J.,
Johnsrude, I., Frackowiak, R., & Kleinschmidt, A. (2000).

Bertoncini et al.: Temporal Cues in Speech Discrimination by Children

693

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

Representation of the temporal envelope of sounds in the
human brain. Journal of Neurophysiology, 84, 1588-1598.
Greenberg, S., & Arai, T. (2001). The relation between
speech intelligibility and the complex modulation spectrum.
In Proceedings of the 7th Eurospeech Conference on Speech
Communication and Technology (pp. 473-476).
Griffiths, T. D., Penhune, V., Peretz, I., Dean, J. L.,
Patterson, R. D., & Green, G. G. (2000). Frontal processing and auditory perception. Neuroreport, 7, 919-922.
Haggard, M., Amber, S., & Callow, M. (1970). Pitch as a
voicing cue. The Journal of the Acoustical Society of America,
47, 613-617.
Haggard, M., Summerfield, Q., & Roberts, M. (1981). Psychoacoustical and cultural determinants of phoneme boundaries: Evidence from trading F0 cues in the voiced-voiceless
distinction. Journal of Phonetics, 9, 49-62.
Hart, H. C., Palmer, A. R., & Hall, D. A. (2003). Amplitude
and frequency-modulated stimuli activate common regions
of human auditory cortex. Cerebral Cortex, 13, 773-781.
Hescot, F., Lorenzi, C., Debruille, X., & Camus, J. F. (2000).
Amplitude-modulation detection for broadband noise in a
single listener with left-hemisphere damage. British Journal
of Audiology, 34, 341-551.
Hilbert, D. (1912). Grundzuge einer allgemeinen theorie der
linearen integralgleichungen [Fundamentals of a general
theory of the linear integral equations]. Leipzig, Germany:
Teubner.
Hnath-Chilsom, T. E., Laipply, E., & Boothroyd, A. (1998).
Age-related changes on a children's test of sensory-level
speech perception capacity. Journal of Speech, Language,
and Hearing Research, 41, 94-106.
Hopkins, K., Moore, B. C. J., & Stone, M. A. (2008). Effects
of moderate cochlear hearing loss on the ability to benefit
from temporal fine structure information in speech. The
Journal of the Acoustical Society of America, 123, 1140-1153.
Houtgast, T., & Steeneken, H. J. M. (1985). A review of the
MTF concept in room acoustics and its use for estimating
speech intelligibility in auditoria. The Journal of the Acoustical Society of America, 77, 1069-1077.
Irino, T., & Patterson, R. D. (1997). A time domain, level
dependent auditory filter: The gammachirp. The Journal
of the Acoustical Society of America, 101, 412-419.
Joris, P. X., Schreiner, C. E., & Rees, A. (2004). Neural
processing of amplitude modulated sounds. Physiological
Review, 84, 541-577.
Jusczyk, P. W. (1997). The discovery of spoken language.
Cambridge, MA: MIT Press.
Jusczyk, P. W., Houston, D. M., & Newsome, M. (1999). The
beginnings of word segmentation in English-learning infants.
Cognitive Psychology, 39, 159-207.
Kemler Nelson, D. G., Hirsh-Pasek, K., Jusczyk, P. W., &
Cassidy, K. W. (1989). How the prosodic cues in motherese
might assist language learning. Journal of Child Language,
16, 55-68.
Kuhl, P. K. (1985). Methods in the study of infant speech perception. In G. Gottlieb & N. A. Krasnegor (Eds.), Measurement of audition and vision in the first year of postnatal life:
Amethodological overview (pp. 223-251). Norwood, NJ: Ablex.
Liegeois-Chauvel, C., Lorenzi, C., Trebuchon, A., Regis,
J., & Chauvel, P. (2004). Temporal envelope processing in

694

the human left and right auditory cortices. Cerebral Cortex,
14, 731-740.
Loizou, P. C., Dorman, M., & Tu, Z. (1999). On the number
of channels needed to understand speech. The Journal of
the Acoustical Society of America, 106, 2097-2103.
Lorenzi, C., Dumont, A., & Fullgrabe, C. (2000). Use of
temporal envelope cues by developmental dyslexics. Journal
of Speech, Language, and Hearing Research, 43, 1367-1379.
Lorenzi, C., Gilbert, G., Carn, H., Garnier, S., & Moore,
B. C. J. (2006). Speech perception problems of the hearing
impaired reflect inability to use temporal fine structure.
Proceedings of the National Academy of Sciences, USA, 103,
18866-18869.
Lorenzi, C., Wable, J., Moroni, C., Derobert, C., Frachet,
B., & Belin, C. (2000). Auditory temporal envelope processing in a patient with left-hemisphere damage. Neurocase,
6, 231-244.
Luo, H., Wang, Y., Poeppel, D., & Simon, J. Z. (2006). Concurrent encoding of frequency and amplitude modulation in
human auditory cortex: MEG evidence. Journal of Neurophysiology, 96, 2712-2723.
Miller, G. A., & Nicely, P. E. (1955). Analysis of perceptual
confusions among some English consonants. The Journal
of the Acoustical Society of America, 27, 338-352.
Nazzi, T., Bertoncini, J., & Mehler, J. (1998). Language
discrimination by newborns: Towards an understanding of
the role of rhythm. Journal of Experimental Psychology:
Human Perception and Performance, 24, 756-766.
Nazzi, T., Floccia, C., & Bertoncini, J. (1998). Discrimination of pitch contours by neonates. Infant Behavior and
Development, 21, 779-784.
Nazzi, T., Iakimova, I., Bertoncini, J., Fredonie, S., &
Alcantara, C. (2006). Early segmentation of fluent speech
by infants acquiring French: Emerging evidence for crosslinguistic differences. Journal of Memory and Language,
54, 283-299.
Nazzi, T., Jusczyk, P. W., & Johnson, E. K. (2000). Language
discrimination by English learning 5-month-olds: Effects of
rhythm and familiarity. Journal of Memory and Language,
43, 1-19.
Nelson, P. B., Jin, S.-H., Carney, A. E., & Nelson, D. A.
(2003). Understanding speech in modulated interference:
Cochlear implant users and normal-hearing listeners.
The Journal of the Acoustical Society of America, 113,
961-968.
Palmer, A. (1995). Neural signal processing. In B. C. J. Moore
(Ed.), Hearing: Handbook of perception and cognition
(pp. 75-113). San Diego, CA: Academic Press.
Qin, M. K., & Oxenham, A. J. (2003). Effects of simulated
cochlear-implant processing on speech reception in fluctuating maskers. The Journal of the Acoustical Society of
America, 114, 446-454.
Rocheron, I., Lorenzi, C., Fullgrabe, C., & Dumont, A.
(2002). Temporal envelope perception in dyslexic children.
Neuroreport, 13, 1683-1687.
Rosen, S. (1992). Temporal information in speech: Acoustic,
auditory, and linguistic aspects. Philosophical Transactions
of the Royal Society of London, Series B, 336, 367-373.
Salomon, A., Espy-Wilson, C. Y., & Deshmukh, O. (2004).
Detection of speech landmarks: Use of temporal information.

Journal of Speech, Language, and Hearing Research * Vol. 52 * 682-695 * June 2009

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

The Journal of the Acoustical Society of America, 115,
1296-1305.
Schulze, H., & Langner, G. (1997). Periodicity coding in the
primary auditory cortex of the Mongolian gerbil (Meriones
unguiclatus): Two different coding strategies for pitch and
rythm? Journal of Comparative Physiology, 181, 651-663.
Serniclaes, W. (1987). Etude experimentale de la perception
du trait de voisement des occlusives du fran0ais [Experimental study of the perception of the voicing feature in
French stop consonants]. Unpublished doctoral thesis,
Universite Libre de Bruxelles.
Shannon, R., Zeng, F.-G., Kamath, V., Wygonski, J., &
Ekelid, M. (1995, October 13). Speech recognition with primarily temporal cues. Science, 270, pp. 303-304.
Siegenthaler, B. M. (1969). Maturation of auditory abilities
in children. International Audiology, 8, 59-71.
Smith, Z. M., Delgutte, B., & Oxenham, A. J. (2002, March 7).
Chimaeric sounds reveal dichotomies in auditory perception. Nature, 416, pp. 87-90.
Stone, M. A., & Moore, B. C. J. (2003). Effect of the speed of a
single-channel dynamic range compressor on intelligibility
in a competing speech task. The Journal of the Acoustical
Society of America, 114, 1023-1034.
Tsao, F. M., Liu, H. M., & Kuhl, P. K. (2004). Speech perception in infancy predicts language development in the second
year of life: A longitudinal study. Child Development, 75,
1067-1084.
van Tasell, D., Soli, S. D., Kirby, V. M., & Widin, G. P.
(1987). Speech waveform envelope cues for consonant recognition. The Journal of the Acoustical Society of America, 82,
1152-1161.
Werker, J. F., & Curtin, S. (2005). PRIMIR: A developmental
framework on infant speech processing. Language Learning
and Development, 1, 197-234.

Werker, J. F., Shi, R., Desjardins, R., Pegg, J., Polka, L., &
Patterson, M. (1998). Three methods for testing infant
speech perception. In A. Slater (Ed.), Perceptual development: Visual, auditory, and speech perception in infancy.
East Sussex, United Kingdom: Psychology Press.
Xu, L., & Pfingst, B. E. (2003). Relative importance of temporal envelope and fine structure in lexical-tone perception. The Journal of the Acoustical Society of America, 114,
3024-3027.
Zeng, F. G., Nie, K., Liu, S., Stickney, G., Del Rio, E., Kong,
Y. Y., & Chen, H. (2004). On the dichotomy in the auditory
perception between temporal envelope and fine structure
cues. The Journal of the Acoustical Society of America, 116,
1351-1354.
Zeng, F. G., Nie, K., Stickney, G. S., Kong, Y. Y., Vongphoe,
M., Bhargave, A., Wei, C., & Cao, K. (2005). Speech recognition with amplitude and frequency modulations. Proceedings of the National Academy of Sciences, USA, 102,
2293-2298.
Ziegler, J. C., Pech-Georgel, C., George, F., Alario, F.-X.,
& Lorenzi, C. (2005). Deficits in speech perception predict
language learning impairment. Proceedings of the National
Academy of Sciences, USA, 102, 14110-14115.
Received December 18, 2007
Revision received June 11, 2008
Accepted September 30, 2008
DOI: 10.1044/1092-4388(2008/07-0273)
Contact author: Josiane Bertoncini, LPP CNRS, Universite
Paris Descartes, 45 rue des Saints Peres, 75006 Paris,
France. E-mail: josiane.bertoncini@parisdescartes.fr.

Bertoncini et al.: Temporal Cues in Speech Discrimination by Children

695

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

