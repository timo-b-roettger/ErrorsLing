Short-Term Word-Learning Rate in
Children With Normal Hearing and
Children With Hearing Loss
in Limited and Extended
High-Frequency Bandwidths
Andrea L. Pittman
Arizona State University, Tempe

Purpose: This study examined children's word learning in limited and extended
high-frequency bandwidth conditions. These conditions represent typical listening
environments for children with hearing loss (HL) and children with normal hearing
(NH), respectively.
Method: Thirty-six children with NH and 14 children with moderate-to-severe HL
served as participants. All of the children were between 8 and 10 years of age and
were assigned to either the limited or the extended bandwidth conditions. Five nonsense
words were paired with 5 novel pictures. Word learning was assessed in a single
session, multitrial, learning paradigm lasting approximately 15 min. Learning rate was
defined as the number of exposures necessary to achieve 70% correct performance.
Results: Analysis of variance revealed a significant main effect for bandwidth but not
for group. A Bandwidth x Group interaction was also not observed. In this short-term
learning paradigm, the children in both groups required 3 times as many exposures
to learn each new word in the limited bandwidth condition compared with the extended
bandwidth condition.
Conclusion: These results suggest that children with HL may benefit from extended
high-frequency amplification when learning new words and for other long-term
auditory processes.
KEY WORDS: word learning, children, normal hearing, hearing loss, bandwidth

I

t is estimated that by the time a child graduates from high school, he
or she will have acquired an understanding of more than 60,000 words.
To achieve a vocabulary of this size, the child must learn multiple words
per day throughout childhood (see Bloom, 2000, for a review). The immediate benefits of a well-developed vocabulary allow a child to learn to read
comprehensively, write meaningfully, and speak effectively. The long-term
benefits are apparent in the child's ability to communicate, socialize, and
achieve academically and vocationally. Unfortunately, vocabulary development in children with hearing loss (HL) is often delayed and appears
to be related to the child's degree of HL (Blamey et al., 2001; Boothroyd
& Boothroyd-Turner, 2002; Davis, Elfenbein, Schum, & Bentler, 1986;
Lederberg, Prezbindowski, & Spencer, 2000; Pittman, Lewis, Hoover, &
Stelmachowicz, 2005). Although children with language impairment (LI)
also share similarly underdeveloped vocabularies, the underlying cause

Journal of Speech, Language, and Hearing Research * Vol. 51 * 785-797 * June 2008 * D American Speech-Language-Hearing Association

785

1092-4388/08/5103-0785

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/09/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

may differ from that of children with HL. Specifically,
children with LI may employ inefficient word-learning
strategies, whereas children with HL may have difficulty
learning new words because of a degraded auditory signal.
These two groups also experience difficulty with phonological processing, which may be related to their ability
to learn new words (Briscoe, Bishop, & Norbury, 2001;
Hansson, Forsberg, Lofqvist, Maki-Torkko, & Sahlen,
2004). Briscoe et al. (2001) compared the phonological,
language, and literacy skills of 5- to 10-year-old children
with HL with those of children with normal hearing (NH)
and with children with LI. Their intent was to characterize the language skills of these children and to determine
the impact of phonological processing difficulties on those
skills. Their results revealed a significant relation between phonological processing and language in children
with LI but not in children with HL. Specifically, the
children with LI performed at levels significantly below
that of their age- and vocabulary-matched peers on all
but one measure (nonverbal reasoning). The children
with HL, on the other hand, performed as well as the
typically developing children on measures of nonverbal
reasoning, receptive vocabulary, grammar, working memory, literacy, and digit span. The only exception was for
children with greater HLs who were found to have poorer
phonological skills than the normally hearing, typically
developing children. When the language and literacy
skills of these children were evaluated, the only significant effect of phonological impairment appeared to
involve vocabulary knowledge. The authors concluded
that poor phonological skills in children with HL are not
necessarily associated with comprehensive LI but may
have an impact on word learning.
To better understand the association between phonological processing and word learning, Gilbertson and
Kamhi (1995) examined word learning in 20 children
with HL between the ages of 7 and 10 years relative to
children with NH who were matched for receptive language. They theorized that word learning in children with
HL is related more to their ability to encode, store, and
retrieve phonemic information than to the level of residual hearing. Four nonsense words differing in phonemic
content and syllable length (tam, jaften, gadakik, and
shabiffidy) were presented orally to each child and paired
with a specific novel object. The child's ability to recognize, produce, and retain each word was measured. In
addition, the child's performance on a number of phonological processing tasks (i.e., word repetition, rapid labeling) was measured. The children with HL wore their
personal amplification devices (e.g., hearing aids, FM systems) during testing. The results revealed no significant
differences between the groups for any of the phonological
processing tasks or for recognition of the nonsense words.
However, the children with HL required significantly

786

more repetitions of the nonsense words "jaften" and
"shabiffidy" to produce them accurately. Further, analyses revealed a bimodal distribution in which half of the
children with HL required significantly more repetitions of the nonsense words than the children with NH,
whereas half did not. From this, the authors concluded
that some children with HL may have significant LI that
may be obscured and possibly complicated by the presence of HL.
However, studies (such as those described above)
often do not control for the quality of the signal received
by the children with HL. Instead, they rely on the child's
personal amplification devices (hearing aids) or FM systems to provide an adequate speech signal during testing.
Because phonological tasks, such as those used in Briscoe
et al.'s (2001) and Gilbertson and Kamhi's (1995) studies,
depend heavily on the child's ability to perceive the full
acoustic content of the speech signal, it is possible that
limitations in the children's personal hearing aids contributed to the phonological problems demonstrated by
these children. For example, the children with HL in
Gilbertson and Kamhi's study may have required more
exposures to the nonsense words "jaften" and "shabiffidy"
because hearing aids do not amplify the high-frequency
fricatives well. Instead, the children may have required
repeated attempts to produce these nonsense words as
they searched for the correct acoustic phonetic content.
The effective bandwidth of most commercially available hearing aids is approximately 0.3-5.0 kHz, which is
comparable with the bandwidth of a home telephone. It
is often the case that proper names or unfamiliar terms
must be spelled out over the telephone because of the
ambiguity imposed by the restricted bandwidth. Also,
the letters of an unfamiliar name or term are often associated with common names to avoid confusion with other
letters having the same acoustic characteristics (e.g., T
as in Tom, F as in Frank). Adult listeners appear to tolerate well the reduced spectral information provided by
the telephone (and hearing aids) probably because very
little information is new to them. Children, on the other
hand, are bombarded with new information throughout
childhood and into adolescence. Therefore, an ambiguous signal provided by hearing aids may reduce their
ability to perceive speech as accurately as adults or their
peers with normal hearing.
Several studies in children confirm the value of highfrequency information for perception, production, and
clarity of speech. Stelmachowicz, Pittman, Hoover, and
Lewis (2001, 2002) studied perception of the phoneme /s/
as a function of bandwidth. They reported systematic
improvements in the performance of children with NH
and children with HL as the bandwidth of the signal
increased up to the 9-kHz bandwidth limit of the test
protocol. In a later study, these investigators reported a
distinct delay in the production of fricatives in a group

Journal of Speech, Language, and Hearing Research * Vol. 51 * 785-797 * June 2008

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/09/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

of young children with HL who were aided within the
1st year of life compared with their peers with normal
hearing (Stelmachowicz, Pittman, Hoover, Lewis, &
Moeller, 2004). Because the delay was restricted to the
fricative class only, the authors theorized that the children received an ambiguous representation of fricatives
via the limited bandwidth of their hearing aids. That
is, the limited bandwidth made fricatives difficult to
distinguish from one another. This notion is supported
by the results of Kortekaas and Stelmachowicz (2000),
who reported that 5- to 10-year-old children with NH
required a wider bandwidth than adults to rate the
phoneme /s/ as being clear. The results of these studies
suggest that, unlike adults, children benefit from extended frequency bandwidths regardless of hearing
status.
Although the immediate effect of a reduced bandwidth appears to be limited to the perception and production of certain phonemes (fricatives), it is important
to recall that speech perception and production are only
part of a child's communication development. Over the
long term, children use these skills to increase their
knowledge and understanding of the world. That is,
whereas adults use their hearing to continue to communicate, children use their hearing to learn to communicate. Therefore, the value of an extended high-frequency
bandwidth may be equally important for long-term auditory processes, such as word learning, that promote the
development of communication.

Word Learning
Experimental paradigms for word learning typically
include a period in which the child is introduced to new
words through direct labeling or indirectly in the form of
a story or reference. Lederberg et al. (2000) have distinguished these two types of word-learning paradigms
as either rapid word learning (i.e., fast mapping), in
which the child is given an explicit reference for the new
word, or novel mapping (i.e., quick incidental learning),
in which the child is expected to make the connection
between the new word and the unfamiliar object without
assistance. In either paradigm, the words may be real,
but unknown to the child, or nonsense words with a specific phonemic content. After a predetermined number of
exposures, the child is tested to determine the degree to
which he/she was able to learn the new words under the
conditions imposed in the experiment. Although these
paradigms may not represent exactly the process by
which children learn words in their natural environment,
they provide valuable information about factors that
may affect word learning. To date, several factors have
been identified and include age, receptive vocabulary,
working memory, hearing level, number of exposures,

phonemic awareness, phonotactic probability,1 and
others (Gilbertson & Kamhi, 1995; Hansson et al., 2004;
Lederberg et al., 2000; Oetting, Rice, & Swank, 1995;
Pittman et al., 2005; Rice, Buhr, & Nemeth, 1990; Rice,
Oetting, Marquis, Bode, & Pae, 1994; Stelmachowicz,
Pittman, Hoover, & Lewis, 2004). Although all of these
factors are accounted for in the present study, the effects
of phonemic awareness, current receptive vocabulary,
and hearing level are particularly relevant.
Storkel (2001, 2003) demonstrated the importance
of the acoustic phonetic content of novel words when she
investigated word learning in 3- to 6-year-old children.
She carefully controlled the phonemic content of the novel
words (nouns and verbs) so that the influence of phonotactic probability could be determined. The results suggested that the children's ability to learn words was
influenced more by the acoustic-phonetic content of the
word than by the grammatical function of the word. In
addition, word learning was greater for words containing more commonly occurring phonemes. Because the
acoustic-phonetic content of a word has a strong effect
on learning, it is possible that a reduced bandwidth
may affect the perception of phonemes and, therefore,
learning.
Stelmachowicz, Pittman, Hoover, Lewis, and Moeller
(2004) examined word learning in children with NH and
children with HL as a function of presentation level. The
children were between the ages of 6 and 9 years. They
reported a positive relation between presentation level
and word learning in both groups. That is, significantly
more words were learned at higher presentation levels.
Pittman et al. (2005) examined word learning in children
with NH and children with HL as a function of stimulus
bandwidth. In that study, the children were between the
ages of 5 and 14 years. The bandwidth of the stimuli approximated the frequency response of a typical ear-level
hearing aid appropriate for children (4 kHz) as well as a
wider bandwidth that more closely approximated the
range of normal human hearing (9 kHz). The children
were exposed to eight CVCVC novel words a total of six
times each in a single session before their retention was
tested. Each novel word contained three unique phonemes
in the same vowel context. Stelmachowicz, Lewis, Choi,
and Hoover (2007) conducted a similar study of word
learning in noise. Their participants were 7- to 14-yearold children with NH and with HL. They also presented
six repetitions of eight novel words embedded in an animated story; however, the eight CVC words were composed of unique consonants and vowels and filtered to
produce bandwidths of 5 and 10 kHz.

1
Phonotactic probability is the likelihood of certain phoneme sequences
occurring in a particular order within a given language ( Vitevitch, Luce,
Charles-Luce, & Kemmerer, 1997; Vitevitch, Luce, Pisoni, & Auer, 1999).

Pittman: Rate of Word Learning in Children

787

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/09/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

The results of both studies showed no significant
difference in word learning between the limited and extended bandwidth conditions. However, because the novel
words in each study contained unique phonemes, the
benefits of an extended high-frequency bandwidth may
have been reduced in that perception of only one phoneme
was necessary to identify any one word. The finite number
of exposures to each word may have limited the evaluation of learning as well. A longitudinal, rather than a
cross-sectional, approach may better inform our understanding of word learning and may be more sensitive to
the effects of some amplification characteristics. That is,
more may be learned by determining the number of exposures necessary to learn a new word in a short period
of time rather than evaluating performance after a predetermined number of exposures. This may be particularly informative for language processes that develop
over extended periods of time and for subtle amplification characteristics that may have significant cumulative effects.
In the present study, the acoustic phonetic content of
the stimuli and the presentation parameters were carefully controlled to avoid variations in amplification that
might arise from using the children's personal hearing
aids. Also, a dynamic word-learning paradigm was used
to determine the number of exposures required to learn
a new word in a short period of time (15 min). The purpose of the present study was to determine the rate of
word learning in children with NH and children with HL
for words having frequency bandwidths that approximate
typical hearing aids and that of normal human hearing.
Rate of word learning was defined as the number of exposures necessary to achieve 70% correct performance in
the multitrial paradigm. It was hypothesized that word
learning would be significantly affected by the acoustic parameters of the physical signal in both groups of
children.

Method
Participants
Thirty-six children with NH and 14 children with sensorineural HL served as participants. All children were
between the ages of 8 and 10 years (mean NH = 9.6 years,
SD = 0.9 months; mean HL = 9.3 years, SD = 0.9 months).
Seven (50%) of the children with HL were boys as were
20 (56%) of the children with NH. A clinical audiometer
was used to confirm the hearing status of the children
with NH. Thresholds were <15 dB HL at octave frequencies between 0.25 and 4 kHz, <25 dB HL at 8 kHz, and
<40 dB HL at 12 kHz. Table 1 shows the age, gender, and
hearing thresholds for the left and right ears; age at
identification; age at amplification; years of hearing aid
use; and standardized vocabulary score for each child

788

with HL. The thresholds of the children with HL were
measured using custom laboratory software (described
below) and expressed in dB SPL. All of the children were
oral and placed in mainstreamed classrooms with their
age-matched peers. Each child wore hearing aids bilaterally, with the exception of 2 children who were not
aided.

Stimuli
Five CaCC nonsense words were created and paired
with five pictures of nonsense toys. The words were
/saqnd /, /daztl /, /fasnS/, /stamn /, and / hamtl /. The
vowels /a / and // occurred in the first and second syllables of each word, respectively. Three repetitions of
/t/, /s/, and /n /; two repetitions of /d /, /m /, and / l /; and
one repetition of /S/, /f /, /q/, /z/, and / h / were distributed
across the five words. This distribution approximates
the frequency with which these phonemes occur in spoken
American English (Denes, 1963). Also, many of the consonant phonemes occurred in more than one word so that
each child would be required to recognize and learn a
combination of phonemes rather than relying on the intelligibility of just one of several unique phonemes in
each word. Table 2 lists the orthographic representation
of each word as well as the phonetic transcription and
the phonotactic probability. Phonotactic probability was
calculated using the procedure suggested by Vitevitch
and Luce (2004). The first number listed (positional segment frequency) represents the likelihood of the phonemes occurring in their positions within the nonsense
word as they may in real English words. The second
number (biphone frequency) represents the likelihood
that each pair of adjacent phonemes also occurs in
English words. Higher values indicate that the phonemes
occur frequently together or in a particular position. By
design, these words were equated as closely as possible
for phonotactic probability so that word learning would be
independent of these effects.
Prior to testing, the nonsense words were presented
orally to a class of 16 undergraduate students who were
instructed to write an English word that sounded most
like the nonsense word. The written responses were then
tallied to determine whether a substantial number of
the students associated any of the nonsense words with
the same English word. No consistent responses were
given for four of the five nonsense words, but half (8) of
the students wrote the word "stamen" (the pollen-bearing
part of a flower) for the word /stamn/. Coincidentally, the
word "stamen" was an item in the vocabulary test administered to each child as part of the study protocol.
Only 4 children recruited for the present study had vocabularies sufficient to reach that level of the test, and
only 1 responded correctly. Therefore, the English word
"stamen" was considered to be beyond the vocabularies

Journal of Speech, Language, and Hearing Research * Vol. 51 * 785-797 * June 2008

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/09/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

Table 1. Age, gender, hearing thresholds (in dB SPL) for the right and left ears; age at identification (Age ID); age at amplification (Aided);
years of hearing aid use (HA use); and Peabody Picture Vocabulary Test (PPVT) standard score for each child with hearing loss.

Child
number

Frequency (kHz)

Age (years:
months)

Gender

1

9:0

Male

2

10:7

3

8:1

4

8:8

5

9:11

6

8:2

7

8:2

M

9:1

8

10:1

9

9:8

10

8:1

11

9:6

12

10:5

13

9:11

14

9:10

M

9:7

Note.

Ear

0.25 0.50

1

2

4

8

9

73
72
87
98
83
87
51
58
33
23
53
50
47
48
61
62

65
68
76
92
75
58
31
28
25
27
52
53
38
33
52
51

Limited bandwidth
77 83 73 92
78 75 70 97
70 68 61 98
70 73 73 103
79 87 78 98
97 89 61 67
26 80 102 125
13 13 83 113
43 73 88 113
44 63 98 110
45 83 68 73
68 78 73 83
38 43 28 63
48 42 33 63
54 74 71 95
60 62 70 91

Female Right 27
Left
28
Male Right 69
Left
61
Female Right 48
Left
47
Female Right 68
Left
63
Male Right 30
Left
38
Female Right 47
Left
38
Male Right 103
Left 108
Right 56
Left
55

13
13
98
72
41
43
68
67
28
33
33
33
93
93
53
51

Extended bandwidth
13 18 63 33
13 63 48 58
97 72 68 46
68 86 76 67
51 58 48 53
48 58 48 53
78 75 53 63
73 85 55 68
28 63 58 63
43 60 68 83
38 48 48 58
38 48 52 58
93 88 68 65
95 88 78 73
57 60 58 54
54 70 61 66

Right
Left
Male Right
Left
Female Right
Left
Female Right
Left
Female Right
Left
Male Right
Left
Male Right
Left
Right
Left

10

condition
80 83
83 93
82 88
93 118
63 84
58 72
125 125
118 109
102 123
94 99
78 58
73 68
78 78
73 72
87 91
85 90
condition
63 73
78 83
48 53
36 43
48 48
56 58
78 93
73 73
58 55
72 68
58 63
58 62
58 72
83 83
59 65
65 67

Age ID
(years)

Aided
(years)

HA use
PPVT standard
(years:months)
score

2

2

7:0

98

3

4

6:7

89

2

3

5:1

95

5

6

2:8

80

5

6

3:11

113

0

1

7:2

113

0

2

6:2

102

2

3:5

5:5

99

3

108

0

2

7:8

84

3

3

5:1

64

2

2

7:6

116

5

5

5:5

109
115

3

3

6:10

68

3

3

6:9

95

Numbers in italics represent the mean values.

Table 2. Orothographic and phonetic transcriptions of the five
novel words.

of most of the children in the study (8- to 10-year-olds)
and likely had little effect on their ability to learn the
word /stamn/.

Phonotactic probability

The words were recorded by a female talker with a
typical American English dialect using a sampling rate
of 22.05 kHz and a microphone with a flat frequency
response to 10 kHz (AKG, C535EB). As in typical conversational English, the stress was placed on the initial
syllable. The words were digitally isolated from the original recording using Adobe Audition (V1.5) and saved as
separate wave files. The words were then low-pass filtered to create two stimulus conditions. In the first stimulus condition, the words were low-pass filtered at 4 kHz
(with a rejection rate of 60 dB/octave), which approximates

Word

Phonetic transcription

Positional segment

Biphone

Sothnud
Doztul
Fosnush
Stomun
Homtul

saqnd
daztl
fasnS
stamn
hamtl

1.3347
1.3425
1.3345
1.3445
1.3594

1.0081
1.0146
1.0073
1.0455
1.0212

Note. Phonotactic probability (positional and biphone frequencies) are
also provided.

Pittman: Rate of Word Learning in Children

789

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/09/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

the bandwidth of currently available hearing aids appropriate for children (ear-level devices). For the second stimulus condition, the words were low-pass filtered
at 9 kHz (with a rejection rate of 60 dB/octave), which
approximates the frequency range of normal human
hearing. Figure 1 shows the 1/3-octave band spectrum
levels of each word as well as the average spectrum of
all the words as presented to the children with NH. The
shaded area in each panel represents the additional highfrequency amplitude provided in the extended bandwidth
condition.
All stimuli were routed binaurally through earphones
having a flat frequency response >10 kHz (Sennheiser,
25D). For the children with NH, the stimuli were presented at 65 dB SPL, which is consistent with average
conversational speech. To accommodate the elevated thresholds of each child with HL, the stimuli were frequency
shaped according to the target gain parameters provided by the desired sensation level (DSL) v4.1 fitting algorithm (Seewald et al., 1997). DSL does not provide
targets for frequencies >6 kHz, so the targets at higher
frequencies were estimated by comparing the level of
the long-term average speech spectrum at adjacent

frequencies and then by providing similar amplification up to 15 dB of sensation at 9 kHz. Because the
hearing thresholds and experimental results were obtained using the same equipment and calibration parameters, audibility of the stimuli was easily determined by
referencing both to a 6-cm3 coupler. Although real-ear
dB SPL is ideal, standing waves in the ear canal make it
difficult to determine the exact presentation levels at
frequencies >4 kHz (Gilman & Dirks, 1986). Therefore,
threshold and stimulus measures were referenced to a
6-cm3 coupler to obtain relative estimates of sensation
for each child.
Figure 2 shows the average hearing thresholds
(+1 SE) for the right and left ears for the children with
HL in the limited and extended bandwidth conditions
(left and right panels, respectively). The average presentation levels of the stimuli are also shown. Note that the
hearing levels of the children in the limited bandwidth
condition are more severe in the high frequencies than
for the children in the extended bandwidth condition.
Although group assignment was random for most of
the children with HL, those children with greater highfrequency losses at 9 kHz were placed in the limited

Figure 1. Third-octave spectrum levels for each word as well as the combined long-term spectrum
(lower right panel) as presented to the children with normal hearing.

790

Journal of Speech, Language, and Hearing Research * Vol. 51 * 785-797 * June 2008

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/09/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

Figure 2. Average presentation levels (in dB SPL) as a function of frequency (kHz) for the children
with hearing loss in the limited and extended bandwidth conditions (left and right panels, respectively).
Average hearing thresholds for the right and left ears are also provided. Error bars represent
1 SE. All levels were referenced to a 6-cm3 coupler.

bandwidth group because adequate sensation of the
stimuli would have exceeded the output limits imposed
in this study.

Procedure
Receptive vocabulary. Prior to testing, the Peabody
Picture Vocabulary Test--III (PPVT-III, Form B; Dunn
& Dunn, 2006) was administered to determine each
child's current receptive vocabulary. For this and the
following test, the children with HL wore their personal
hearing aids and were tested in a quiet room. The results
of the PPVT were used to equate the receptive vocabularies of the children assigned to each listening condition
(described below) because previous research suggests
that word learning is related to the size of a child's current vocabulary. In this way, the influence of receptive
vocabulary on word learning could be controlled a priori
so that the effects of stimulus condition might be more
apparent.
Working memory. The Rey Auditory-Verbal Learning Test (AVLT) was also administered to assess verbal
memory and retention (Lezak, Howieson, & Loring, 2004;
Taylor, 1959; van den Burg & Kingma, 1999). The test
requires the child to learn and retain a list of familiar
words read aloud. This test has been used extensively
with both children and adults to determine the effects of
various disorders, such as traumatic brain injury and degenerative diseases on working memory (e.g., multiple
sclerosis, Alzheimer's, Huntington's). A list of 15 monosyllabic words familiar to children is read five times to the
child at a rate of one word per second. After each repetition of the list, the child's task is to recall as many words

as possible in no particular order and in no predetermined
period of time. The number of words recalled on each of
the five repetitions of the list is then tallied and compared with normative values for typical children (van den
Burg & Kingma, 1999). Although these data may be analyzed a number of ways (e.g., total words acquired, interference, number of repetitions, retention after delay), for
purposes of this study, only the total number of words
retained after each of the five recitations was calculated.
The results of this test were used to identify any apparent
differences between the children in the two stimulus conditions so that the effects of verbal learning and retention
could be accounted for statistically.
Word learning. The children with NH and the children with HL were divided into two equal subgroups.
Each subgroup learned the five words in the limited or
the extended bandwidth condition, but not in both. Each
child participated in two word-learning tasks: a familiarization task and a learning task. In the familiarization
task, the child was briefly exposed to the visual pictures
of toys and their names. A picture of a novel toy was displayed on a computer screen while the child heard, "This
is a ____. Can you say_____?" The examiner then listened to the child's production to confirm that he/she
produced the word correctly before moving on to the next
picture. The familiarization task consisted of three repetitions of each word (two aural presentations and one
production by the child). This task was similar to fast
mapping in that the child was provided several directed
exposures to the words and their associated toys before
beginning the learning task.
In the learning task, the child played a simple computer game to learn the names of the five toys. Prior to

Pittman: Rate of Word Learning in Children

791

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/09/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

implementing the task, each child was given the following
instructions by the examiner:
You will play a computer game to see how quickly you
can learn the names of the toys. In the game you will
see the pictures of the five toys on the computer
screen. Then you'll hear a woman tell you a toy name.
Select the toy that you think has that name. If you're
right, the game will play. If you're not right, nothing
will happen. At first you may not get very many right,
but keep trying. As you play the game, you'll get better
and better.

This task was similar to novel mapping in that the child
was expected to connect the novel word to the correct
novel object.
Custom laboratory software was used to randomly
select a word, process it according to the frequencyshaping parameters calculated for each child, provide
feedback in the form of a simple video game (e.g., dot-todot, puzzle), record the trial-by-trial data, and display
real-time data analysis for the examiner. Figure 3 shows
the interactive response screen used by the children for
this task. A picture of each toy was displayed as response
buttons on the left side of the computer screen. For each
correct response, the video game on the right side of the
screen was advanced incrementally (e.g., the next line
was drawn in the dot-to-dot game). The video game did
not advance for incorrect selections. The learning task
consisted of a total of 150 trials (30 repetitions of each

word presented randomly) and took approximately
15 min to complete.
In the event that one toy-name association was more
salient than the others or if one toy was simply more appealing, the name associated with each toy was rotated
systematically for each child. That is, the toy-name association was different for each child. This reduced the
effects of picture or word preference by distributing the
effect across children. All testing was conducted in a
sound-treated booth in the presence of an examiner who
evaluated the child's production of the words, encouraged consistent attention to each task, and answered
any questions that the child had.

Results
Preliminary Tests
Figure 4 shows the average PPVT raw scores (1 SE)
as a function of group (NH and HL). The children enrolled
in the limited and extended bandwidth conditions are indicated by open and filled bars, respectively. The average
standard score for each group and condition is also indicated in parenthesis above each bar. The raw scores were
subjected to a univariate analysis of variance with hearing status (NH, HL) and bandwidth (limited, extended) as
between-subjects factors. A significant main effect of

Figure 3. Interactive response screen used by the children to select a toy after the presentation of each
novel word. Feedback was provided via several video games. In this example, the dot-to-dot game was
incrementally advanced after each correct response.

792

Journal of Speech, Language, and Hearing Research * Vol. 51 * 785-797 * June 2008

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/09/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

Figure 4. Average raw scores for the Peabody Picture Vocabulary
Test (PPVT) as a function of hearing status (normal hearing [NH] and
hearing loss [HL]). Error bars represent 1 SE. The children enrolled
in the limited and extended bandwidth conditions are indicated by
open and filled bars, respectively. Standard scores are shown in
parentheses.

hearing status was revealed, F(1, 46) = 9.1, p < .01, but
not for bandwidth, F(1, 46) = 0.2, p = .63. There was
no Hearing Status x Bandwidth interaction, F(1, 46) =
0.1, p = .79. These results indicate that across groups
the children with NH had significantly higher receptive vocabularies, but within each group the children
assigned to each bandwidth condition possessed similar vocabularies. Therefore, any difference between
the word-learning rates of the children in each stimulus
condition was not due to differences in receptive
vocabulary.
Figure 5 shows the mean AVLT scores (+1 SE) as a
function of list repetition for the children with NH (filled
symbols) and the children with HL (open symbols). The
children enrolled in the extended and limited bandwidth
conditions are indicated by circles and squares, respectively. The symbols have been jittered slightly to expose
the overlapping error bars. The shaded area represents
the 95% confidence intervals for typical 8- to 10-year-old
children (van den Burg & Kingma, 1999). Recall that the
AVLT is a measure of verbal memory and retention of
familiar words. The average performance of each group
suggests a systematic increase in the number of words
retained with each repetition of the list. The children with
HL, however, retained consistently fewer words across
repetitions than the children with NH. Even so, the children assigned to the two stimulus conditions within each
group demonstrated similar learning functions suggesting that any difference between the word-learning rates
across stimulus conditions was not due to differences in
verbal memory and retention.

Figure 5. Average recall for the Rey Auditory-Verbal Learning Test
as a function of list repetition. Error bars represent 1 SE. Children
with NH and children with HL are represented by filled and open
symbols, respectively. The children enrolled in the limited and
extended bandwidth conditions are indicated by squares and
circles, respectively. The shaded area represents the 95% confidence
interval for typical 8- to 10-year-old children (van den Burg &
Kingma, 1999).

Word Learning
To characterize word learning, the data from the
learning task were used to create growth functions for
each of the four groups (2 hearing status x 2 bandwidth).
The most efficient way to do this was to fit learning curves
to the data and base any inferences on the parameter that
characterized the curve. In this case, an exponential
growth function was chosen and used the time constant
of that function to indicate the number of exposures
necessary to acquire new words. The exponential growth
function is as follows:
P L 1/4 1  en=c ;

1

where PL , the probability of learning, ranges from 0 to 1;
e is 2.718 I; n is the number of the trial block; and c is
the time-constant of the process. When the number of
trials happens to equal the time constant, n = c, learning
is almost two thirds complete (PL = 0.63); furthermore,
when n = 3c, learning is 95% complete.
In this experiment, a child who could make no discrimination at all would be correct just one time out of
five by chance. Therefore, the floor of the performance
was not 0% correct but 20% correct. Thus, the model of
learning, Equation 1, was corrected for chance to give a
model of performance that could be used to map the data.
The standard correction for guessing was used: The probability of being correct (PC) equals the probability of having learned (PL), plus the probability of not yet having

Pittman: Rate of Word Learning in Children

793

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/09/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

learned (1 - PL), times the probability of getting the
answer by chance (PCh):
P C 1/4 P L  1  P L P Ch :

2

Putting this together with the learning model provided the predicted rate of improvement in performance:
P C 1/4 1  0:8en=c ;

3

where PC is the probability of a correct answer, and, as
before, n is the number of the trial block, and c is the time
constant for the learning process. With this formula,
PC = 0.2 when n = 0, with the curve growing from that
raised floor in a smooth fashion to 1.0. When n = c, performance is approximately 70% (70.57%) correct.
The advantage of using Equation 3 to model the data
was that all data points in the learning process contributed to the determination of the time constant. Because
the speed of learning--the key dependent variable--is
simply 1/c, fitting Equation 3 to the data was the best way
to address the experimental question. This was accomplished by adjusting estimates of c to minimize the sum
of squared deviations between the data and the points
predicted. Figure 6 shows the learning functions (+1 SE)
for each group and bandwidth condition averaged across
children. Hearing status is indicated by filled and unfilled
symbols, whereas bandwidth is indicated by circles and
squares. The symbols have been jittered to expose the
overlapping error bars. The slopes of the learning functions were greater for the children in the extended bandwidth condition as were the slopes for the children with
NH. That is, the performance of the children in the

Figure 6. Averaged learning functions (+1 SE ) for the novel words as
a function of trial number. Children with NH and children with HL are
represented by filled and open symbols, respectively. The children
enrolled in the limited and extended bandwidth conditions are
indicated by squares and circles, respectively.

extended bandwidth condition exceeded that of the children in the limited bandwidth condition as did the performance of the children with NH relative to the children
with HL. These results suggest that the extended bandwidth condition allowed both groups of children to learn
the words more rapidly than in the limited bandwidth
condition.
To determine whether the acoustic characteristics of
the input affected the number of exposures necessary for
the children to learn new words, the number of exposures
necessary to reach a performance of 70% was estimated
for each child using the harmonic mean of the blocked
trials. The harmonic mean, rather than the arithmetic or
geometric mean, was used because it is appropriate for
calculating the average of rates. It more accurately describes the number of trials required for learning, and it
tends to compensate for extreme outliers. The learning
rates were then log transformed and subjected to a univariate analysis of variance with hearing status (NH, HL)
and bandwidth (limited, extended) as between-subjects
factors. A significant main effect of bandwidth condition
was revealed, F(1, 46) = 5.8, p = .02, but not an effect of
hearing status, F(1, 46) = 1.8, p = .19. There was also no
Hearing Status x Bandwidth interaction, F(1, 46) = 0.6,
p = .44. These results indicate that on average, the children required fewer exposures to learn the words in the
extended bandwidth condition regardless of hearing
status.
Two additional analyses were conducted to address
directly the primary question of interest. That is, did the
word-learning rate of each group increase in the extended
bandwidth condition? A one-tailed t test was used to compare the learning rates of the children with NH in each
bandwidth condition. The results reveal a significant difference between the bandwidth conditions, t(34) = 1.8,
p = .04, d = 0.75, and suggest that these children required significantly fewer exposures to learn the new
words in the extended bandwidth. The effect size indicates that on average, the rate of word learning by the
children in the extended bandwidth exceeded that of the
children in the limited bandwidth condition by 0.75 standard deviations. An additional one-tailed t test was conducted to compare the learning rates of the children with
HL as a function of bandwidth. No significant difference
between the learning rates in each bandwidth condition
was revealed, t(12) = 1.4, p = .10. Although the learning
functions for these children suggest a large effect of bandwidth (see Figure 6), the lack of significance is likely due
to the smaller number of children in this group.

Number of Exposures
Required for Learning
On average, the children with NH required 20 trials
to achieve the criterion performance level (70%) in the

794

Journal of Speech, Language, and Hearing Research * Vol. 51 * 785-797 * June 2008

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/09/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

extended bandwidth condition, whereas 72 trials were
necessary in the limited bandwidth condition. For the
children with HL, 43 trials were necessary to achieve the
criterion performance in the extended bandwidth condition, whereas 121 trials were necessary in the limited
bandwidth condition. For easier interpretation, the learning rate for a single word in these conditions was also
calculated using the same criterion performance (70%).
On average, the children with NH required 5 trials to
learn each word in the extended bandwidth condition,
whereas 16 trials were required in the limited bandwidth condition. The children with HL required 10 trials
to learn each word in the extended bandwidth condition,
whereas 27 trials were necessary in the limited bandwidth condition. The results suggest that compared with
the children with NH, the children with HL required
approximately twice the number of exposures to learn
each word. Also, although the group effect was not statistically significant for the children with HL, both
groups required 3 times as many trials to learn the new
words in the limited bandwidth condition.

Discussion
The purpose of the present study was to determine
the short-term word-learning rate of children as a function of their hearing status and the bandwidth of the
speech signal. It was hypothesized that word learning
would be significantly affected by the acoustic parameters of the physical signal. The principle result from this
study suggests that regardless of hearing status, the
children learned words significantly faster (fewer exposures were necessary) when they were provided with a
speech signal that encompassed a bandwidth similar to
that of NH. Conversely, the children learned words more
slowly (more exposures were necessary) when they were
provided with a limited speech signal.
These results are consistent with the results of studies showing that children with HL possess significantly
smaller vocabularies than children with NH and may explain, in part, why they are unable to learn words as well
as their peers with normal hearing (Briscoe et al., 2001;
Gilbertson & Kamhi, 1995; Hansson et al., 2004). That
is, the amplified signal provided to children with HL may
be insufficient to promote optimal word learning. These
results also suggest that the phonological difficulties
demonstrated by children with HL may be associated
with the somewhat ambiguous signal that they receive
through their hearing aids. Because word learning requires a child to perceive the subtle acoustic elements
of the word to distinguish it from other similar words,
they may require more exposures to overcome the ambiguous signal that they receive. That ambiguity also
may be responsible, in part, for the poorer performance

demonstrated by children with HL on phonological processing tasks (Briscoe et al., 2001; Hansson et al., 2004)
and would suggest that some speech and language measures are sensitive to variations in the integrity of the
acoustic signal. For example, a common test of phonological processing requires that the child repeat aloud
nonsense words that increase in syllable length. It is not
difficult to imagine that a child receiving a limited acoustic signal would find it difficult to repeat the word, much
like trying to perceive an unfamiliar name or term over
the telephone.
Recall that the qualitative difference between the
limited and extended bandwidth conditions is quite subtle, particularly when perceiving familiar speech. The
results of this study suggest that the qualitative contributions of high-frequency energy to speech perception
may be quantitative over the long term for children who
are listening to and learning unfamiliar speech. In addition to the subtle effects of high-frequency amplification,
it is possible that other amplification characteristics
(e.g., frequency compression, noise reduction, directional
microphones) also may interact with word learning in
children with HL. To date, no studies are available regarding the effect of these amplification characteristics
on word learning. The consistent difference, and in some
studies the increasing difference, between the receptive
vocabularies of children with HL and age-matched children with NH (Blamey et al., 2001; Pittman et al., 2005)
suggests an urgent need to determine those amplification parameters that provide a comprehensive acoustic
signal so that word learning may be optimized in children with HL.

Limitations of the Current Study
It is important to recognize the limitations of the
short-term paradigm used in the present study as well
as the results of that paradigm. First, the controlled
conditions necessary to examine an acoustic effect (e.g.,
sound treated room, high-fidelity earphones) limit the
generalization of the results because the test conditions
are far from most naturalistic learning environments. It
is possible that the benefits of an extended bandwidth
may be enhanced or reduced by such things as speech
reading, contextual cues, background noise, and distance from the talker. Second, and most important, the
number of exposures necessary to learn the words in this
short-term paradigm should not be interpreted as the
number of exposures that a child may require over a
more extended period of time or under different circumstances. Instead, they should be interpreted in relative
terms and in the context of the acoustic parameters
under examination.
Finally, it is important to recall that children with
HL are a highly heterogeneous population. In addition to

Pittman: Rate of Word Learning in Children

795

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/09/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

the factors that contribute to the variability of all children (e.g., age, IQ), children with HL also vary in terms
of the etiology of the HL; the degree and configuration of
the HL; the age at which they were identified and provided with intervention; the hearing aid make, model,
and features prescribed to them; their mode of communication; the consistency with which they use their hearing
aids or attend intervention programs; and the support
that they receive from their parents and other family
members. Not only do these factors make it difficult
to recruit a homogenous group of children for research
but the application of the results to this population is
even more questionable. It is likely that each child with
HL requires a unique intervention plan to optimize his
or her auditory processing. However, because some direction regarding the best course of action is helpful,
children with NH are also examined (as was done in the
present study) to confirm the benefits of a particular
form of intervention in the absence of the factors that
can confound the performance of children with HL.

Future Directions for Research
The results of the present study suggest that subtle
variations in the acoustic signal may affect long-term
auditory processes in children. Although extending the
bandwidth of a signal is perceived as an increase in
sound quality (Munro & Lutman, 2005; Versfeld, Festen,
& Houtgast, 1999), that increased quality appears to
have a quantitative effect in children who use their hearing primarily to learn. More research is needed to determine the extent to which other seemingly subtle
properties of the amplified signal affect long-term auditory processes in children. For example, noise-reduction
algorithms may have negligible effects on speech recognition thresholds (Alcantara, Moore, Kuhnel, & Launer,
2003) but may have a significant cumulative effect on
long-term processes, such as word learning (Marcoux,
Yathiraj, Cote, & Logan, 2006). Likewise, frequency transposition may not improve speech perception significantly
in the short term (McDermott & Dean, 2000; McDermott,
Dorkos, Dean, & Ching, 1999; McDermott & Knight,
2001) but may improve word learning over time. The
learning paradigm employed in the present study may
be a useful tool for tapping into the word-learning process to evaluate the effect of these and other amplification characteristics.

Acknowledgments
This work was supported by Grant R03 DC 06573 from the
National Institute on Deafness and Other Communication
Disorders. I would like to thank Christina Sergi for her help
with data collection and article preparation, Peter Killeen for
his help with data analyses, and Mary Pat Moeller for her
comments on earlier versions of this article.

796

References
Alcantara, J. L., Moore, B. C., Kuhnel, V., & Launer, S.
(2003). Evaluation of the noise reduction system in a
commercial digital hearing aid. International Journal of
Audiology, 42, 34-42.
Blamey, P. J., Sarant, J. Z., Paatsch, L. E., Barry, J. G.,
Bow, C. P., Wales, R. J., et al. (2001). Relationships among
speech perception, production, language, hearing loss, and
age in children with impaired hearing. Journal of Speech,
Language, and Hearing Research, 44, 264-285.
Bloom, P. (2000). First words. In How children learn the
meanings of words (pp. 1-23). Cambridge, MA: The MIT
Press.
Boothroyd, A., & Boothroyd-Turner, D. (2002). Postimplantation audition and educational attainment in children
with prelingually acquired profound deafness. Annals of
Otology, Rhinology, and Laryngology, 189, 79-84.
Briscoe, J., Bishop, D. V., & Norbury, C. F. (2001). Phonological processing, language, and literacy: A comparison of
children with mild-to-moderate sensorineural hearing loss
and those with specific language impairment. Journal of
Child Psychology and Psychiatry and Allied Disciplines,
42, 329-340.
Davis, J. M., Elfenbein, J., Schum, R., & Bentler, R. A.
(1986). Effects of mild and moderate hearing impairments
on language, educational, and psychosocial behavior of children. Journal of Speech and Hearing Disorders, 51, 53-62.
Denes, P. B. (1963). On the statistics of spoken English. The
Journal of the Acoustical Society of America, 35, 892-905.
Dunn, L. M., & Dunn, L. M. (2006). Peabody Picture Vocabulary Test--III. Circle Pines, MN: American Guidance
Services.
Gilbertson, M., & Kamhi, A. G. (1995). Novel word learning
in children with hearing impairment. Journal of Speech and
Hearing Research, 38, 630-642.
Gilman, S., & Dirks, D. D. (1986). Acoustics of ear canal measurement of eardrum SPL in simulators. The Journal of
the Acoustical Society of America, 80, 783-793.
Hansson, K., Forsberg, J., Lofqvist, A., Maki-Torkko, E.,
& Sahlen, B. (2004). Working memory and novel word
learning in children with hearing impairment and children with specific language impairment. International
Journal of Language and Communication Disorders, 39,
401-422.
Kortekaas, R. W., & Stelmachowicz, P. G. (2000). Bandwidth
effects on children's perception of the inflectional morpheme
/s/: Acoustical measurements, auditory detection, and clarity rating. Journal of Speech, Language, and Hearing
Research, 43, 645-660.
Lederberg, A. R., Prezbindowski, A. K., & Spencer, P. E.
(2000). Word-learning skills of deaf preschoolers: The development of novel mapping and rapid word-learning strategies. Child Development, 71, 1571-1585.
Lezak, M. D., Howieson, D. B., & Loring, D. W. (2004).
Neuropsychological assessment. New York: Oxford University Press.
Marcoux, A. M., Yathiraj, A., Cote, I., & Logan, J. (2006).
The effect of a hearing aid noise reduction algorithm on the
acquisition of novel speech contrasts. International Journal
of Audiology, 45, 707-714.

Journal of Speech, Language, and Hearing Research * Vol. 51 * 785-797 * June 2008

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/09/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

McDermott, H. J., & Dean, M. R. (2000). Speech perception
with steeply sloping hearing loss: Effects of frequency
transposition. British Journal of Audiology, 34, 353-361.
McDermott, H. J., Dorkos, V. P., Dean, M. R., & Ching, T. Y.
(1999). Improvements in speech perception with use of the
AVR TranSonic frequency-transposing hearing aid. Journal
of Speech, Language, and Hearing Research, 42, 1323-1335.
McDermott, H. J., & Knight, M. R. (2001). Preliminary
results with the AVR ImpaCt frequency-transposing hearing
aid. Journal of the American Academy of Audiology, 12,
121-127.
Munro, K. J., & Lutman, M. E. (2005). Sound quality judgments of new hearing instrument users over a 24-week
post-fitting period. International Journal of Audiology,
44, 92-101.
Oetting, J. B., Rice, M. L., & Swank, L. K. (1995). Quick
incidental learning (QUIL) of words by school-age children
with and without SLI. Journal of Speech and Hearing
Research, 38, 434-445.
Pittman, A. L., Lewis, D. E., Hoover, B. M., & Stelmachowicz,
P. G. (2005). Rapid word-learning in normal-hearing and
hearing-impaired children: Effects of age, receptive vocabulary, and high-frequency amplification. Ear and Hearing, 26,
619-629.
Rice, M. L., Buhr, J. C., & Nemeth, M. (1990). Fast mapping
word-learning abilities of language-delayed preschoolers.
Journal of Speech and Hearing Disorders, 55, 33-42.
Rice, M. L., Oetting, J. B., Marquis, J., Bode, J., & Pae, S.
(1994). Frequency of input effects on word comprehension of
children with specific language impairment. Journal of
Speech and Hearing Research, 37, 106-122.
Seewald, R. C., Cornelisse, L. E., Ramji, K. V., Sinclair,
S. T., Moodie, K. S., & Jamieson, D. G. (1997). DSL v4.1
for Windows: A software implementation of the desired sensation level (DSL[i/o]) method for fitting linear gain and
wide-dynamic-range compression hearing instruments.
User's manual. London, Ontario, Canada: The University of
Western Ontario Hearing Health Care Research Unit.
Stelmachowicz, P. G., Lewis, D. E., Choi, S., & Hoover, B.
(2007). Effect of stimulus bandwidth on auditory skills in
normal-hearing and hearing-impaired children. Ear and
Hearing, 28, 483-494.
Stelmachowicz, P. G., Pittman, A. L., Hoover, B. M., &
Lewis, D. E. (2001). Effect of stimulus bandwidth on the
perception of /s/ in normal- and hearing-impaired children
and adults. The Journal of the Acoustical Society of America,
110, 2183-2190.

Stelmachowicz, P. G., Pittman, A. L., Hoover, B. M., &
Lewis, D. E. (2004). Novel-word learning in children with
normal hearing and hearing loss. Ear and Hearing, 25,
47-56.
Stelmachowicz, P. G., Pittman, A. L., Hoover, B. M.,
Lewis, D. E., & Moeller, M. P. (2004). The importance
of high-frequency audibility in the speech and language
development of children with hearing loss. Archives of
Otolaryngology--Head and Neck Surgery, 130, 556-562.
Storkel, H. L. (2001). Learning new words: Phonotactic
probability in language development. Journal of Speech,
Language, and Hearing Research, 44, 1321-1337.
Storkel, H. L. (2003). Learning new words: II. Phonotactic
probability in verb learning. Journal of Speech, Language,
and Hearing Research, 46, 1312-1323.
Taylor, E. M. (1959). Psychological appraisal of children with
cerebral defects. Cambridge, MA: Harvard University Press.
van den Burg, W., & Kingma, A. (1999). Performance of
225 Dutch school children on Rey's Auditory Verbal Learning
Test (AVLT): Parallel test-retest reliabilities with an interval
of 3 months and normative data. Archives of Clinical
Neuropsychology, 14, 545-559.
Versfeld, N. J., Festen, J. M., & Houtgast, T. (1999).
Preference judgments of artificial processed and hearing-aid
transduced speech. The Journal of the Acoustical Society of
America, 106, 1566-1578.
Vitevitch, M. S., & Luce, P. A. (2004). A web-based interface
to calculate phonotactic probability for words and nonwords
in English. Behavior Research Methods, Instruments, and
Computers, 36, 481-487.
Vitevitch, M. S., Luce, P. A., Charles-Luce, J., &
Kemmerer, D. (1997). Phonotactics and syllable stress:
Implications for the processing of spoken nonsense words.
Language and Speech, 40, 47-62.
Vitevitch, M. S., Luce, P. A., Pisoni, D. B., & Auer, E. T.
(1999). Phonotactics, neighborhood activation, and lexical
access for spoken words. Brain and Language, 68, 306-311.
Received October 19, 2006
Accepted October 17, 2007
DOI: 10.1044/1092-4388(2008/ 056)
Contact author: A. L. Pittman, Department of Speech
and Hearing Science, Arizona State University,
P.O. Box 870102, Tempe, AZ 85287-0102.
E-mail: andrea.pittman@asu.edu.

Stelmachowicz, P. G., Pittman, A. L., Hoover, B. M., &
Lewis, D. E. (2002). Aided perception of /s/ and /z/ by
hearing-impaired children. Ear and Hearing, 23, 316-324.

Pittman: Rate of Word Learning in Children

797

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 04/09/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

