J Psycholinguist Res (2018) 47:1015-1033
https://doi.org/10.1007/s10936-018-9574-7

The Role of Phonetic Similarity and Orthographic
Information in Asymmetrical Lexical Encoding in Second
Language
Jeong-Im Han1

* Sujin Oh1

Published online: 12 March 2018
(c) Springer Science+Business Media, LLC, part of Springer Nature 2018

Abstract This study examined two possible sources of asymmetrical lexical access: phonetic
proximity to the nearest L1 category and orthographic information. Three groups of native
Korean speakers learned Arabic non-words with sound pairs with/without an L1-dominant
category (/l-r/ vs. /-e/), and then their phonetic categorization and lexical encoding abilities
were evaluated. One group was presented with the same letters for the target pair (e.g., <l> for
both /l/ and /r/), the second group, different letters (e.g., <l> for /l/, <r> for /r/), and the third
group, auditory input only. The results of discrimination did not show any effect of these
two sources, whereas in lexical encoding, (1) a pair with an L1-dominant category was
more accurately encoded; and (2) orthographic information hindered the lexical encoding.
In the following spelling recall task, the scores from the learners with different letters for the
target pair were similar to a ceiling. Thus, orthographic information might help them to have
target-like representation, despite difficulties in online processing.
Keywords Asymmetrical lexical encoding * Phonetic proximity to L1 category *
Orthographic information * Modern Standard Arabic * Korean learners

Introduction
There has been a growing interest in investigating the relationship between learners' phonetic
categorization abilities and their abilities to lexically encode novel contrasts. Traditionally, it
has been assumed or argued that second-language (L2) learners fail to lexically encode a novel
contrast because they cannot reliably distinguish the contrast (Broersma 2012; Diaz et al.
2012; Han et al. 2017; Nakai et al. 2015; Ota et al. 2009; Pallier et al. 1997, 2001; SebastianGalles and Baus 2005). Escudero et al. (2013), for example, examined Spanish learners'
discrimination accuracy for Dutch novel words that have minimal pairs with perceptually

B
1

Jeong-Im Han
jhan@konkuk.ac.kr
Department of English, Konkuk University, 120 Neungdong-ro, Gwangjin-gu, Seoul 143-701, Korea

123

1016

J Psycholinguist Res (2018) 47:1015-1033

difficult vowel contrasts (/i/-/I/) and those with perceptually easy ones (/u/-/a/), and found that
difficulty in vowel discrimination led to poor performance in the recognition of novel minimal
pairs. However, evidence against the continuity between phonological and lexical difficulties
in L2 acquisition has also been reported in the literature (Cutler et al. 2006; Darcy et al. 2012;
Escudero et al. 2008; Hayes-Harb and Masuda 2008; Weber and Cutler 2004). In these studies,
it has been shown that L2 learners can have separate lexical representations for minimal pairs
with confusable phonemes. In an eye-tracking study by Weber and Cutler (2004), native
English listeners and Dutch-English bilinguals were asked to click on the picture that they
heard out of four pictures: the target (e.g., panda, with /ae/ in the first syllable), the competitor
(e.g., pencil, with /2/ in the first syllable) and two fillers (e.g., beetle, bottle). Given that English
/2/ and /ae/ are mapped onto a single Dutch category, which is phonetically closer to the English
/2/, both the target and the competitor have confusable vowels. However, Dutch-English
bilinguals, but not native English listeners, showed an asymmetrical pattern of activation
in that pan- inappropriately activated pencil, but pen- did not activate panda. The authors
explained this asymmetrical pattern of word activation by arguing that the two categories /2/
and /ae/ are not fully merged in lexical representation and the distinction is preserved, even
though L2 learners experience difficulties in online auditory word-identification tasks.
The sources of this asymmetry remain unclear, however, and could be due to a number of
factors. Most obvious is the acoustic-phonetic proximity to the nearest L1 category (Barrios
et al. 2016; Cutler et al. 2006; Weber and Cutler 2004). In Weber and Cutler (2004), Dutch
listeners exhibited a response bias such that activation of the targets containing a more
similar L2 category was more selective in word recognition than that of the targets with a
new category. That is, given that Dutch contains the category /2/, but not /ae/, the phoneme
category in English that is perceived to be nearest to the native category (/2/ in pencil)
activates the targets with this category more selectively in word recognition than the English
phoneme that is perceived to be further from any native category (/ae/ in panda). Later, Cutler
et al. (2006) replicated Weber and Cutler (2004) with native Japanese speakers listening
to English words with contrasting /l/ and /o/. They showed a similar asymmetrical pattern
of lexical activation with spoken words in the eye-tracking test, with /o/ inducing looks to
pictures with /l/, but not vice versa. This result suggests that /l/ was the dominant category for
lexical activation. The Japanese liquid consonant is indeed phonetically closer to English /l/
than /o/. Based on these two studies, Cutler and her colleagues concluded that the L2 category
which is phonetically closer to the L1 category emerges as the dominant category for the
purpose of spoken-word recognition.
Escudero et al. (2008) proposed an alternative explanation for the lexical asymmetry,
based on the role of orthographic information. They hypothesized that lexical contrasts could
have emerged via orthographic information even when categorization of the contrast was not
robust. Escudero et al. trained two groups of Dutch learners on novel English words containing
/2/ and /ae/ where one group of participants was presented with English-spelled non-words as
well as auditory forms, while the other group was only presented with auditory forms. The
results of an eye-tracking test demonstrated an asymmetrical pattern of lexical encoding (as
shown in those of Weber and Cutler 2004) only for the group trained with both auditory and
orthographic forms (e.g., <tenzer> for [t2n-] and <tandek> for [taen-]). The two graphemes for
the two target vowels (<e> for /2/ and <a> for /ae/) were also used to distinguish two native
Dutch vowels, namely, /a/ and /e/, and Dutch learners seemed to use this Dutch phoneme-tographeme correspondence in their English lexicon to distinguish these two English vowels
in a word-recognition task. These orthographic forms would facilitate the Dutch learners'
memories for the minimal pair words that differ in such a difficult contrast as /2/ and /ae/,
which helps them to establish separate lexical representations for the minimal pair words with

123

J Psycholinguist Res (2018) 47:1015-1033

1017

this contrast. Escudero et al. concluded that availability of the abstract knowledge about a
novel contrast such as the mapping between orthographic and phonological forms can result
in establishing the lexical representation of novel L2 words.
The aim of the present study is to further explore these two sources of separate lexical encoding, despite the difficulties in phonetic categorization, within a single study. We
investigate the phonetic categorization and lexical decision patterns of the consonants in an
unfamiliar language, using an adapted format of word-learning paradigm (Rastle et al. 2011).
Specifically, native Korean speakers learn a set of Modern Standard Arabic (MSA) non-words
in four consecutive daily sessions and then their accuracy in phonetic categorization is tested
in an AX discrimination task and their lexical processing abilities, in a lexical decision task.
Crucially, two factors are manipulated in the experiment: (1) the presence/absence of orthographic information available to the Korean learners and (2) differences of the stimuli in
sound pairs from a corresponding native-language(L1)-dominant category and those lacking
such category. The reason for the choice of MSA is that MSA is typologically distant from
the Korean language and most Korean speakers are indeed rarely exposed to the Arabic language. If we use a familiar language, numerous factors could potentially impact L2 sound
categorization and lexical access. Therefore, this study can provide an opportunity to directly
trace the initial stage of learning, avoiding any possible effect of prior L2 experience.
The target categories in MSA are two types of consonantal phoneme pairs such as /l/
and /r/ vs. // and /e/. The phoneme /l/ is a lateral approximant which is maintained in all
Arabic dialects, while /r/ is an alveolar (or sometimes dental) trill (Al-Ani 1970; Amayreh
2003; Mahmoud 2013). Arabic /r/ has a variety of free allophones, but this segment can be
realized as a tap in word-initial position (Watson 2002; Younes 1994). The phonemes // and
/e/ are voiceless uvular and pharyngeal fricatives, respectively. The phoneme // appears
spectrally as random noise averaging 100-160 ms, and the phoneme /e/ is realized with an
average duration of 100-150 ms (Al-Ani 1970). These two pairs of consonants might be
distinctly matched up against the available Korean categories. First, the lateral and rhotic
liquids /l/ and /r/ might be perceptually mapped to a single consonant in Korean. In Korean,
there is a single liquid phoneme, transcribed phonemically as /l/, which is realized as an
apical tap [R] or an alveolar lateral [l]. The tap is produced in intervocalic position (e.g., [u.Ri]
/u.li/ `we') or in word-initial position for loan words (e.g., [Ra.di.o] /la.di.o/ `radio'), while
the alveolar lateral appears elsewhere, namely, in pre-consonantal (e.g., [tal.kwa] /tal.kwa/
`moon and') or final position (e.g., [tal] /tal/ `moon') (Shin et al. 2013). By contrast, the two
target fricatives in MSA, // and /e/, are new to the Korean speakers in that neither appears
in Korean. Presumably, the most similar category to these fricatives is a voiceless glottal
fricative, /h/, but the pharyngeal /e/ is realized with a constricted articulation by bringing the
tongue dorsum against the posterior wall of the pharynx (Al-Ani 1970), which shows more
intense noise at lower third formant frequencies (Klatt and Stevens 1969). Thus, it is not the
case that one member of the MSA pair is closer to the Korean /h/. 1
It is important to note that discrimination of the cases in which two sounds are not differentiated in L1 at all (i.e., single-category assimilation) is worse than cases in which one
1 Given the lack of research examining the perceptual similarities between MSA and Korean consonants,
we relied on descriptive phonetic realizations of the target phonemes to compose the contrasts to be tested,
including articulatory and acoustic measurements of MSA and Korean consonants that were provided by
other research studies. Directly relating to the present study, Mahmoud (2013), who examined how Arabic
consonants would be perceived by speakers of the American English, considered the uvular-pharyngeal ///e/ contrast in Arabic as a case where both sounds fall outside of any particular native category of American
English. Considering that both Korean and American English have velar and glottal consonant phonemes at
back places of articulation such as /k/, /g/, /N/, and /h/, a similar prediction for this contrast seems to be borne
out for Korean.

123

1018

J Psycholinguist Res (2018) 47:1015-1033

sound fits into one L1 category better than the other (i.e., category-goodness assimilation)
(e.g., PAM by Best 1995; Best and Tyler 2007). In the mapping of /l/ and /r/ in MSA to /l/ in
Korean, the MSA /l/ would be perceived as a closer match to the Korean category /l/, whereas
the MSA // and /e/ would not show any dominant category relationship with the relevant
Korean category. Recall that activation of the targets containing the more dominant, similar L2
category is more selective in word recognition than that of the targets with the non-dominant
category, which can lead to distinct lexical representations for minimal pairs with confusable phonemes (Cutler et al. 2006; Weber and Cutler 2004). If the dominant-category-based
argument is correct, learners would have more difficulties in learning the lexical encoding of
the MSA pair // and /e/ than the pair /l/ and /r/. When learners were exposed to the /l/-/r/
pair, the /l/ member, which is a closer phonemic match to the native phoneme, would emerge
as the dominant category for lexical activation, and lexical dominance of one member of the
L2 contrast over the other would lead to contrastive lexical representations of the words with
this distinction. On the other hand, when the MSA //-/e/ pair is presented, such asymmetry
in the lexical activation would not be observed because these two sounds are equally remote
from the corresponding L1 phoneme. As a result, these two categories might be fully merged
in the lexical representation and learners would continue to encode words with this contrast
poorly in the lexical representation.
On the other hand, if orthographic information plays a crucial role in the development
of contrastive lexical representations (Escudero et al. 2008), these two sound pairs can
be developed differently depending on the way the corresponding letters are presented.
Instead of manipulating the availability of the target words' orthographic forms to learners as in Escudero et al. (2008), we present three conditions regarding the form of exposure
to spellings--namely, the target sound pairs are presented with distinct spelling forms, or
identical spelling forms, in addition to the pairs with only auditory forms. In the /l/-/r/ pair,
for example, learners are randomly assigned to one of the three groups where one group of
learners is exposed to the graphemes <l> and <r> for /l/ and /r/ phonemes, respectively; the
second group of learners is exposed to the grapheme <l> for both liquids; and the remaining
group is not exposed to any letters during the learning phase.
Thus, the main question of the present study is whether learners' ability to encode the
novel L2 contrasts lexically is primarily determined by the dominance of one of the two
members of the L2 contrast over the other, or the availability of orthographic information.

Method
Participants
Forty-eight native Korean speakers using the Seoul dialect (standard Korean) participated
in the experiment. All participants were born, raised, and educated in Korea and had never
lived outside Korea for more than 6 months. None of the participants had any familiarity with
Arabic and other languages that contain the target segments as phonemes. Participants were
randomly assigned to `auditory-only group' (8 males; mean 21.6 years; range 19-29 years),
`same-letter group' (9 males; mean 23.9 years; range 20-26 years), or `different-letter group'
(8 males; mean 22.0 years; range 19-25 years), with 16 participants for each group. None
of the participants reported any speech or hearing disorders, and they were all paid for their
participation.

123

J Psycholinguist Res (2018) 47:1015-1033

1019

Stimuli
The target words were 30 monosyllabic or bisyllabic MSA non-words that met the MSA
phonotactic constraints. Each set of five test words had one of the six test phonemes (/l/, /r/,
//, /e/, /m/, and /t/) as a word-initial onset. Among these, /l/ versus /r/ is a contrast with a
dominant L1 category in that these two phonemes are matched to the Korean /l/, whereas //
and /e/ are equally non-dominant phonemes for the Korean speakers. In addition to these two
types of target pairs, two additional phonemes such as /m/ and /t/ were included as controls,
both of which appear in MSA and Korean as separate phonemes. All stimuli were randomly
associated with pictures that represented simple objects, body parts, or animals. They were
black and white line drawings which were taken from Snodgrass and Vanderwart (1980) or
Cycowicz et al. (1997). The complete set of test words is presented in Appendix A. The
materials for the experiment were recorded by two female native speakers of MSA. Both
speakers were from Saudi Arabia, and their ages were 20 and 25 at the time of experiment.
They recorded the stimuli in a soundproof booth with a Shure KSM44 microphone and a Tascam (HD-P2) solid state recorder. The recorded tokens were digitized in Praat at a sampling
rate of 44.1 kHz and saved as 16-bit computer audio files to be used in the experiment.

Procedure
The experiment was administered in a 4-day long, consecutive experimental session for each
participant, as schematized in Table 1.
The participants were tested individually in a soundproof booth which had in it a computer
with E-prime (2.0 Professional) installed. The participants were first informed that they would
learn novel words from a language they had never been exposed to, which represented simple
objects, animals, or body parts. The detailed procedure was as follows:
Introduction to the stimuli Each participant was presented two times with a randomized list
of all 30 words with the corresponding pictures. When the spoken form of each word was
played over headphones (Sennheiser HD 590), the corresponding picture appeared on the
screen of the computer. All pictures were 196 x 137 pixels, resized to approximately 13 cm
horizontally and 9 cm vertically, and converted from .jpeg to .bmp format for compatibility
with the E-Prime software (E-Prime 2.0 Professional; Schneider et al. 2002). The spellings
Table 1 Experimental sessions
over 4 days

Day

Session

Task

1

1

Introduction to the stimuli

2

3

4

2

Learning 1

3

Test

1

Learning 2

2

Learning 3

3

Test

1

Learning 4

2

Learning 5

3

Test

1

AX discrimination
task/Lexical decision task

2

Spelling recall task

123

1020

J Psycholinguist Res (2018) 47:1015-1033

of whole words were presented to the different-letter group and the same-letter group.
However, the way the spellings of the test words were presented differed according to
the participant group. For the different-letter group, the letter corresponding to the onset
of each test word as in <l>, <r>, <x>, <h>, <m>, and <t> was presented with the picture
for the target words beginning with /l, r, , e, m, t/, respectively. For the same-letter
group, the test words had the spelling <l> for the words beginning with either /l/ or /r/,
and <h> for those beginning with either // or /e/. The control words were presented with
the spellings as in those for the different-letter group. The remaining participants in the
auditory-only group were not exposed to the spellings of novel words, and thus received
auditory input only. While participants were listening to the spoken form of each novel
word, the spellings appeared below the corresponding pictures, written in Arial 16-point
font. They were instructed to pay attention to the spellings of the words. The participants
were asked to memorize the association of spoken words to pictures and were allowed to
set the inter-stimulus-interval (ISI) by clicking the space bar on a keyboard. The actual
time each participant used to memorize the new words with pictures varied but did not
exceed 10 min.
Learning Each learning session consisted of two blocks. In the first block, each participant
heard the spoken form of a novel word via headphones. At the same time, two different
pictures appeared at the center of the screen, one of which was associated with the spoken
word while the other was not. The participant was asked to click on the target picture. The
way the spellings of the test words were presented was the same as in the introduction
of the stimuli. They were allowed to take as much time as they felt they needed and to
press `Enter' if they felt that they were ready to move on to the next word. If she/he
thought that the picture on the left was associated with the spoken word, the `1' key on
the keypad was to be pressed, while the `3' key was to be pressed if the picture on the
right was associated with the spoken word. If the response was correct, the English word
`correct' appeared on the screen; however, if the response was incorrect, the English word
`wrong' appeared on the screen. There was a 500 ms blank-screen interval between trials
and the ISI was 3 s. Each target word was heard two times in randomized order. In the
second block, each participant heard the spoken form of a novel word via headphones and
was asked to shadow the word. This method was based on the experimental results that
speech production affects the representations of newly learned words as in the way that
adults were faster to recognize new words that were produced than those that were heard
only during training (Zamuner et al. 2015). The way the spellings of the test words were
presented was also the same as in the first block. The ISI was again 3 s. The total number
of tokens was 120 (30 words x 2 repetitions x 2 blocks) and the whole learning session of
two blocks lasted approximately 10 min.
Test After learning sessions/session sets 1, 2/3, and 4/5, participants took a test that consisted of 30 words to examine how well they memorized the words and their scores were
computed for accuracy of responses. Participants heard the spoken form of a novel word
via headphones. At the same time, two different pictures appeared at the center of the
screen, one of which was associated with the spoken word while the other was not. The
spellings of the target words were not presented in the test. Each participant was asked to
click on the appropriate button for the target picture on the keypad such as `1', and `2'.
The ISI was 3 s and the test lasted approximately 3 min.
AX discrimination task In a categorial AX discrimination task, two stimuli were presented
through headphones with a 500 ms-ISI which should be long enough to induce phonemic
processing (Boomershine et al. 2008). Participants were asked to judge whether the initial
sounds of the two stimuli were either identical or different. They had 3 s to respond before

123

J Psycholinguist Res (2018) 47:1015-1033

1021

the next trial was initiated, and the correct responses were measured. For a given test item
(e.g., litaab), a non-word beginning with a confusable consonant (ritaab) was produced
and presented to test for any discrimination between the target phonemes, /l/ and /r/. 2 Four
counterbalanced orderings for the pairs were used, i.e., litaab-litaab (AA), litaab-ritaab
(AB), ritaab-litaab (BA), or ritaab-ritaab (BB), which resulted in 120 test pairs (30 test
words x 4 orderings). These 120 trials were presented in two randomized blocks separated
by a short break. Within each trial, the first and the second tokens were spoken by the
different female speakers. The purpose of the use of two different speakers' voices as
well as long ISI (500 ms) for the stimuli pairs was to ensure that listeners focused on
relevant phonetic properties that linked two tokens without being distracted by indexical,
phonetically irrelevant variation, as the auditory trace for sensory persistence is lost within
about 300 ms (Cowan 1984). Before the test, there was a practice session, where 12 test
words including 6 target phonemes were randomly presented. The inter-trial interval was
set at 3 s and the inter-block interval at 7 s, following Abramson (1979a, b). Participants
were instructed to press the `1' key on the keyboard for each trial upon hearing two identical
sounds and to press the `3' key upon hearing two different sounds. Participants were asked
to place their left and right index fingers on the `1' and `3' keys, respectively, to avoid
pressing the wrong keys. The participants were also asked to respond as quickly as possible
once they felt confident in their answers. Stimulus presentation and response collection
were implemented using the E-Prime program and the task lasted approximately 8-10 min.
Lexical decision task The 30 test words were used as real word tokens. Furthermore,
20 non-words were created based on MSA phonotactic constraints, all of which were
monosyllabic or bisyllabic words beginning with sounds of which 14 were different from
the target phonemes (e.g., baraf ) and the remaining 6 were the same as target phonemes.
In addition, 30 non-words were created in terms of changing the initial consonant of the
test words to a confusable phoneme (e.g., litaab `book'  ritaab). These words were
expected to be considered real words at first, but would be considered non-words when
they completely learned the target words (and/or phonemes). In total, there were 160 tokens
(80 items x 2 repetitions), which were randomized. Stimuli were divided into two blocks,
where the word and the non-word created with modification of the initial consonant (e.g.,
litaab and ritaab) were not in the same block. After a short practice, participants were
instructed to decide whether or not each token they heard was a real word of the language
they learned by pressing the designated key as quickly as possible. The participants were
asked to press the `1' key on the keypad if they were real words and the `3' key if they were
not. Participants had 3 s to respond before the next trial was initiated. Before they began
the task, they were informed that the number of tokens for real words and non-words could
be different. The lexical decision task lasted approximately 8-9 min. The order of the AX
discrimination and lexical decision tasks was counterbalanced.
Spelling recall task The participants were asked to write the spelling of each novel word.
The purpose of this task was to examine how the participants retained the spellings of
novel words in their mental lexicon. The picture of each novel word was provided on the
computer screen one by one, and the participants were asked to write the spellings of the
words on a sheet as they recalled. They were allowed to have as much time as they felt
they needed and then moved on to the following word by pressing the Enter key. Even the
auditory-only group of participants was asked to write the spellings of the words, using
English equivalents (in the Roman alphabet) of the MSA words.
2 Non-words whose initial onset phonemes were replaced by confusable consonants were also non-words in
MSA, with few exceptions (/xenzer/ `pig', /xobz/ `bread', and /eot/ `whale'). Since none of the participants
had any experience with Arabic, this difference in lexical status was of no consequence.

123

1022

J Psycholinguist Res (2018) 47:1015-1033

Results
A complete set of data from one participant (from the different-letter group) was excluded
from all analyses due to sloppy responses to the stimuli even before the spoken forms were
presented. The final data set includes the data from 47 subjects.

Word Learning Results
The purpose of the word-learning tests was to examine whether participants learned the
associations between the novel words and their corresponding pictures. A mixed analysis of
variance (ANOVA) was carried out on the participants' accuracy scores with Phoneme (/l/,
/r/, //, /e/, /m/, /t/), and Day of Learning (Day 1, Day 2, and Day 3) as within-participant
factors, and Participant Group (auditory-only, same-letter, and different-letter) as a betweenparticipant factor. The mean accuracy scores (%) of each phoneme across the three learning
sessions were 99.4, 97.5, 98.5, 98.5, 99.5, and 99.1 for /l/, /r/, //, /e/, /m/, and /t/, respectively
(see Appendix B for more details). Except for the control phoneme pair, the participants
showed the lowest scores for /r/ and the highest scores for /l/, the latter being close to those
of the control pair. The pair //-/e/ showed intermediate scores. The mean accuracies (%) of
each learning session were 98.2, 98.8, and 99.2 for Day 1, Day 2, and Day 3, respectively.
There was a significant main effect of Phoneme for the accuracy scores [F(5, 225) = 5.319,
p < .001]. There was also a significant effect of Day of Learning for the accuracy scores
[F(2, 90) = 5.670, p < .01]. The effect of Participant Group, however, was not statistically
significant [F(1, 45) = 1.633, p = .207]. None of the interactions among these three variables
were statistically significant [F(10, 225) = .870, p = .562 for Phoneme*Participant Group;
F(4, 90) = .412, p = .800 for Participant Group*Day of Learning; F(20, 450) = 1.440, p = .099
for Phoneme*Day of Learning*Participant Group]. The pairwise comparisons for Phoneme
indicated that there was a significant difference between /l/ (99.4) and /r/ (97.5) (p < .05), and
between /m/ (99.5) and /r/ (97.5) (p < .01). The differences between the other pairs, however,
were not significant (all p's > .05). The pairwise comparisons for Day of Learning showed
that the differences between Day 1 and Day 2, and those between Day 2 and Day 3 were
not significant, but the differences between Day 1 and Day 3 were significant (p < .05). The
statistical results reveal that the participants' learning scores gradually increased from the
first to the third day, and reached a ceiling by the end of the Day 3 learning session in terms
of accuracy, regardless of the participant group. Based on these results, we assume that after
three days of learning, the participants fully encoded the novel words, or associations of the
spoken forms and the corresponding pictures, even though they might not have established
native-like phonological representations for the test words.

AX Discrimination Results
Figure 1 summarizes the mean A scores in the AX discrimination task for each sound pair.
The discrimination accuracy scores were converted to A (A-prime) values. 3

3 As an index of discrimination accuracy, A-prime scores (A s) were calculated based on the proportion of "hits" obtained for each contrast and the proportion of "false alarms" (Snodgrass et al. 1985). If
the proportion of hits (Hs) equaled the proportion of false alarms (FAs), then A was set to 0.5. If H
exceeded FA, then A = 0.5 + ((H - FA) x (1 + H - FA))/((4 x H) x (1 - FA)). However, if FA exceeded H,
then A = 0.5 - ((FA - H) x (1 + FA - H))/((4 x FA) x (1 - H)). An A score of 1 indicated perfect sensitivity,
whereas an A score of 0.5 or lower indicated a lack of sensitivity.

123

J Psycholinguist Res (2018) 47:1015-1033

1023

Fig. 1 Mean discrimination scores for each sound pair by three groups of participants. The error bars represent
the standard errors

A mixed ANOVA was carried out on the mean A scores, with Sound Pair Group (/l//r/, //-/e/, and /m/-/t/) as a within-participant factor and Participant Group (auditory-only,
same-letter, different-letter) as a between-participant factor. The main effect of Sound Pair
Group [F(2, 88) = 184.14, p < .001] was significant, but there was no significant effect of
Participant Group [F(1, 44) = .599, p = .554] and no significant effect of interaction between
these two factors [F(4, 88) = .622, p = .648]. The pairwise comparisons showed that the A
scores of /m-t/ pair were significantly different from the other two pairs (/l-r/ and /-e/) (p
< .001), but those of the latter two pairs did not significantly differ from each other (p = .569).
The mean A scores for the control pair (/m/-/t/) reached a ceiling (.98), whereas both of the
other two pairs (/l/-/r/ and //-/e/) were similar to the chance level (.61 for pair /l/-/r/, .62
for pair //-/e/). The A scores of the same-letter group (.72) were similar to those of the
different-letter group (.76), both of which were similar to those of the control pair (.74). The
results of the AX discrimination task demonstrate that sound pairs which show a two-to-one
mapping relationship between L2 and L1 are not easily discriminated regardless of whether
one of their members is closer to the corresponding L1 category than the other. Furthermore,
these difficulties in discrimination are also not influenced by exposure to spellings.

Lexical Decision Results
In the lexical decision task, the accuracy scores were also converted to A scores, which were
then submitted to a mixed ANOVA, with Sound Pair Group (/l/-/r/, //-/e/, and /m/-/t/) as a
within-participant factor and Participant Group (auditory-only, same-letter, different-letter)
as a between-participant factor. The main effects of Sound Pair Group [F(2, 88) = 173.32, p
< .001] and Participant Group [F(1, 44) = 3.449, p < .05] were significant, and their interaction
effect was only marginally significant [F(4, 88) = 2.467, p = .051].

123

1024

J Psycholinguist Res (2018) 47:1015-1033

Fig. 2 Mean lexical decision scores for each sound pair by three groups of participants. The error bars represent
the standard errors

As shown in Figure 2, mean A scores for the lexical decision task for pair //-/e/ were
lower (.75) than those for pair /l/-/r/ (.79), which were in turn lower than those for the control
pair (/m/-/t/) (.98). Planned pairwise comparisons showed that the mean A scores in the lexical decision between pair //-/e/ and pair /l/-/r/ were significantly different (p < .05). As for
the effect of Participant Group, the auditory-only group participants showed higher values
(.87) than the other two group participants, but the latter groups did not show large differences
(.82 for the same-letter group, and .83 for the different-letter group). Planned pairwise comparisons showed that the differences of mean A scores between the auditory-only group and
the same-letter group were significant (p < .05), and those between the auditory-only group
and the different-letter group were marginally significant (p = .05), while those between the
same-letter group and the different-letter group were not significant (p = .706). These results
indicate that unlike for sound categorization (AX discrimination), there is an asymmetrical
pattern for lexical access between the two target pairs, /l/-/r/ and //-/e/. Namely, during
the early stage of learning, participants began to show improvement of lexical encoding for
pair /l/-/r/ earlier than for pair //-/e/. However, there may be no orthographic effect; rather,
orthographic information appeared to hinder the acquisition of the target categories in the
lexical access. Participants showed higher scores in the lexical access when they were presented with the auditory input only than when they were provided with spellings, whether
they contained distinct or identical letters for the sounds in the target pair.

Spelling Recall Results
Spelling recall accuracy was used to evaluate whether the target words were properly stored
in the lexicon of the participants. The participants' responses were hand-scored for accuracy
by the first author. The results are presented in Table 2.
Table 2 shows the percentage of accurate responses and error types according to the
consonant pair types which were incorrectly spelled. The accuracy scores were only based

123

J Psycholinguist Res (2018) 47:1015-1033

1025

Table 2 Mean accuracy scores and error types for each sound pair in the spelling recall task (%)
Learner group

Accuracy

Error types
/m-/t/

/l/-/r/

//-/e/

Auditory only

62.7

26 (n = 42)

36 (n = 57)

49 (n = 79)

Same letter

99.3

.006 (n = 1)

.006 (n = 1)

.006 (n = 1)

Different letter

96.7

0

.013 (n = 2)

.087 (n = 13)

on the target consonants in initial position. Both same-letter and different-letter groups of
participants showed responses corresponding to the given letters, succeeding in writing the
spellings of each novel word close to a ceiling. However, the responses from the auditory-only
group participants were somewhat different from those from the two letter groups (sameletter and different-letter). Recall that the auditory-only group participants were not provided
with any orthographic information during the learning stage, and thus they were asked to
write the spellings of the target consonants using the Roman alphabet. Consequently, we
expect that their spellings would be rather faithful to the given sound inputs. Considering
this, their results were evaluated based on whether the target phonemes of the contrast (i.e.,
/l/-/r/ and //-/e/) were spelled with two distinct letters, rather than whether the letters for
the target phonemes were for the corresponding phonemes (e.g., <l> for [l] and <r> for [r]).
Still it was observed that their accuracy was 62.7%. Close inspection of the error types from
all three participant groups reveals an asymmetry between the /l/-/r/ and //-/e/ pairs: the
pair //-/e/ showed more errors than the pair /l/-/r/. For instance, the different-letter group
participants made two errors for the pair /l/-/r/, but 13 errors for //-/e/. The most crucial
consequence in this task was that the scores from the learners presented with different letters
for the target pair (different-letter group) were shown to be close to a ceiling (96.7%), even
though the same group participants did now show a main effect of orthographic information
in the lexical decision task.

General Discussion
In this study, we investigated two plausible explanations for the asymmetrical patterns of
lexical access, namely, acoustic proximity to the nearest L1 category and metalinguistic
influence such as orthographic information. We employed a word-learning experiment in
which the native speakers of Korean learned MSA nonwords beginning with two different
types of sound pairs--those with, and those without, a corresponding L1-dominant category.
The participants were also divided into three subgroups depending on the way orthographic
information was provided: one group was presented with the same letters for the confusable
sound pair, the second group, distinct letters for the pair, and the third group, auditory input
only. Subsequently, their patterns of phonetic categorization of the sound pairs and lexical
decision of the novel words with those sounds were examined in AX discrimination and
lexical decision tasks, respectively.
The results of the AX discrimination task did not show any effect of phonetic proximity
to the L1 category nor orthography to phonetic categorization. The discrimination of the
target sound pairs was poor as compared to that of the control pair, regardless of whether
one of their members was closer to the corresponding L1 category than the other. Addition-

123

1026

J Psycholinguist Res (2018) 47:1015-1033

ally, the discrimination performance was not influenced by exposure to the spellings. All
three participant groups (auditory-only group, same-letter group, and different-letter group)
exhibited very similar discrimination scores. In lexical encoding, however, the pair with an
L1-dominant category was more accurately encoded than one without such category. The
lexical decision scores for the pair with an L1-dominant category were much lower than those
for the control pair, but significantly higher than those for the pair without such category.
Surprisingly, lexical decision was not facilitated by exposure to spellings and in fact, orthographic information was shown to hinder the lexical encoding. The participants who were
provided with orthographic information showed lower lexical decision scores than those with
auditory input only, regardless of the letter types given. However, in the subsequent spelling
recall task, the scores from the learners presented with different letters for the target pair
(e.g., <l> for /l/, <r> for /r/) were shown to be close to a ceiling. It is also noteworthy that
there were still differences in the accuracy of spelling recall between the sound pair containing an L1-dominant category and one without such category such that the spellings of the
former were more correctly written than those of the latter.
The results of the present study have important implications on the relationship between
phonetic categorization and lexical encoding of the confusable L2 contrasts. The present
results provide evidence for dissociation between phonetic categorization and lexical encoding of the L2 contrasts. Until recently it was widely accepted that L2 learners need to establish
robust phonetic L2 categories to create lexical representations (e.g., Pallier et al. 1997;
Sebastian-Galles and Baus 2005). All previous studies in this stream showed that lack of
phonetic distinction for the confusable phonemes in L2 (e.g., /2/-/ae/ for Dutch learners of
English) leads to an inability to differentiate lexical representations for two separate lexical items (e.g., pen and pan). This is directly related to the way L2 learners perceive the
phonological contrasts in L2; L2 learners start with low-level acoustic input and then analyze
the input to convert the output of phonetic analysis into abstract phonological representation
(Gor 2015). However, a recent body of research (e.g., Darcy et al. 2012; Escudero et al.
2008; Weber and Cutler 2004) has provided evidence that L2 learners may establish lexical
contrasts with enough input from the target language, even though they still show persistent
perceptual difficulties in the categorization of the sound contrasts. It was shown in Weber and
Cutler (2004), for instance, that in an eye-tracking task, English non-words containing /ae/
(e.g., /taendk/) trigger looks to pictures of /ae/- and /2/- words, whereas English non-words
with /2/ only trigger looks to pictures of /2/- words (/t2nzr/). These results were taken to
mean that Dutch learners of English cannot discriminate /2/ and /ae/ auditorily, but they contrast these two vowels lexically. With regard to the present results, if the difficulty in phonetic
categorization extended to the language processing system at all levels, then we would expect
the words beginning with those confusable sounds to be homophonous. This does not appear
to be the representation of words containing such sounds, however; lexical encoding of the
novel words beginning with /r/ was shown to be poor as compared to that of words beginning
with /l/.
Given the dissociation between phonetic categorization and lexical encoding instead of
a causal relationship between them, an immediate question arises as to what causes such
dissociation between them. Among a number of possible factors, we examined the phonetic
similarity between L1 and L2 sound contrasts and orthographic information in this study.
First, with respect to the role of phonetic similarity between L1 and L2 sound contrasts, it
had no sizable effect in phonetic categorization, but its impact on lexical encoding was quite
solid. The null effect of L1-dominant category in phonetic categorization was also observed
in a previous study (Mahmoud 2013). Mahmoud examined the perceptual discriminability
of various consonantal phonemes in MSA by native English speakers and found that the

123

J Psycholinguist Res (2018) 47:1015-1033

1027

beginner level of learners did not show statistical differences in AXB discrimination between
the phoneme pairs /k/-/q/ and //-/e/. This result indicates that both types of consonantal
contrasts are comparably difficult for English learners. In the pair /k/-/q/, the velar stop, /k/,
is similar to the native phoneme (/k/), while the uvular stop, /q/, is a new sound. On the other
hand, both // and /e/ are absent in English. The relationship between these sound pairs is
comparable to that of /l/-/r/ and //-/e/ in the present study. Similar to Mahmoud, in the
present results, there was no difference in discrimination of the target sound pairs between
the sound pair with one member closer to the corresponding L1 category than the other, and
the pair without such category.
In lexical encoding, however, indiscriminability of the novel words with two target sound
pairs was not equivalent: the pair with an L1-dominant category was more accurately encoded
than that without such category. Recall that MSA /l/ is phonetically closer to the Korean liquid than MSA /r/ so that /l/ is a candidate for the dominant category to the Korean learners,
whereas the pair //-/e/ does not show such dominant relationship. The lexical words which
contained the dominant phoneme (/l/) appeared to be more active than those containing the
non-dominant category (/r/). Accordingly, this distinction might have been facilitative in
incorporating the differences of the target sounds in the Korean learners' lexical representations of the target words containing those sounds. Similarly, in the spelling recall task,
words containing /l/ and /r/ were neatly discriminated and thus correctly spelled at a ceiling.
The present results are in line with those of previous studies like Cutler et al. (2006) and
Weber and Cutler (2004), where the confusable phonemes are not equivalent, but one sound
of the contrast is clearly dominant. In Weber and Cutler (2004) the dominant category is
/2/ from among /2/ and /ae/, and in Cutler et al. (2006), it is /l/ between /l/ and /r/. These
dominant phonemes are phonetically/acoustically closer to the native phonemes. The perceptual representations of these dominant phonemes (/2/ and /l/) appear to get access to their
lexical representations accurately, because the dominant phonemes are more active than the
non-dominant phonemes. This dominance can lead to separate lexical representation of the
contrast in question (/2/-/ae/ and /l/-/r/).
Second, the effect of orthographic information was not observed in the results of phonetic
categorization. This is just as expected given the results for phonetic similarity between L1
and L2 sound contrasts. The findings regarding the role of orthographic knowledge in L2
learners' establishment of lexical representations, however, are not consistent. The orthographic information did have a positive effect in spelling recall, but not in lexical decision.
The Korean learners of MSA were not able to retrieve the words with target sounds at the
lexical level during online spoken-word recognition, but they could represent them accurately
in their L2 lexicon if they were allowed to use as much time as they wanted. These findings suggest that orthographic information might indeed help L2 learners to have target-like
representations despite difficulties in online processing.
Given the inconsistent results between the lexical decision task and the spelling recall task,
it is difficult to judge whether the present results support either Cutler et al. (2006) or Escudero
et al. (2008). Recall that Cutler et al. (2008) provided evidence against the explanation based
on orthographic knowledge; for Japanese learners of English, English /l/, but not /r/, was
the dominant category because /l/ is phonetically closer to the Japanese liquid consonant,
but the matched Japanese liquid consonant is always written in Romanji with the letter <r>.
On the other hand, Escudero et al. (2008) argued that abstract knowledge in the form of
grapheme-phoneme mappings is exploited in the creation of a phonological representation
for newly acquired L2 words. Escudero et al. replicated Weber and Cutler (2004) with the
manipulation of orthographic knowledge and found that the asymmetrical lexical activation
between words containing the contrast (/2/ and /ae/) is triggered by knowledge of spelled forms

123

1028

J Psycholinguist Res (2018) 47:1015-1033

of words. When only auditory forms of novel L2 words were available, listeners showed an
equal number of fixations on pictures of the words containing /2/ and /ae/.
The results of the present study thus need to be interpreted with caution. In fact, the
results of the lexical decision task and the spelling recall task have important implications
for the issue of phonological representation versus phonological processing of L2 words.
McDonald (2006) proposed that late L2 learners' poor performance in accessing and using
relevant grammatical knowledge could be caused by processing difficulties stemming from
low memory capacity, poor decoding and lexical access abilities, and/or slow processing
speed. According to this view, L2 learners are predominantly bottom-up processors; they
focus too much attention on identifying sounds and words that they do not have enough
time or working memory capacity in order to build higher-level units of representation. In a
related line of research, Lopez and Gabriele (2014) examined two accounts of morphological
variability in L2, representational and computational accounts. The representational accounts
posit a deficit in the L2 grammar since parameter setting is not possible after a certain age.
Therefore, late learners cannot acquire native-like abstract representations of new features
not in L1, which leads to an incomplete L2 grammar. On the other hand, in the computational
accounts, learner variability may stem from difficulty in processing, rather than from a deficit
in the L2 grammar. In these accounts, native-like attainment is in principle possible, regardless
of the learners' age of acquisition and of differences between the L1 and the L2 contrasts. The
morphological variability in L2 appears to be under a processing burden. Following these
views, it is quite reasonable to observe that Korean learners of MSA perform at a ceiling in
offline tasks, as shown in the spelling recall task, yet they show much worse results in more
cognitively demanding online tasks, as shown in the lexical decision task with (possibly)
short ISI.
It is important to note that the present study captures the initial stage of the learning process, whereas the learners in previous studies were mostly proficient L2 learners (Cutler et al.
2006; Escudero et al. 2008; Hayes-Harb and Masuda 2008; Nakai et al. 2015; Weber and Cutler 2004). Although this study employed a simple artificial language paradigm, the Korean
learners of MSA might remain in the early stage of learning and thus they might have much
difficulty in learning such confusable sound contrasts of an unfamiliar language even at the
end of the experiment. With enough input from the target language, they might show better
performance in the lexical decision task, since L2 learners' lexical representations are gradually encoding all phonological contrasts accurately (Darcy et al. 2013). It is worth mentioning
here the results of Veivo and Jarvikivi (2013) and Veivo et al. (2016), where orthography
was shown to play a role in L2 spoken-word recognition only for relatively advanced learners with a relatively established mental representation of the L2 lexicon. Veivo and Jarvikivi
(2013) examined orthographic effects in a lexical decision task with cross-modal priming, and
showed that both within-language (L2) repetition primes and between-language (L1  L2)
primes with shared orthography produced stronger effect with higher-proficiency learners.
For example, in their Experiment 2, the authors investigated orthographic and phonological
influences from L1 Finnish on L2 French using a masked cross-modal priming technique.
They created three Finnish-based visual primes which were associated with the French auditory targets: 1) orthographic onset overlap (e.g., prime: L1 <huivi> ([huivi] `scarf'), target: L2
[4il] (<huile> `oil'); 2) Finnish (L1)-based pseudohomophones (e.g., prime: L1 <yil> ([yil]
`non-word'), target: L2 [4il]; and 3) unrelated controls. Veivo and Jarvikivi found that
when the learners at two ends of the proficiency scale were compared, the high-proficiency
group showed facilitation in the latencies in the purely orthographic condition of L1 Finnish
real-word primes (condition 1 as above), whereas the lower-intermediate group showed no
facilitation in this condition, but did benefit from the phonological condition consisting of L1

123

J Psycholinguist Res (2018) 47:1015-1033

1029

Finnish non-words that are pronounced like the targets (condition 2 as above). This finding
suggests that high-proficiency L2 learners activate orthography automatically in spoken-word
recognition, whereas lower-proficiency L2 learners rely more on phonological processing.
Veivo et al. (2016) further posit that even low-proficiency L2 learners "may co-activate
orthography in spoken word recognition sublexically, but more advanced learners may have
integrated orthographic and phonological information to common abstract representations
leading to orthographic activation at the whole word level" (p. 3).
In sum, examination of the phonetic categorization and lexical encoding of the MSA words
with confusable sound pairs by Korean learners demonstrates that both acoustic/phonetic
proximity to the nearest native-language category and metalinguistic influences such as
orthographic information have an influence on the asymmetrical pattern between phonetic
and lexical learning. At least at an early stage of learning, however, phonetic similarity to
the nearest L1 category plays a more important role than orthographic information. While
much work remains to be done to understand the relationship between phonetic and lexical
learning, the present study empirically demonstrates how these two sources have effects on
the dissociation between phonetic categorization and lexical encoding.
Acknowledgements An earlier version of the work was presented in PSLLT 2017 conference at Salt Lake
City. We thank the audience of the conference and also anonymous reviewers for their helpful and constructive
comments.
Funding This work was supported by the Ministry of Education of the Republic of Korea and the National
Research Foundation of Korea (NRF-2015S1A5A2A01011545).
Compliance with Ethical Standards
Conflicts of interest The authors declare that they have no conflict of interest.
Ethical Standards The authors declare that they followed the guidelines in every respect.
Informed Consent The authors received the informed consent forms from the human participants.

Appendix A: Test Words
Target sound

Spelling for
`same-letter'
group

Spelling for
`different-letter'
group

Meaning

/l/

<laima>

<lai-ma>

Banana

<litaab>

<litaab>

Book

<lazeem>

<lazeem>

Cat

<lem-sah>

<lem-sah>

Piano

Picture

123

1030
Target sound

/r/

/e/

//

123

J Psycholinguist Res (2018) 47:1015-1033
Spelling for
`same-letter'
group

Spelling for
`different-letter'
group

Meaning

<lesht>

<lesht>

Ear

<latah>

<ratah>

Apple

<ladaak>

<radaak>

Airplane

<lofaz>

<rofaz>

Giraffe

<looq>

<rooq>

Pencil

<leb-ham>

<reb-ham>

Shoe

<henzer>

<henzer>

Traffic light

<hazam>

<hazam>

Rat

<harool>

<harool>

Strawberry

<hobs>

<hobs>

Glasses

<hemaj>

<hemaj>

Butterfly

<hobooz>

<xobooz>

Turtle

<harooq>

<xarooq>

Umbrella

<hot>

<xot>

Cup

<heqaad>

<xeqaad>

Wrist watch

Picture

J Psycholinguist Res (2018) 47:1015-1033
Target sound

/m/

/t/

1031

Spelling for
`same-letter'
group

Spelling for
`different-letter'
group

Meaning

<hamer>

<xamer>

Sun

<muf-fah>

<muf-fah>

Balloon

<melfaz>

<melfaz>

Toothbrush

<morf>

<morf>

Star

<mawoos>

<mawoos>

Lip

<meraal>

<meraal>

Foot

<tesbaah>

<tesbaah>

Bicycle

<turan>

<turan>

Snowman

<teek>

<teek>

Train

<tom-yah>

<tom-yah>

Scissors

<taqma>

<taqma>

Socks

Picture

Appendix B: Mean (Standard Errors) Accuracy Scores in the WordLearning Tests
Participant group

Auditory only

Sound

Day of learning
Day 1

Day 2

Day 3

/l/

1.000 (.007)

1.000 (.007)

1.000 (.000)

/r/

.963 (.020)

.975 (.011)

.994 (.006)

/e/

.994 (.007)

.988 (.013)

.994 (.010)

123

1032
Participant group

J Psycholinguist Res (2018) 47:1015-1033
Sound

Day of learning
Day 1

Same-letter

Different-letter

Day 2

Day 3

//

.975 (.013)

1.000 (.009)

1.000 (.007)

/m/

.994 (.006)

.994 (.005)

.988 (.005)

/t/

.994 (.005)

.988 (.009)

.994 (.009)

/l/

.969 (.007)

.988 (.007)

1.000 (.000)

/r/

.925 (.020)

1.000 (.011)

.988 (.006)

/e/

.988 (.007)

.969 (.013)

.963 (.010)

//

.981 (.013)

.975 (.009)

.975 (.009)

/m/

.988 (.006)

.994 (.005)

1.000 (.005)

/t/

1.000 (.005)

.988 (.009)

.994 (.009)

/l/

1.000 (.007)

.988 (.007)

1.000 (.000)

/r/

.944 (.020)

.988 (.009)

1.000 (.006)

/e/

.994 (.007)

.981 (.013)

.994 (.010)

//

.981 (.013)

.981 (.009)

.994 (.009)

/m/

1.000 (.006)

1.000 (.005)

1.000 (.005)

/t/

.994 (.005)

.988 (.009)

.981 (.009)

References
Abramson, A. S. (1979a). The coarticulation of tones: An acoustic study of Thai. In T. L. Thongkum, P.
Kullavanijava, V. Panupong, & K. Tingsabadh (Eds.), Studies in Tai and Mon-Khmer phonetics and
phonology in honour of Eugenie T. A. Henderson (pp. 10-25). Bangkok: Indigenous Languages of
Thailand Research Project.
Abramson, A. S. (1979b). The noncategorical perception of tone categories in Thai. In B. Lindblom & S.
Ohman (Eds.), Frontier of speech communication research (pp. 127-134). London: Academic Press.
Al-Ani, S. H. (1970). Arabic phonology. The Hague: Mouton.
Amayreh, M. M. (2003). Completion of the consonant inventory of Arabic. Journal of Speech, Language, and
Hearing Research, 46, 517-529.
Barrios, S., Jiang, N., & Idsardi, W. J. (2016). Similarity in L2 phonology: Evidence from L1 Spanish latelearners' perception and lexical representation of English vowel contrasts. Second Language Research,
32(3), 367-395.
Best, C. T. (1995). A direct realist view on cross-language speech perception. In W. Strange (Ed.), Speech
perception and linguistic experience: Theoretical and methodological issues in cross-language speech
research (pp. 171-204). Timonium, MD: York Press.
Best, C. T., & Tyler, M. D. (2007). Nonnative and second-language speech perception: Commonalities and
complementarities. In O. S. Bohn & M. J. Munro (Eds.), Language experience in second language speech
learning: In honor of James Emil Flege (pp. 13-34). Amsterdam: John Benjamins.
Boomershine, A., Hall, K. C., Hume, E., & Johnson, K. (2008). The impact of allophony versus contrast
on speech perception. In P. Avery, B. E. Dresher, & K. Rice (Eds.), Contrast in phonology: Theory,
perception, acquisition (pp. 146-172). Berlin: Mouton de Gruyter.
Broersma, M. (2012). Increased lexical activation and reduced competition in second-language listening.
Language and Cognitive Processes, 27, 1205-1224.
Cowan, N. (1984). On short and long auditory stores. Psychological Bulletin, 96(2), 341-370.
Cutler, A., Weber, A., & Otake, T. (2006). Asymmetrical mapping from phonetic to lexical representations in
second-language listening. Journal of Phonetics, 34, 269-284.
Cycowicz, Y. M., Friedman, D., & Rothstein, M. (1997). Picture naming by young children: Norms for name
agreement, familiarity, and visual complexity. Journal of Experimental Child Psychology, 65, 171-237.
Darcy, I., Daidone, D., & Kojima, C. (2013). Asymmetrical lexical access and fuzzy lexical representations
in second language learners. The Mental Lexicon, 8, 372-420.

123

J Psycholinguist Res (2018) 47:1015-1033

1033

Darcy, I., Dekydtspotter, L., Sprouse, R. A., Glover, K. C., Kaden, C., McGuire, M., et al. (2012). Direct
mapping of acoustics to phonology: On the lexical encoding of front rounded vowels in L1 English-L2
French acquisition. Second Language Research, 28, 5-40.
Diaz, B., Mitterer, H., Broersma, M., & Sebastian-Galles, N. (2012). Individual differences in late bilinguals'
L2 phonological processes: From acoustic-phonetic analysis to lexical access. Learning and Individual
Differences, 22, 680-689.
Escudero, P., Broersma, M., & Simon, E. (2013). Learning words in a third language: Effects of vowel inventory
and language proficiency. Language and Cognitive Processes, 28(6), 746-761.
Escudero, P., Hayes-Harb, R., & Mitterer, H. (2008). Novel L2 words and asymmetrical lexical access. Journal
of Phonetics, 36(2), 345-360.
Gor, K. (2015). Phonology and morphology in lexical processing. In J. W. Schwieter (Ed.), The Cambridge
handbook of bilingual processing (pp. 173-199). Cambridge: Cambridge University Press.
Han, J.-I., Jeon, M., & Oh, S. (2017). Examining the temporal development of phonetic and lexical learning
in second language. Psychological Reports, 120(5), 785-804.
Hayes-Harb, R., & Masuda, K. (2008). Development of the ability to lexically encode novel second language
phonemic contrasts. Second Language Research, 24(1), 5-33.
Klatt, H., & Stevens, K. N. (1969). Pharyngeal consonants. Quarterly Progress Report, Research Laboratory
of Electronics, MIT, 93, 207-216.
Lopez, P. B., & Gabriele, A. (2014). Examining the impact of task demands on morphological variability in
native and non-native Spanish. Linguistic Approaches to Bilingualism, 4, 192-221.
Mahmoud, M. S. A. (2013). Discrimination of Arabic contrasts by American learners. Studies in Second
Language Learning and Teaching, 2, 261-291.
McDonald, J. L. (2006). Beyond the critical period: Processing-based explanations for poor grammaticality
judgment performance by late second language learners. Journal of Memory and Language, 55, 381-401.
Nakai, S., Lindsay, S., & Ota, M. (2015). A prerequisite to L1 homophone effects in L2 spoken-word recognition. Second Language Research, 31, 29-52.
Ota, M., Hartsuiker, R. J., & Haywood, S. L. (2009). The KEY to the ROCK: Near-homophony in nonnative
visual word recognition. Cognition, 111, 263-269.
Pallier, C., Bosch, L., & Sebastian-Galles, N. (1997). A limit on behavioral plasticity in speech perception.
Cognition, 64, B9-B17.
Pallier, C., Colome, A., & Sebastian-Galles, N. (2001). The influence of native-language phonology on lexical
access: Exemplar-based versus abstract lexical entries. Psychological Science, 12, 445-449.
Rastle, K., McCormick, S. F., Bayliss, L., & Davis, C. J. (2011). Orthography influences the perception
and production of speech. Journal of Experimental Psychology. Learning, Memory, and Cognition, 37,
1588-1594.
Schneider, W., Eschman, A., & Zuccolotto, A. (2002). E-Prime 10. Pittsburgh, PA: Psychological Software
Tools.
Sebastian-Galles, N., & Baus, C. (2005). On the relation between perception and production in L2 categories.
In A. Cutler (Ed.), Twenty-first century psycholinguistics: Four corner stones (pp. 279-292). New York:
Erlbaum.
Shin, J., Kiaer, J., & Cha, J. (2013). The sounds of Korean. Cambridge: Cambridge University Press.
Snodgrass, J. G., Levy-Berger, G., & Haydon, M. (1985). Human experimental psychology. New York: Oxford
University Press.
Snodgrass, J. G., & Vanderwart, M. (1980). A standardized set of 260 pictures: Norms for name agreement, image agreement, familiarity, and visual complexity. Journal of Experimental Psychology: Human
Learning and Memory, 6, 174-215.
Veivo, O., & Jarvikivi, J. (2013). Proficiency modulates early orthographic and phonological processing in L2
spoken word recognition. Bilingualism: Language and Cognition, 16(4), 864-883.
Veivo, O., Jarvikivi, J., Porretta, V., & Hyona, J. (2016). Orthographic activation in L2 spoken word recognition
depends on proficiency: Evidence from eye-tracking. Frontiers in Psychology, 7, 1120.
Watson, J. C. E. (2002). The phonology and morphology of Arabic. Oxford: Oxford University Press.
Weber, A., & Cutler, A. (2004). Lexical competition in non-native spoken-word recognition. Journal of Memory
and Language, 50, 1-25.
Younes, M. A. (1994). On emphasis and /r/ in Arabic. In M. Eid, V. Cantarino, & K. Walters (Eds.), Perspectives
on Arabic linguistics VI (pp. 215-235). Amsterdam: John Benjamins Publishing Company.
Zamuner, T. S., Morin-Lessard, E., Strahm, S., & Page, M. P. A. (2015). Spoken word recognition of novel
words, either produced or only heard during learning. Journal of Memory and Language, 89, 55-67.

123

