The Role of Selected Lexical Factors
on Confrontation Naming Accuracy,
Speed, and Fluency in Adults Who
Do and Do Not Stutter
Rochelle S. Newman
Nan Bernstein Ratner
University of Maryland

Purpose: The purpose of this study was to investigate whether lexical access in adults
who stutter (AWS) differs from that in people who do not stutter. Specifically, the
authors examined the role of 3 lexical factors on naming speed, accuracy, and
fluency: word frequency, neighborhood density, and neighborhood frequency. If
stuttering results from an impairment in lexical access, these factors were hypothesized
to differentially affect AWS performance on a confrontation naming task.
Method: Twenty-five AWS and 25 normally fluent comparison speakers, matched for
age and education, participated in a confrontation naming task designed to explore
within-speaker performance on naming accuracy, speed, and fluency based on
stimulus word frequency and neighborhood characteristics. Accuracy, fluency, and
reaction time (from acoustic waveform analysis) were computed.
Results: In general, AWS demonstrated the same effects of lexical factors on their
naming as did adults who do not stutter. However, accuracy of naming was reduced
for AWS. Stuttering rate was influenced by word frequency but not other factors.
Conclusions: Results suggest that AWS could have a fundamental deficit in lexical
retrieval, but this deficit is unlikely to be at the level of the word's abstract phonological
representation. Implications for further research are discussed.
KEY WORDS: stuttering, lexical access, naming

A

lthough the underlying causes of stuttering are not known, there
are a number of linguistic regularities that characterize stutter
events in both adults and children (see Bernstein Ratner, 1997, for
a review). As a result, a number of authors (see, e.g., Howell, Au-Yeung, &
Sackin, 2000; Karniol, 1995; Perkins, Kent, & Curlee, 1991; Postma &
Kolk, 1993) have suggested that its distal or proximate cause may lie in
some weakness in retrieving or assembling utterance elements. Phonological encoding, lexical retrieval, and syntactic encoding have each been
investigated as specific stages in the speech production process that might
be disrupted in stuttering.
It remains unclear whether stuttering moments reflect impairment in
linguistic processing or are the result of more generalized capacity limitations that may affect the motoric encoding of linguistic elements (see
Bosshardt, Ballmer, & de Nil, 2002; Weber-Fox, Spencer, Spruill, & Smith,
2004, for support for such a multifactorial view of the core deficit in stuttering). However, the notion that the problem could potentially lie in an
aspect of phonological, lexical, or syntactic retrieval or encoding suggests
that further examination of these stages of processing is warranted. The
196 Journal of Speech, Language, and Hearing Research *

Vol. 50 * 196-213 * February 2007 * D American Speech-Language-Hearing Association
1092-4388/07/5001-0196

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/17/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

current article focuses particularly on the stage of lexical
access. In the sections that follow, we describe both what
is known about lexical organization and access, and, in
particular, the lexical retrieval skills of individuals who
stutter.

(Levelt, 1999). They may, however, occur at slightly different stages in processing, because word frequency involves
a word's complete form, whereas phonological pattern frequency involves the frequency of sublexical units (see Luce
& Pisoni, 1998; Vitevitch & Luce, 1998).

Models of Lexical Access

Lexical Factors in Typical
Speech Production

Contemporary models of word production suggest
that lexical access consists of a series of distinct stages,
including (at least), conceptual preparation, lemma retrieval, and word-form encoding (Levelt, Roelofs, & Meyer,
1999; Roelofs, 1992). The last stage consists of a number
of different substages, including accessing the word form
as a whole and accessing sublexical units that make up
that word form. One adapted model of language production focuses on single-word retrieval (German, 2000). This
model is based on work by Levelt and colleagues (Levelt,
1989, 1991, 1999), and contains four stages. During the
process of naming a picture, the first stage involves the
picture eliciting the conceptual structure or underlying
concepts associated with a target word (Bierswisch &
Schreuder, 1991). In the second stage, activation spreads
from this conceptual structure to the target word's lemma
(its semantic and syntactic features), selecting that lemma
from among neighboring entries (Garrett, 1991). In the
third stage, activation spreads from the lemma to the
entry's corresponding abstract phonological properties (its
syllabic frame and phonemic units); this results in the creation of a complete phonological schema (Levelt, 1991).
Finally, in the fourth stage, a motor plan is created and
forwarded to lower level articulation processes in order
to produce the word. Although the extent to which this
adapted model and its components are fully descriptive of
lexical retrieval awaits further investigation, this model
has been fruitfully applied to a number of clinical and
typical populations (German, 2000; German & Newman,
2004; Newman & German, 2002, 2005).
Although there are competing models of both lexical
access and production (Dell, 1986; Luce & Pisoni, 1998),
Levelt and colleagues' model (known as WEAVER++;
Roelofs, 2000) has most frequently been applied to linguistic analyses of stuttering (e.g., Postma & Kolk, 1993;
Wijnen & Boers, 1994; Yaruss & Conture, 1996). We therefore selected this model as an underlying framework for
examining factors that might influence lexical access in
adults who do and do not stutter.
This model, as well as models based on it, makes certain predictions regarding the impact of lexical factors on
the ease of access and production (German, 2000; Levelt,
1999). For example, it should be easier to access a word's
phonological form if that word is encountered more frequently in the language. Similarly, words with more common phonological patterns should be easier to access. Both
of these effects occur in a stage following lemma activation

A number of factors appear to organize the mental
lexicon and influence ease of lexical retrieval. These factors include the frequency with which a word occurs and
its similarity in phonological form to other known words.

Word Frequency
Some words occur more frequently in the language
than do others, and this influences how easily they are accessed. Studies suggest that high-frequency words are produced more quickly (Jescheniak & Levelt, 1994; Lachman,
Shaffer, & Hennrikus, 1974; Oldfield & Wingfield, 1965),
are less likely to be involved in speech production errors
(Dell, 1988; Vitevitch, 1997, 2002), and result in fewer
tip-of-the-tongue states in both young and older speakers
(Vitevitch & Sommers, 2003). This effect of word frequency
appears to be relatively constant across adulthood, although it tends to be larger among children than adults
(Newman & German, 2005).

Lexical Neighborhood
Another potential source of lexical access differences
comes not from the words themselves, but from their
similarity to other words the individual knows. According
to the Neighborhood Activation Model (Luce & Pisoni,
1998), the process of discriminating among possible words
is "a function of the number and I acoustic-phonetic
similarity among the activated lexical items" (p. 12). Although this model was designed to focus on distinguishing among possible lexical items perceptually, the basic
notion is that selecting a particular word will depend not
only on properties of that word, but also on its phonological similarity to other known words. Some words will be
similar to many other words (e.g., the word let is similar
to bet, less, lent, and light, among many others), whereas
other words will be similar to far fewer (e.g., the word kept
is similar to only three other English words, crept, Celt,
and wept).1 These storage differences can affect how words
are accessed. Words from dense neighborhoods (those similar to many words) tend to be repeated aloud (named)
1
Although some past tense forms, such as capped, might be considered to be
phonological neighbors and indeed, there is ongoing debate on this concept,
current research tends to favor a view in which regular past tense and
plural markings are decomposed (see Frost, Grainger, & Rastle, 2005).
Thus, we presume that the lexicon does not have separate entries for
regular past tense or pluralized forms, and such forms do not count as
neighbors.

Newman & Bernstein Ratner: Lexical Effects in Adults Who Stutter

197

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/17/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

more slowly than words in sparse neighborhoods (Luce
& Pisoni, 1998), presumably as a result of the confusability of the target word and its phonological neighbors.
However, the accuracy of word retrieval appears to be
enhanced by the presence of neighbors, perhaps because
they help the speaker reach the appropriate region of
lexical space. Both phonological (Vitevitch, 2002) and
tip-of-the-tongue (Harley & Bown, 1998) errors by adult
speakers appear to be more common for words from
sparse neighborhoods than for those from dense neighborhoods, and items involved in malapropisms tend to
come from sparse neighborhoods (compared with words
chosen at random from the lexicon; Vitevitch, 1997). Some
studies suggest that speakers name words more quickly
from dense neighborhoods after studying them (Vitevitch,
2002). However, there are some contradictory findings. For
example, Newman and German (2005; see also Newman &
German, 2002) reported poorer naming performance for
words from dense neighborhoods, suggesting that neighbors could cause naming interference in some situations.
This effect was greatest in children and adolescents than
in young or older adults. Some of these differences may be
the result of difference in task methodology. For example,
Vitevitch's (2002) task, with its prior stimulus studying
phase, was designed to measure speed of retrieval in a
fluent production, whereas Newman and German's work
was designed to elicit errors. Alternatively, it may be the
result of differences in the populations tested; perhaps
neighborhood frequency may impact naming more strongly
in speakers with weaker or immature lexical systems.
This latter possibility suggests that examining neighborhood density effects in atypical populations may be particularly informative.
In addition to this effect of the number of neighbors a
word has, the frequency with which those neighbors occur can also influence lexical access. For example, kept's
neighbors are not only few, but those neighbors are very
low-frequency words of English. In contrast, the word weld
has some very high-frequency neighbors, such as well and
world. However, this effect appears to demonstrate a more
variable impact on speech production. Neighborhood frequency was not found to influence word repetition speed
(Luce & Pisoni, 1998) in adults. In Vitevitch and Sommers
(2003), however, it did influence naming speed in a task
in which participants first studied the 54 target words
and were then asked to provide them as labels for each
picture. Participants responded more quickly and accurately to items with high neighborhood frequency. Likewise, words involved in speech production errors such
as malapropisms tend to have a lower neighborhood frequency than do randomly selected words from the lexicon
(Vitevitch, 1997). Moreover, Newman and German (2002)
reported a strong effect of neighborhood frequency in children's speech production; words with high average neighborhood frequency were named more accurately than

198

those with low average neighborhood frequency. Thus,
across a number of methodologies, neighborhood frequency
has been found to influence naming speed and accuracy.
It generally shows a facilitative effect, with greater accuracy and faster responding on items with high neighborhood frequency.

Lexical Processing in People Who Stutter
As early as 1923, well before more recent hypotheses
that stuttering might reflect some sort of psycholinguistic
impairment, some researchers posited that stuttering
reflected a type of word retrieval disability (Scripture &
Kittredge, 1923). Is there evidence that people who stutter show differences in lexical ability or processing? We
do know that lexical factors affect patterns of fluency
in people who stutter. Words that are less common in
the language are more likely to be stuttered (Danzger
& Halpern, 1973; Hubbard & Prins, 1994; Palen &
Peterson, 1982; Prins, Main, & Wampler, 1997; Ronson,
1976; Soderberg, 1966). When frequency is controlled for,
nouns tend to be stuttered less in conversational speech
than other content words (Quarrington, Conway, & Siegel,
1962). In contrast, few regular and systematic phonological factors appear to be associated with elevated stutter
frequency (see Bernstein Ratner, 2005), other than a typical finding that vowels are often stuttered less in adult
speech than consonants (see summary in Quarrington
et al., 1962).
Given the difficulty of controlling or balancing phonological, lexical, and syntactic factors in spontaneous corpora, a number of studies have relied on standardized
tests or laboratory tasks to uncover potential lexical factors that might distinguish adults who stutter (AWS) or
influence stuttering frequency (patterns that might implicate the lexicon or access to it as a factor that precipitates fluency breakdown in stuttering). For example,
vocabulary depression or lexical difficulty (such as the ability to resolve ambiguity) has been noted in some studies of
adults and children who stutter (Arnold, Conture, & Ohde,
2005; Byrd & Cooper, 1989; Murray & Reed, 1977;
Scripture & Kittredge, 1923; Watson et al., 1994; Westby,
1974) and on conversational measures of lexical diversity
in children (Silverman & Bernstein Ratner, 2002). Another task that has been used is lexical decision, which requires the speaker to indicate, manually or vocally, whether
a visual stimulus is a real word of the language. Slower
overall lexical-decision times have been noted for AWS
(Hand & Haynes, 1983; Rastatter & Dell, 1987).
Other studies have asked AWS to name words aloud,
particularly in response to pictures. AWS tested by Prins
et al. (1997) showed slower latencies than did fluent
speakers on picture naming tasks, even when the set consisted of as few as eight familiar nouns and verbs pretested for recognition. Verb encoding was particularly

Journal of Speech, Language, and Hearing Research * Vol. 50 * 196-213 * February 2007

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/17/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

slowed, as was naming of low-frequency words. Thus,
again, AWS appear slower to respond to lexical items,
particularly when those items are low in frequency of
occurrence.

attributes of words, it is possible that the study's results
could reflect slower ability of AWS to access other types
of information (such as semantic, syntactic, or frequency
of use).

The organization of the mental lexicon is also thought
to be reflected in the effects of priming on the speed of
lexical retrieval. In priming studies, baseline measures
of lexical decision or word-naming latency are contrasted
to conditions in which the target is preceded by a semantically or phonologically similar item. For example, people are faster to respond to the word cat after hearing the
word dog because dog and cat are semantically linked
in the mental lexicon. Similarly, phonological priming is
demonstrated by faster responding to cat after hearing a
similar-sounding word, such as cap. One study (Burger &
Wijnen, 1998) suggested that AWS require larger amounts
of phonological priming information (initial consonant +
vowel) to speed speech onset compared with consonantonly priming in adults who do not sutter (AWDNS). However, in a follow-up study, although Burger and Wijnen
(1999) showed slower reaction times (RTs) in a phonological priming study of single-word naming, they showed no
reliable effects that differentiated priming patterns between the groups. Likewise, in a recent study of 3-5-yearold children, Melnick, Conture, and Ohde (2003) did not
find patterns of generalized slower RTs to picture naming, nor differential effects of phonological priming across
groups. Thus, phonological priming appears to be comparable between individuals who do and do not stutter.
Different patterns have been found for semantic priming,
however. Pellowski and Conture (2005) found children who
stutter to be slower than similarly aged peers in naming
both unprimed and semantically primed picture stimuli.
Additionally, semantic priming did not appear to speed
RTs for the children who stutter, while it facilitated the
speech of their fluent peers. These results imply that the
mental lexicons of fluent and stuttering speakers may be
organized similarly in terms of phonological properties of
words, but may differ in terms of semantic organization
or activation. This implies that lexical deficts in AWS may
be more likely to be found at stages involving concept and
word activation than at sublexical or form-based levels.
However, these studies differed not only in the type of
priming involved, but also in the task and the age groups;
this makes any definitive conclusions tentative at best.

In general, AWS are slower in response to both auditory and visual stimuli, and even show slowed galvanic
skin responses to auditory stimuli, raising concerns that
slowed absolute latencies of response to verbal tasks may
not be specific to linguistic processing or be informative
regarding the basis of the presumed deficit (see summary
in Starkweather, Franklin, & Smigo, 1984). However,
others have argued that slowing is limited to activities
requiring vocal responses only (Reich, Till, & Goldsmith,
1981), and some have found no evidence of generalized
slowing (McFarlane & Shipley, 1981). McFarlane and
Shipley did find relatively slower responses of AWS to
auditory cues, but no differences when responding to
visual cues, as in the present article. In a recent study
using rhyme judgment tasks conducted by Weber-Fox
et al. (2004), AWS showed atypically increased RTs under
conditions of increased cognitive load, such as incongruence between orthography and phonology (e.g., gown-
own). In discussion, Weber-Fox and colleagues noted that
the data to date are "consistent with the hypothesis that
underlying neural processes mediating lexical access I
may operate atypically in adults who stutter in the absence of overt speech" (Weber-Fox et al., 2004, p. 1246).
Because past research had shown aberrant event-related
potential (ERP) patterns in AWS for receptive lexical processing (Weber-Fox, 2001), it is possible that it is not
speech production, per se, that is aberrant in AWS, but
the lexical retrieval and encoding prior to motor action
that are impaired. Moreover, other work done by WeberFox's colleagues (e.g., Smith & Kleinow, 2000) suggests
that language demand can adversely affect motor stability of articulatory patterns in AWS, providing a mechanism whereby potential language weakness could cascade
through the motor system during speech production.

AWS also have slower RTs on tasks requiring phonological monitoring (such as judging whether things
rhyme) and lexical analysis (semantic category judgment;
Bosshardt, 1993, 1994). Most recently, Sasisekaran and
colleagues utilized a classic phoneme monitoring paradigm with stuttering and fluent adults, and reported
slowed phoneme monitoring in AWS, suggesting delayed
phonological encoding ability (Sasisekaran, De Nil, Smyth,
& Johnson, in press). Alternatively, because phoneme
monitoring task RTs are also affected by nonphonological

In contrast to a number of researchers who have targeted lexical abilities in AWS as a potential underlying
source of speech encoding difficulty, Packman, Onslow,
Coombes, and Goodwin (2001) rejected lexical retrieval as
a primary factor in stuttering, because their 3 participants stuttered during reading of nonword sequences.
Thus, they argued, failures of lexical retrieval are not
necessary conditions to trigger stutter events. We would
agree, but are not sure that their rather unique and limited study can answer questions about how stuttering
arises in the language acquisition process, or how lexicalization factors that operate during meaningful sentence generation might trigger stutter events. Au-Yeung
and Howell (2002) raised similar concerns about the
ability of the study design to rule out any particular stage
in the lexicalization process as being critical in fluency
breakdown.

Newman & Bernstein Ratner: Lexical Effects in Adults Who Stutter

199

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/17/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

The Impact of Frequency and
Neighborhood Factors in Stuttering
As noted earlier, most studies of lexical factors in
speech production have focused on typical AWDNS, although some have examined other clinical groups, such
as individuals with word-finding difficulties. Presumably,
an individual who has some difficulty in lexical access
might show different effects of these lexical properties on
lexical access. As an example, older adults (who tend to
demonstrate poorer lexical access) show greater effects of
a word's semantic familiarity than do younger adults.
Although all individuals are more accurate at naming
high-familiarity than low-familiarity words, this difference is greater in older adults, suggesting that age and
impairment tend to amplify the effects of lexical factors
on naming (Newman & German, 2005). Word frequency
and phonological form have also been investigated in individuals with aphasia (e.g., Boyczuk & Baum, 1999;
Gordon, 2002). The results of such research led us to expect that linguistic impairment at some stage in processing might result in increased weight on factors that
typically serve a facilitative role. If individuals who stutter are particularly impaired at some stage of lexical
access, we might similarly expect to find greater effects of
lexical factors focused at that stage of processing. For
example, we might see greater effects of word frequency
in individuals who stutter if they are impaired in accessing the particular word form (i.e., they would show a
greater difference between their speed and accuracy for
high-frequency words and for low-frequency words than
would individuals who do not stutter). Likewise, we might
see greater effects of neighborhood frequency if AWS are
impaired in accessing sublexical representations. In contrast, if AWS do not have impairments in lexical access,
per se, we would expect them to show similar effects of
lexical factors as do AWDNS.
We know of only two studies that have contrasted the
impact of neighborhood factors on RT, fluency, or both
in AWS. Both have been conducted with children. In an
experimental study conducted by Arnold et al. (2005) of
picture-naming speech reaction time (SRT) in nine pairs
of 3-5-year-old stuttering and fluent children, all participants demonstrated faster and more accurate performance
on words from phonologically sparse neighborhoods than
on words from phonologically dense neighborhoods. However, no differences were observed between the two groups
on these factors, and a secondary analysis linking SRT to
receptive vocabulary scores showed vocabulary to be more
predictive of SRT than neighborhood characteristics of
the stimulus items. The authors noted that their small
set of stimulus items may have made it difficult to obtain
statistical differentiation for SRTs among items. They also
cautioned that broad variability in lexical abilities of children in this young age range might make it difficult to

200

effectively assess phonological neighborhood effects in individuals who stutter. Study of adult SRTs for pictures differing in neighborhood characteristics would partially solve
this problem.
Anderson and Linton (2004) conducted an analysis
of frequency and neighborhood characteristics of stuttering children's conversational speech. Stuttered words
were more likely to be low frequency and low neighborhood
frequency than fluently produced words. This effect was
more marked for what were called "sublexical disfluencies"
(sound, syllable repetitions, blocks, and prolongations)
than for "lexical disfluencies" common in young children's
stuttering (single-syllable, whole-word repetitions). Neighborhood density did not appear to exert a strong effect on
either word fluency or stutter-event type. However, the
conversational speech samples could not effectively balance
or stratify extreme contrasts in neighborhood characteristics. Thus, it appears that an experimental investigation of the effects of lexical factors on constrained naming
tasks could shed greater light on lexical and phonological
access in stuttering.
In summary, if individuals who stutter have deficits
involving one or more stages of lexical access, this should
be reflected in the patterns of lexical effects that they
demonstrate. Specifically, we might hypothesize the following: If AWS have either atypical organization of their
lexicon or atypical processes of activation, they should
show different effects of lexical factors on latency and accuracy of naming than do individuals who do not stutter.
In addition we might expect these variables to affect the
fluency of their productions.
This hypothesis regarding the role of lexical processing in stuttering might be evaluated by exploring the
impacts of a select set of lexical properties on the ease and
fluency of single-word naming. If word frequency, neighborhood density, and neighborhood frequency effects
differed between AWS and AWDNS, this would provide
support for the hypothesis that stuttering reflects some
underlying impairment in lexical organization or retrieval.

Method
Participants
Participants included 25 AWS and 25 AWDNS who
were matched for age (within 3 years), education level,
and gender. Each group included 8 women and 17 men;
all were native speakers of English. None reported exceptional language or hearing background, with the exception
of fluency difficulties; some individuals did have articulation difficulties as children that had resolved with development. AWS ranged in age from 18 to 66, with a mean of
38.2 years; AWDNS ranged in age from 18 to 64, with a
mean of 37.8 years. Years of education ranged from 12 years
(high school diploma or equivalent) to PhD level; average

Journal of Speech, Language, and Hearing Research * Vol. 50 * 196-213 * February 2007

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/17/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

years of education were 15.6 for AWS and 15.8 for AWDNS.
All participants were volunteers who were not paid or reimbursed for their participation. Data from 1 additional
pair of participants were removed because 1 member of
the pair made an excessive number of multiword, rather
than single-word, responses (well over half of the trials).
Recruitment of AWS was done primarily through attendance at a national self-help meeting in the local area
and participation in treatment programs at the University
of Maryland's Speech and Hearing Clinic. Other participants (both AWS and AWDNS) were recruited by personal contact or by responses to posters placed on campus.
Classification of an individual as being an adult who
stutters was initially made by self-report. However, this
classification was confirmed individually for each participant, either during the course of the study (by one or
more stuttering episodes during the testing or interview
portions of the study) or afterward via a conversation
with a trained clinician.

Stimuli: Word Selection
Our goal was to create a set of stimuli that could be
used across a range of ages. For that reason, we limited
ourselves to words likely to be known by children as young
as 5 years of age. Using words such as these had the added
benefit that for adult participants, therefore, we did not
need to be overly concerned with participant vocabulary
size; all adult native speakers without cognitive impairments could be expected to know these words. We began
by collecting a set of 350 possible target words from books,
stories, and other child-friendly sources. We then removed
from this list all words unlikely to be clearly picturable,
and next calculated familiarity, neighborhood, and frequency values for all words.
Familiarity ratings were taken from Nusbaum, Pisoni,
and Davis (1984), and were based on adult participants'
subjective familiarity ratings, with 7 indicating greatest
familiarity. Although we did not manipulate familiarity
as a factor in this study, we collected this information so
that we could ensure that only high-familiarity words
were included in our analyses. We then measured the frequency of occurrence of each of our target words using
word counts reported in the Carroll, Davies, and Richman
(1971) corpus. These were then transformed into logfrequency values. To determine neighborhood density,
each word was looked up phonologically in a computerized version of Webster's dictionary. All words in the
lexicon that differed from the target word by a single
phoneme (either a single phoneme addition, deletion, or
substitution) and that had familiarities of at least 6.0 on
the 7-point familiarity scale (Nusbaum et al., 1984) were
considered to be neighbors for this analysis. (We avoided
using unfamiliar words on the assumption that these
would not necessarily have full lexical representations for

our participants.) However, because we were particularly
interested in selecting items that could also be used with
young children, we also recalculated neighborhoods in a
second manner. The dictionary-based approach includes
many items as "neighbors" that young children are unlikely to know. We therefore checked each of these neighbors in the Carroll frequency listing; any item that did not
have a U value of at least 1.0 was excluded from consideration as a neighbor for the second analysis. This resulted
in only minor changes in values. For neighborhood frequency, we calculated frequency (as indicated previously)
for each of the neighbors. We then took an average of these
values as being the average neighborhood frequency for
each word. For this analysis, we used neighborhood frequency values based on the child set. From these sets of
data, three sets of words were chosen for testing. All measurements were performed on the base morpheme (singular form for nouns, the infinitive form for verbs).
The first set of words consisted of two lists differing in
word frequency, or the frequency with which the words
are commonly encountered. (The list of words, along with
mean and standard deviations of their lexical values, is
provided in the Appendix.) The low-frequency list had
an average log frequency of 0.85, corresponding to a raw
value of approximately 10 instances per million (range =
1.5-27.0); the high-frequency list had an average log frequency of 2.68, corresponding to a raw value averaging
more than 1,000 times per million (range = 76-4,850).
Each list contained 21 words, with the same distribution
of onset phonemes in each list. (This matching was necessary to avoid confounds; if an individual had a tendency
to stutter on particular onset phonemes, this could not
cause an apparent word frequency effect. Each set of
21 words contained 2 words each beginning with /b, d, m,
t/; 3 words beginning with /h/; and 1 word beginning with
/tS, &, ai, f, g, k, l, r, S, w/.) The two lists were matched
in terms of the average number of syllables per word
(1.30 vs. 1.35), the average number of phonemes per word
(3.25 vs. 3.40), the number of neighbors the words have
(10.15 vs. 10.20 based on the child set, 11.0 vs.10.6 based
on the adult set), and the average log frequency with which
those neighbors occur (1.40 vs. 1.42).
The second set of words consisted of two lists differing in neighborhood density. Neighborhood density refers
to the number of items in the lexicon that are similar to the
target word. Each list contained 22 words, with an average of 5.18 neighbors in the sparse set and 22.9 neighbors
in the dense set based on the adult neighborhood calculations and an average of 4.36 neighbors in the sparse
set and 22.5 neighbors in the dense set based on the child
neighborhood calculations. As with the frequency set,
these two lists contained the same distribution of onset
phonemes (6 beginning with /k/, 5 beginning with /b/,
3 with /f/, 2 with /d, h/, and 1 with /g, m, n, w/). Average log
frequency was 1.892 for items in the low neighborhood

Newman & Bernstein Ratner: Lexical Effects in Adults Who Stutter

201

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/17/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

set and 1.893 for items in the high neighborhood set; neighborhood frequency values for the two sets were 1.594 and
1.596, respectively. For the full set of words, see the Appendix.
The third set of words consisted of two lists differing
in neighborhood frequency, or the frequency with which
the neighbors are encountered. This can be thought of as
a measure of the frequency with which the sound pattern
in general is encountered. (Indeed, for the target words,
neighborhood frequency strongly correlated with both
biphone-based phonotactic probability and phoneme-based
phonotactic probability once the number of phonemes
in the words was accounted for: for phonemes, r = .43,
p < .005; for biphones, r = .41, p < .01). Each list contained
22 words, with an average log neighborhood frequency
of 0.87 for the low neighborhood frequency set, and 2.00
for the high neighborhood frequency set. The sets were
matched for the number of neighbors (7.2 vs. 7.3 based on
the child set, 7.6 vs. 8.2 on the adult set), for average log
word frequency (1.76 vs. 1.77), and for the number of
phonemes per word (3.96 vs. 3.59). As with the other sets,
these two lists contained the same distribution of onset
phonemes (4 beginning with /s/; 3 beginning with /b, f, k/;
2 beginning with /n /; and 1 each beginning with /&, E, g, l,
S, t, w/ ).
We note that while our sets of words were matched in
terms of initial phoneme, they were not matched in terms
of onsets; the existence of a single versus a cluster onset was not separately controlled for, as this is one of the
factors that influences neighborhood properties. The existence of clusters could have its own effect on RTs (see
Santiago, MacKay, Palma, & Rho, 2000). This issue is addressed in a later section.

Stimuli: Picture Selection
We then attempted to find pictures appropriate for
each of these words. Most pictures were selected from
colored line drawings in Nova Development's Art Explosion; when there was no appropriate picture from this
source, other sources of images were consulted. All images were then piloted by presentation to laboratory members, and next by a set of 22 pilot participants. Pictures
that were not identified appropriately by the majority of
participants were replaced with alternate pictures. Although all images for the original piloting were colored
line drawings, a few items were not sufficiently well identified with this form of picture, and photographic images
were needed to avoid confusion (e.g., in order for a picture
to be clearly a muffin, and not a cupcake, it needed to be
an actual photograph, rather than a line drawing). In
total, 11 of the final items (10%) were photographic in
nature. To ensure that results were not affected by this
difference in picture quality, we performed all analyses
two ways: once on the full set of items, and once only on
the line drawings. The basic pattern of results remained

202

identical, although some effects that were marginal by one
analysis were more clear by the other form; these differences are noted when they occur.

Stimulus Presentation and Order
All three word sets were presented to the participants in a combined fashion, with words intermixed and
presented in random order. Because the different word
sets contained some overlap, there were a total of 107 target words. Most of the target words were nouns, but a
small number (7 words) were verbs. We subdivided the
words into these two groups. Half of the participants were
tested on nouns first, and half were tested on verbs first.
Order of trials within each set was randomized for each
participant. For the nouns, participants were told to name
the item they saw on the screen, using a single-word answer. For the verbs, participants were told to identify what
the person or people in the picture were doing, again using
a single-word answer. Prior to each word type, participants
were given a 10-item practice set. (Thus, prior to being
tested on nouns, participants received a practice set of
nouns; prior to being tested on verbs, participants received a practice set of verbs.) This ensured that participants understood the instructions and were comfortable
with the task.
Thus, from the point of view of participants, there
were two sets of words they were asked to name: one set of
nouns, and a second set of verbs. From our point of view in
conducting analyses, there were three sets of words that
were examined separately: words differing in frequency,
neighborhood density, and neighborhood frequency. To
ensure that the difference between nouns and verbs did
not influence the results, we performed all analyses twice:
once with the full set of items, and once with nouns alone.
The pattern of results was identical, but some marginal
effects disappeared with the smaller number of items;
these differences are noted in the text.

Procedure
Participants were seated comfortably in front of a
computer screen. They were asked to wear a clip-on Shure
MX185 microphone, which recorded their responses. At
the start of each trial, the computer would beep. This occurred simultaneously with the picture appearing on the
computer screen. Participants were asked to identify the
picture as quickly and accurately as possible by saying
the word aloud. All responses were recorded on compact
disk, using a Marantz CDR300 portable CD recorder.
After the participant responded, the experimenter pressed
a button on the computer mouse, which advanced the experiment to the next trial. There was a 1,000-ms intertrial
interval between the experimenter's button press and the
onset of the following trial.

Journal of Speech, Language, and Hearing Research * Vol. 50 * 196-213 * February 2007

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/17/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

Coding and Reliability
Experimenters listened to the recordings to determine the accuracy of the participants' responses. Experimenters also indicated if they judged the participant to
have stuttered on that response. Reliability for identification of stuttering episodes was calculated by having two
trained listeners separately assess 6 of the 25 participants
(or 24%); the 6 were selected so as not to be outliers (i.e.,
we avoided selecting those individuals who did not stutter at all, or who made the largest number of stuttering
episodes). Across these 6 individuals, there were a total
of 642 trials; the two listeners agreed on 627 of the trials
(or 97.7%). Any trial on which the two listeners disagreed
was juried before use in the final data.
RTs were measured on the digital waveform as the
time between the onset of the beep and the onset of the
participant's response, using Syntrillium's CoolEdit program (see Figure 1). RTs were measured only when the
participant's response matched the one intended. Reliability of RT measures was assessed by having a second
individual code 6 of the participants (3 who do not stutter
and 3 who do). This constitutes 12% of the data. Reliability for the 6 participants ranged from .88 to .997, with
an average value of .945. Average difference in RT scores
per item was 41 ms, or about 4% of average RT.
In the current study, pictures were identified as intended 89.7% of the time, on average (after the 1 participant who made an excessive number of elaborations was
eliminated, as discussed previously). Other responses

were classified as (a) true word-finding difficulty or response
errors, (b) dialectal variants or alternate word choices,
(c) elaborations, and (d) visual confusions. Classification
of errors was juried. Dialectal variants were responses
that were correct, but not the word we had intended; some
of these variations may be a result of dialect differences,
while others might be considered appropriate synonyms
or near synonyms. Examples include garbage for trash,
bicycle for bike, and puppy for dog. Elaborations consisted
of multiple word responses, such as Christmas bell instead of bell, birthday cake instead of cake, and swim
goggles instead of goggles, in which the correct word was
included but was not the first part uttered. Both of these
types of responses were considered correct responses for
the accuracy analyses; however, no RT was generated
because the participant did not initially give the intended
utterance. Elaborations occurred 2.8% of the time overall;
dialectal variants 1.5% of the time. Visual errors consisted
of responses suggesting the person had misperceived the
picture itself or what aspect of it he or she was supposed to
name; examples include stalagmites for icicles, bruise for
shoulder, man for beard, and doll for girl. These occurred
only 2.1% of the time overall, and these trials were excluded from the analysis for that particular individual.
Word-finding errors consisted of any response indicating that the person was having trouble finding the
correct word (such as saying, "I don't know," "What's that
called again?" or giving an incorrect response and then
self-correcting) or giving an incorrect or generic response
that suggested the picture was correctly perceived (e.g.,

Figure 1. Image of waveform, with beeps, speech, and reaction times marked.

Newman & Bernstein Ratner: Lexical Effects in Adults Who Stutter

203

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/17/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

bird for swan, cut for knife, clock for watch). In addition, if
the individual said "ummmm" or "uhh" more than once on
a trial, it was considered an indication of a word-finding
problem (this occurred on only two trials and was combined with long RTs, indicating difficulty; see German,
1991). Across words, these word-finding errors occurred
3.9% of the time overall.
There were also some items that were named correctly, but for which RTs were unavailable; generally,
these were the result of the participant talking, laughing,
or coughing over the start of the trial (indicating they were
not ready to respond) or of the beep being inaudible as a
result of background noise. RTs for 34 trials across the
50 participants (or approximately 0.6%) needed to be eliminated for this reason; this was no more common in AWS
than in AWDNS, t(24) = 0.98, p > .05.
One concern is that particular items may have been
problematic, leading to a confound. Alternatively, elaborations or dialectal responses could have been a means of
avoiding difficult words for individuals who stutter. We
examined this in two ways. First, we compared the percentage of responses of different types for the different
groups. In no case did the two groups differ significantly:
elaborations, 3.1 versus 2.5, t(24) = 0.95, p > .05; dialectical variant, 2.0 versus 1.3, t(24) = 1.76, p = .09; visual
errors, 2.20 versus 2.24, t(24) = 0.09, p > .05.
Second, we looked at each item across participants, to
determine if particular items were especially problematic
(items that were named in a manner other than intended
at least one third of the time). Seven items met these criteria. These items were then removed from the word sets,
in pairs, in such a way as to maintain the matching across
lists; this involved removing four additional items to maintain matching. All analyses were then conducted both with
the full sets of words and with these words excluded; the
general patterns of results remained identical, suggesting
that these items are not the cause of our effects. We therefore report the data from the full sets in the final analyses.

Results
We first report overall patterns of the error data.
Next, we look separately at the analyses of items by frequency, neighborhood density, and neighborhood frequency.
These analyses were performed separately on the three
types of data collected: RTs, accuracy, and stuttering episodes. The latter were examined only for AWS (although
there were occasional disfluencies among AWDNS, these
were exceedingly rare, occurring in only 4 trials out of 5,350,
or less than 0.1%). RT measurements were performed only
on responses that matched what was intended. We originally did not remove outliers from the analyses because
we were not certain whether this would have a differential
effect on the two groups of participants. However, we then

204

reanalyzed the RT data by removing from the analysis any
item with an RT more than two standard deviations from
that individual's mean RT. Both analyses are reported in
all cases. Partial eta-squared measurements are reported
as measures of effect size.

Overall Analyses
Although there was a tendency for AWS to have
overall slower RTs, this difference was not significant.
On average, AWS responded in 1.19 s to each stimulus
(SD = 427 ms); AWDNS responded in 1.04 s (SD = 153 ms),
a difference of 150 ms, t(24) = 1.75, p < .10, h2 = .11. AWS
appeared to be more variable in their RT, but not, perhaps,
slower on average. This marginal effect disappeared when
verbs were excluded, t(24) = 1.64, p > .10. Likewise, once
individual participants' outliers were removed from their
average RTs, the difference across groups disappeared
as well; AWS responded in 1.11 s (SD = 361 ms), and
AWDNS responded in 988 ms (SD = 134 ms), t(24) = 1.67,
p > .10.There was, however, a significant accuracy difference between the two groups, with AWS responding
correctly 94.3% of the time (SD = 3.4 %), but AWDNS
responding correctly 97.6% (SD = 2.0%) of the time,
t (24) = 3.89, p < .001, h2 = .39. This difference in accuracy is particularly striking given the nonsignificant difference in speed of responding, and suggests that AWS
were having particular difficulty accessing the words, not
simply having difficulty in producing them. This finding
supports the original hypothesis that individuals who
stutter have some deficit in their lexical processing.
Looking more specifically at the AWS, there did not
appear to be any particular pattern with regard to the
initial phoneme of the target word and likelihood of that
word being stuttered. There was variability; stuttering
proportions ranged from 4% of the time for /tX / ("ch") to
16% of the time for /X /. Words beginning with vowels had
stuttering episodes 12.8% of the time versus 10.1% for
words beginning with consonants. Voiced consonants were
stuttered slightly more often than voiceless ones (11.5 vs.
8.4% of the time), and nasals slightly more often than
other manners (13.1% vs. 9.3% for stop consonants, 9.4%
for fricatives and affricates, and 11.1% for liquids and
glides). However, there was a large amount of variability
in these tendencies across participants, such that none
of these trends represented statistically significant differences across participants. Rather, looking across participants as a group, there appeared to be a relatively even
distribution of stuttering across phoneme classes.

Effects of Word Frequency
Looking at RTs, there was no overall effect of group,
F(1, 24) = 2.78. p = .11, hp2 =.11, again suggesting that
AWS were no slower than those who did not stutter. As

Journal of Speech, Language, and Hearing Research * Vol. 50 * 196-213 * February 2007

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/17/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

Figure 2. Effect of word frequency on reaction times (left) and error rate (right) for both adults who stutter (AWS) and
adults who do not stutter (AWDNS) . Error bars indicate standard error.

expected, there was an overall effect of word frequency,
with slower RTs to low-frequency words (1.19 s to lowfrequency words, 1.09 s to high-frequency words, or a
100-ms difference), F(1, 24) = 12.89, p = .0015, hp2 = .34,
as shown in the left-hand panel of Figure 2. This effect of
word frequency was significant in both groups separately:
AWS, F(1, 24) = 8.50, p = .008; AWDNS, F(1, 24) = 7.43,
p = .011. Interestingly, there was a marginal interaction
between word frequency and group, with AWS showing
a larger effect of word frequency than AWDNS: F(1, 24) =
3.88, p = .061, hp2 = .13; average RTs to low- and highfrequency words were 1.32 s and 1.15 s for AWS, but 1.07 s
and 1.02 s for AWDNS. This suggests that AWS may
be particularly disadvantaged when attempting to identify low-frequency words. However, this interaction was
only marginal, making any such conclusions somewhat
tentative.
Once outliers were removed, however, the interaction
became significant. There was again no overall effect of
group, F(1, 24) = 2.99, p = .097, hp2 = .11, and a significant
effect of word frequency, F(1, 24) = 18.11, p = .0003, hp2 = .43,
but there was also a significant interaction, F(1, 24) =
4.60, p = .04, hp2 = .16. AWS responded in 1.187 s for lowfrequency words but 1.094 s for high-frequency words.
AWDNS responded in 1.011 s for low-frequency words but
0.979 s for high-frequency words. The effect was significant in both groups separately: AWS, F(1, 24) = 14.53,
p > .0008; AWDNS, F(1, 24) = 4.63, p = .04, so the interaction is rather an indication of a change in degree of the
effect, rather than a change in the presence of the effect.
There was a greater effect of word frequency among
AWS. This greater deficit for low-frequency words might

be an indication of generally impaired access for word
forms in AWS.
Looking at individuals' rates of word-finding errors
showed a large effect of group, with AWS making more
errors than AWDNS (error rate of 5.80% vs. 2.60%),
F(1, 24) = 11.55, p = .002, hp2 = 0.32, as can be seen in the
right-hand panel of Figure 2. There was also a large effect
of word frequency, with more errors on low-frequency words
(5.60% vs. 2.80%), F(1, 24) = 11.25, p = .003, hp2 = .32. This
supports the findings based on RTs, suggesting that words
that occur less often in the language tend to be harder
to access. However, there was no significant interaction
between these factors, F(1, 24) = 1.52, p = .23, hp2 = .06.
What trend existed mirrored that in the RT data, with AWS
showing a larger effect of word frequency than AWDNS
(for AWS, errors occurred on 7.75% of trials involving
low-frequency words and 3.84% of trials involving highfrequency words; for AWDNS, the values were 3.44% and
1.75%, respectively).
Finally, as has been reported in previous studies (e.g.,
Hubbard & Prins, 1994; Soderberg, 1966), AWS were more
likely to stutter on low-frequency words than on highfrequency words. They averaged 2.5 episodes of stuttering
on the low-frequency words (range = 0-14, with 15 individuals having at least one stutter event) but only 1.6 episodes
on the high-frequency words (range = 0-14, 11 individuals
contributing), a significant difference, t(24) = 2.72, p = .0118,
h2 = .24. (This effect was only marginal once photographic
items were removed, t(24) = 1.86, p < .08, perhaps because
of the smaller number of items). This effect of word frequency on stuttering occurrences can be seen in the lefthand panel of Figure 3.

Newman & Bernstein Ratner: Lexical Effects in Adults Who Stutter

205

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/17/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

Figure 3. Number of stuttering episodes, based on word frequency
(left), neighborhood density (center), and neighborhood frequency
(right). Error bars indicate standard error.

Effects of Neighborhood Density
Looking at RTs showed no effect of group, F(1, 24) =
2.35, p = .14, hp2 = .09, and no Group x Neighborhood
Density interaction (F < 1), as seen in the left-hand panel
of Figure 4. Surprisingly, the effect of neighborhood was
itself only marginal, F(1, 24) = 3.04, p = .094, hp2 = .11, and
absent if verbs were excluded (F < 1). Nor did this change
when outliers were removed from the analysis; with outliers removed, there was no effect of group, F(1, 24) = 1.96,
p = .17, hp2 = .08, no effect of neighborhood (F < 1, hp2 =
.02), and no interaction, F(1, 24) = 2.92, p = .1002, hp2 = .11.
This lack of significance may be the result of a lack of
sufficient power; it is possible the effect would have
reached significance with more participants. Participants

responded in 1.14 s for words from low-density neighborhoods, and 1.09 s for words from high-density neighborhoods; thus, the trend was for a speed advantage for
words from dense neighborhoods. This may be an indication that dense neighborhoods facilitate naming speeds,
in the same fashion that they have been shown to increase
naming accuracy (Newman & German, 2005; Vitevitch,
2002).
Although the effect of lexical neighborhood density
was not significant in the RT data, lexical neighborhood
did appear to affect accuracy of naming, as seen in the
right-hand panel of Figure 4. Individuals made errors on
6.0% of the words from sparse neighborhoods, but only on
3.3% of words from dense neighborhoods, F(1, 24) = 7.59,
p = .011, hp2 = .25. There was also a significant effect of
group, F(1, 24) = 10.25, p = .004, hp2 = .32, with poorer
accuracy for AWS (6.57% vs. 2.75%) but no interaction
between these two factors (F < 1).
Neighborhood density values did not appear to affect
the frequency of stuttering episodes, as seen in the central
panel of Figure 3. AWS averaged 2.12 stuttering occurrences on the words from both low-density and high-density
neighborhoods, t(24) = 0.00, p > .05, h2 = .00 (range = 0-14
episodes for each condition, with 13 and 11 individuals,
respectively, contributing to each condition).
One concern is that the words compared for neighborhood density were matched only for initial phoneme,
not for onset; indeed, the low-density set contained many
more items containing clusters than did the high-density
set. Perhaps this masked an underlying effect going in the
opposite direction. Although the issue of clusters is beyond
the scope of the current article, we did do a subsequent
analysis comparing only a subset of words, those that did
not contain clusters. This comparison involved two sets

Figure 4. Effect of neighborhood density on reaction times (left) and error rate (right) for both AWS and
AWDNS. Error bars indicate standard error.

206

Journal of Speech, Language, and Hearing Research * Vol. 50 * 196-213 * February 2007

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/17/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

of 12 words each, matched on initial phoneme, word frequency, and neighborhood frequency, but differing in the
number of neighbors. We found no effects in the RTs: for
group, F(1, 24) = 1.38, p = .25, hp2 = .05; for neighborhood
density, F(1, 24) = 1.41, p = .25, hp2 = .05; and the interaction (F < 1). In error rates, we again found an effect
of group, with AWS making more errors than AWDNS,
F(1, 24) = 6.16, p = .02, hp2 = .20, but no effect of density,
F(1, 24) = 1.36, p = .26, hp2 = .05, and no interaction (F < 1).
Thus, while it does not appear that the presence of clusters is masking an opposing effect of neighborhood density, it is possible that the increased error rate on items
with sparse neighbors may be due, in part, to the difficulties associated with accessing words with initial clusters
(see Santiago et al., 2000).

Effects of Neighborhood Frequency
Neighborhood frequency refers to the frequency with
which a word's neighbors occur and can be thought of as
roughly a measure of how often the general sound pattern
is encountered. The effect of neighborhood frequency was
highly significant in the RT data, with participants naming words with common sound patterns (high neighborhood frequency) more quickly than words with rarer
patterns (1.05 s vs. 1.11 s, a 60-ms difference), F(1, 24) =
16.38, p = .0005, hp2 = 0.41. This can be seen in the lefthand panel of Figure 5. There was also a marginal effect
of group, with a trend toward slower responding in AWS
(1.16 s. vs. 1.00 s), F(1, 24) = 4.16, p = .0525, hp2 = .15. (This
marginal effect of group was significant with the photographic items removed, suggesting that there may be some
RT differences in this subset of items, F[1, 24] = 4.36,
p < .05).

Most interestingly, there was no interaction between
these factors, F(1, 24) = 1.67, p = .21, hp2 = .06. That said,
looking at the groups separately, this effect was present
only in the AWDNS, F(1, 24) = 30.06, p < .0001, not in
AWS, F(1, 24) = 1.33, p = .05. With outliers removed, there
was likewise only a marginal effect of group, F(1, 24) = 2.96,
p = .099, hp2 = .11; a significant effect of neighborhood
frequency, F(1, 24) = 39.08, p < .0001, hp2 = 0.62; and
no interaction (F < 1, hp2 = .003). However, without the
outliers, the effect was present in both groups: AWS,
F(1, 24) = 31.38, p < .0001; AWDNS, F(1, 24) = 8.69,
p = .007. Thus, it appears there is an effect of neighborhood frequency in both groups, but outliers masked this
when all items were included.
The same pattern of findings occurred in the accuracy
data, as seen in the right-hand panel of Figure 5. There
was again a significant effect of neighborhood frequency,
with more errors on items with rare sound patterns (4.00%
vs. 1.39%), F(1, 24) = 15.51, p = .0006, hp2 = .39. There was
a marginal effect of group, F(1, 24) = 3.14, p = .089, hp2 = .11;
this disappeared when photographic items were removed,
F(1, 24) = 2.83, p < .11, or when verbs were removed,
F(1, 24) = 1.08, p > .10, suggesting that it was dependent
on having the larger set of items. There was no interaction
between these factors, F(1, 24) = 1.56, p = .022, hp2 = .06.
Neighborhood frequency did not appear to affect the
frequency of stuttering episodes, as seen in the right-hand
panel of Figure 3. AWS averaged 2.32 stuttering occurrences on the words from low-frequency neighborhoods
(range = 0-16 episodes, with 14 individuals contributing) and 2.20 episodes on the words from high-frequency
neighborhoods (range = 0-14 episodes, with 13 individuals contributing), t(24) = 0.43, p = .67, h2 = .01.

Figure 5. Effect of neighborhood frequency on reaction times (left) and error rate (right) for both AWS and
AWDNS. Error bars indicate standard error.

Newman & Bernstein Ratner: Lexical Effects in Adults Who Stutter

207

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/17/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

Discussion
In this study, we investigated the effects of three
different lexical factors known to affect ease of access in
fluent speakers, on access in AWS. We found effects of
lexical neighborhood, neighborhood frequency, and word
frequency in response latency patterns of both fluent and
stuttering participants, as expected. We also found that
the size of the neighborhood effects was fairly comparable
across groups, suggesting no basic differences in lexical
organization between people who stutter and those who
do not. However, even for very simple stimuli, people who
stutter made more errors in naming the pictured stimuli.
Moreover, adults who stutter showed greater effects of
word frequency than did adults who do not stutter. This
could suggest a fundamental difference between groups
in a basic level of language processing. It is also possible
that the difference in errors was caused when individual speakers sought to avoid a moment of stuttering by
circumlocuting or providing a synonym. This would be
impossible to ascertain post hoc, but is possible for individual participants who were observed to supply very lowfrequency responses to relatively common stimuli (e.g.,
saying "adrogyne" for boy, an unusual word even if our
stimulus was not a paradigm of masculinity, "pheasant"
for goose, or "patella" for knee). Such responses appeared to be less common in AWDNS, whose errors
tended to be more prosaic (e.g., saying "child" for boy,
"duck" and "bird" for goose, and "elbow" for knee). To
examine whether this was generally the case, we examined the frequency of participants' errors. For this analysis, we only examined real-word errors; responses such
as "I don't know" and circumlocutions were ignored. A
number of errors needed to be ignored as we were unable
to get frequency measures on them; for example, one
person, upon seeing a picture of a cat, gave the name of
her cat as a response; several individuals called the picture of the mummy a "boogeyman," a word not in our
online dictionary. For the remaining words, however, we
determined the log frequency value of both the intended
word and the error, and calculated a difference score. We
then took the means of these values for each participant,
and compared these. Difference scores were no greater for
AWS than for AWDNS, t(24) = 0.55, p = .59. Likewise, just
looking at the words they erred on, t(20) = 0.27, p = .79, or
just the words erred to, t(20) = 0.84, p = .41, we found no
significant differences. Thus, we found no greater tendency
overall for AWS to err to lower frequency words than for
AWDNS, and although this may be the case for a small number of participants, it does not seem to be the case in general.
It is also not clear whether circumlocutions are caused
by a desire not to stutter, difficulty in accessing a word
form, or difficulty in producing a word form. Because the
AWS were not significantly slower in general while naming the stimuli, we believe that a look-ahead strategy

208

implemented to avoid anticipated stuttering seems somewhat unlikely. Such a strategy should have contributed
to slower overall naming patterns. Potential origins of our
observed naming errors would need to be explored in future studies. The pattern of elevated naming errors was
maintained in two of the three subset analyses (those for
frequency and neighborhood density, with a nonsignificant trend in that direction occurring in the neighborhood
frequency analysis). While differences in stuttering adults'
naming accuracy for common words is not something we
expected to find, they are consistent with a very recent
report of elevated RTs in lexical-decision tasks for some
otherwise apparently language-normal AWS (Sasisekaran,
2006). We also note that, although AWS seem to make more
word-finding errors in general, the pattern of errors they
make (or the types of words they find difficult) seems to
be the same as for AWDNS. We also found that people
who stutter are more likely to demonstrate disfluencies
on words that are low frequency, which is not a particularly novel finding. However, neither of the other potential lexical factors that have been shown to affect naming
latencies and accuracy in normally fluent speakers exerted
any observable effect on precipitating stutter events.
Looking across the lexical factors, we thus find a
general pattern emerging. First, those lexical factors reported in the literature appeared to influence speakers in
our study, suggesting that our task was sensitive to these
factors. Effects of frequency, neighborhood density, and
neighborhood frequency were all apparent, generally in
both RT and accuracy measures (the one exception being
neighborhood density, which was only marginal in the RT
measure). Thus, our participants found it easier to name
words that were high in frequency and neighborhood
frequency, and that were located in dense neighborhoods.
Despite these strong findings for all lexical factors,
we generally did not find any interactions between the
neighborhood lexical factors and group membership. Thus,
it appears that the effects for neighborhood factors are
generally quite comparable for AWS and AWDNS. This is
supported by prior work demonstrating comparable phonological priming in individuals who do and do not stutter
(Burger & Wijnen, 1999; Melnick et al., 2003), and suggests that form-based factors do not have differential effects across groups. In contrast, we found amplified effects
of word frequency in individuals who stutter. Comparable
findings have been found for both less mature (Newman
& German, 2002) and language-impaired (Gordon, 2002)
speakers. This similarity in results suggests that adults
who stutter may have difficulty accessing lexical word forms.
This supports earlier work suggesting a lack of semantic priming in children who stutter (Pellowski & Conture,
2005). However, even if AWS do have difficulty with lexical forms, they do not appear to have difficulty accessing
phonological forms, as they did not show greater deficits
accessing items low in neighborhood frequency.

Journal of Speech, Language, and Hearing Research * Vol. 50 * 196-213 * February 2007

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/17/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

It is possible that the limited sample size obscured
subtle but real neighborhood differences between our
groups that might have emerged with greater power. However, the fact that we found such effects for word frequency
suggests that our methodology was sensitive enough to
detect group differences when they are large enough. Moreover, despite the need for very large participant pools to
identify fine-grained differences in language processing,
we note that most studies of AWS utilize samples much
smaller than the one reported here. We also note that word
frequency, the one small differentiating factor in
our findings, has been found to show amplified effects on
naming for less mature speakers as well. Thus, it may be
useful to further explore this factor in future psycholinguistic investigations of AWS.
Our current results of depressed naming accuracy
are consistent with findings of subtly decreased expressive vocabulary ability in children who stutter (CWS;
Bernstein Ratner & Silverman, 2000), decreased lexical
variability in the conversational speech of CWS (Silverman
& Bernstein Ratner, 2002), and atypical discrepancies between expressive and receptive vocabulary skills in CWS
(Arnold et al., 2005). Thus, it would also be valuable to
replicate this experiment with CWS and children who do
not stutter because we could anticipate more obvious differences between groups on our relatively simple stimuli for children who are still solidifying their linguistic
abilities.
If such results can be confirmed by further experimental tests of lexical retrieval in AWS, it will be necessary to then narrow down the specific point in lexical
processing that appears to cause the most difficulty for
people who stutter. In the model we have selected (Levelt,
1999), lexical access involves a variety of stages, such as
accessing the lemma, accessing abstract word forms and
sublexical units, and creating a motoric output plan. According to such a model, the current findings suggest that
lexical processing difficulties in AWS are most likely to
occur at the stage of accessing either the lemma or the
absract word forms. However, many models of speech
production (e.g., Dell, 1986) also acknowledge interactive
and bidirectional relations between semantic and phonological features in lexical retrieval for speech. These complicated interactions make it difficult to tease apart the
different stages of lexical processing in typically fluent
speakers as well as in AWS. Doing so would require not
only additional, carefully designed psycholinguistic experiments akin to those used to develop and refine the
Levelt model (see summaries in Indefrey & Levelt, 2004;
Levelt, 2001), but may also require "chronometric studies
of cerebral activation in word production," such as magnetoencephalography and lateralized readiness potentials, which have the potential to isolate and plot the time
course of specific stages in lexical encoding (Levelt, 2001,
p. 13470). Such sophisticated analysis may be crucial to

understanding the prearticulatory processing characteristics of word production in AWS, particularly because
speech latencies, even in typical speakers, represent the
cumulative effect of multiple successive operations that
are difficult to distinguish temporally using behavioral
data (Indefrey & Levelt, 2004; Levelt, 2001). With few
exceptions (notably the ERP investigations of phonological, semantic, and syntactic encoding in AWS by WeberFox and colleagues [Cuadrado & Weber-Fox, 2003; WeberFox, 2001; Weber-Fox et al., 2004] and the recent series
of phonological, semantic, and syntactic priming studies carried out by Conture and colleagues [Anderson &
Conture, 2004; Arnold et al., 2005; Melnick et al., 2003;
Pellowski & Conture, 2005]), systematic replication of
paradigms that have been used to develop lexical access
models has not been frequent in the stuttering literature.
Nonetheless, the current results do provide some clues
as to which proposed stages of lexical access might be most
fruitful to investigate in future studies of AWS. Given that
phonological factors did not appear to exert a greater influence on AWS than they did for AWDNS, degraded
phonological representations are unlikely to explain the
core deficit in stuttering. In contrast, the Group x Word
Frequency interaction suggests the possibility that there
may be deficits at the stage of word forms in AWS. However, this does not mean that phonological encoding is as
efficient in AWS as in AWDNS; potential problems in the
time course and accuracy of phonological encoding, and
the possibility that prearticulatory monitoring of the phonetic plan is aberrant in AWS (Vasi( & Wijnen, 2005), merit
further experimental evaluation, in our opinion, using the
major language production models as an organizing framework (Bernstein Ratner, 2005).
Work by Weber-Fox and colleagues (Cuadrado &
Weber-Fox, 2003; Weber-Fox, 2001; Weber-Fox et al.,
2004), as well as work by Bosshardt and colleagues
(Bosshardt, 1999, 2002), also suggests that increases in
cognitive load required to complete a phonological (or other
language-based) processing task can affect RTs in AWS,
and indicate a more general capacity limitation for efficient language formulation and encoding in stuttering.
Findings such as this also imply that pre- or postproduction monitoring or attentional processes may play a role
in stuttering. This should be considered along with more
traditional speech production stages and processes when
attempting to describe how disfluencies arise in stuttering. In this vein, it is also interesting that Vasi( and
Wijnen (2005) discovered that increased concomitant cognitive load during language formulation tasks decreased
the frequency of stuttering in AWS. They suggested that
this increased load distracted the overly attentive internal monitor, and this decrease in self-monitoring led to
the decrease in stuttering behaviors. This pattern of results suggests that competing cognitive, linguistic, and
motor programming demands may have differential

Newman & Bernstein Ratner: Lexical Effects in Adults Who Stutter

209

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/17/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

impacts on the time course of speech encoding, as well as
on rate and fluency of output. In summary, this study
suggests that paradigms used to study lexical organization and access in AWDNS can be used successfully with
AWS to identify areas of relative impairment that appear
to be specific to stuttering, at least between these two
populations. The paradigms may also be used to rule out
less likely bases for the fluency breakdown observed in
stuttering. In contrast to studies of spontaneous corpora,
laboratory experiments allow us to investigate specific linguistic factors thought to influence ease of speech production while controlling for potential confounds. This, in turn,
allows us to evaluate competing models of the level(s) at
which the presumed deficit that leads to stuttering arises.

Acknowledgments
We particularly thank Darlene Foster, Laura Gutowksi,
and Katya Rozanova for their work testing participants and
analyzing data, and the National Stuttering Association
Research Review Board for allowing us to test participants
at their national meeting. A portion of this data was presented
at the 2005 Annual Convention of the American SpeechLanguage-Hearing Association meeting in San Diego, CA.
We also thank the following students for assistance either
in participant testing, data analysis, or data coding: Emilie
Clingerman, Nicole Craver, Akiko Elders, Jamie Fisher, Lisa
King, James Liu, Mirza Lugo, Amanda McAdoo, Abimbola
Odukoya, Emily Singer, and Jenni Zobler.

References
Anderson, J., & Linton, A. (2004, November). Neighborhood
effects of children's stuttered disfluencies. Poster presented
at the annual convention of the American Speech-LanguageHearing Association, Philadelphia.

Bierswisch, M., & Schreuder, R. (1991). From concepts to
lexical items. In W. J. M. Levelt (Ed.), Lexical access in
speech production (pp. 23-60). Cambridge, MA: Blackwell.
Bosshardt, H.-G. (1993). Differences between stutterers'
and nonstutterers' short-term recall and recognition
performance. Journal of Speech and Hearing Research,
36, 286-293.
Bosshardt, H.-G. (1994). Temporal coordination between
pre-motor and motor processes in speech production.
Journal of Fluency Disorders, 19, 157.
Bosshardt, H.-G. (1999). Effects of concurrent mental
calculation on stuttering, inhalation and speech timing.
Journal of Fluency Disorders, 24, 43-72.
Bosshardt, H.-G. (2002). Effects of concurrent cognitive
processing on the fluency of word repetition: Comparison
between persons who do and do not stutter. Journal of
Fluency Disorders, 27, 93-113.
Bosshardt, H.-G., Ballmer, W., & de Nil, L. (2002). Effects
of category and rhyme decisions on sentence production.
Journal of Speech, Language, and Hearing Research, 45,
844-857.
Boyczuk, J. P., & Baum, S. R. (1999). The influence of
neighborhood density on phonetic categorization in aphasia.
Brain and Language, 67, 46-70.
Burger, R., & Wijnen, F. (1998, September). The effects of
accent, linear word position and consonant-vowel transition
on stuttering. Paper presented at the Xth Congress of the
European Society for Cognitive Psychology, Jerusalem.
Burger, R., & Wijnen, F. (1999). Phonological encoding and
word stress in stuttering and nonstuttering subjects.
Journal of Fluency Disorders, 24, 91-106.
Byrd, K., & Cooper, E. (1989). Expressive and receptive
language skills in stuttering children. Journal of Fluency
Disorders, 14, 121-126.
Carroll, J. B., Davies, P., & Richman, B. (1971). The
American Heritage word frequency book. Boston:
Houghton-Mifflin.

Anderson, J. D., & Conture, E. G. (2004). Sentencestructure priming in young children who do and do not
stutter. Journal of Speech, Language, and Hearing
Research, 47, 552-571.

Cuadrado, E. M., & Weber-Fox, C. (2003). Atypical syntactic
processing in individuals who stutter: Evidence from eventrelated brain potentials and behavioral measures. Journal
of Speech, Language, and Hearing Research, 46, 960-976.

Arnold, H. S., Conture, E. G., & Ohde, R. N. (2005).
Phonological neighborhood density in picture naming of
children who stutter: Preliminary study. Journal of Fluency
Disorders, 30, 125-148.

Danzger, M., & Halpern, H. (1973). Relation of stuttering to
word abstraction, part of speech, word length, and word
frequency. Perceptual and Motor Skills, 37, 959-963.

Au-Yeung, J., & Howell, P. (2002). Non-word reading, lexical
retrieval and stuttering: comments on Packman, Onslow,
Coombes and Goodwin (2001). Clinical Linguistics and
Phonetics, 16, 287-293.
Bernstein Ratner, N. (1997). Stuttering: A psycholinguistic
perspective. In R. Curlee & G. Siegel (Eds.), Nature and
treatment of stuttering: New directions (2nd ed., pp. 99-127).
Boston: Allyn & Bacon.
Bernstein Ratner, N. (2005). Is phonological complexity a
useful construct in stuttering? Journal of Fluency Disorders,
30, 337-341.
Bernstein Ratner, N., & Silverman, S. (2000). Parental
perceptions of children's communicative development at
stuttering onset. Journal of Speech, Language, and Hearing
Research, 43, 1252-1263.

210

Dell, G. (1986). A spreading-activation theory of retrieval in
sentence production. Psychological Review, 93, 283-321.
Dell, G. S. (1988). The retrieval of phonological forms in
production: Tests of predictions from a connectionist model.
Journal of Memory and Language, 27, 124-142.
Frost, R., Grainger, J., & Rastle, K. G. (2005). Current
issues in morphological processing: An introduction.
Language and Cognitive Processes, 20(1), 1-5.
Garrett, M. (1991). Disorders of lexical selection. In W. J. M.
Levelt (Ed.), Lexical access in speech production (pp. 143-180).
Cambridge, MA: Blackwell.
German, D. J. (1991). Test of Word Finding in Discourse.
Allen, TX: DLM.
German, D. J. (2000). Test of Word Finding (2nd ed). Austin,
TX: Pro Ed.

Journal of Speech, Language, and Hearing Research * Vol. 50 * 196-213 * February 2007

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/17/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

German, D. J., & Newman, R. S. (2004). The impact of
lexical factors on children's word finding errors. Journal of
Speech, Language, and Hearing Research, 47, 624-636.

Murray, H., & Reed, C. (1977). Language abilities of
preschool stuttering children. Journal of Fluency Disorders,
2, 171-176.

Gordon, J. K. (2002). Phonological neighborhood effects
in aphasic speech errors: Spontaneous and structured
contexts. Brain and Language, 82, 113-145.

Newman, R. S., & German, D. J. (2002). Effects of lexical
factors on lexical access among typical language-learning
children and children with word-finding difficulties.
Language and Speech, 43, 285-317.

Hand, C. R., & Haynes, W. (1983). Linguistic processing and
reaction time differences in stutterers and nonstutterers.
Journal of Speech and Hearing Research, 26, 181-185.
Harley, T. A., & Bown, H. E. (1998). What causes a tip-of-thetongue state? Evidence for lexical neighbourhood effects
in speech production. British Journal of Psychology, 89,
151-174.
Howell, P., Au-Yeung, J., & Sackin, S. (2000). Internal
structure of content words leading to lifespan differences in
phonological difficulty in stuttering. Journal of Fluency
Disorders, 25, 1-20.

Newman, R. S., & German, D. J. (2005). Life span effects of
lexical factors on oral naming. Language and Speech, 48,
123-156.
Nusbaum, H. C., Pisoni, D. B., & Davis, C. K. (1984). Sizing
up the Hoosier Mental Lexicon: Measuring the familiarity of
20,000 words (Research on Speech Perception Progress
Report 10). Bloomington, IN: Indiana University.
Oldfield, R. C., & Wingfield, A. (1965). Response latencies
to naming objects. Quarterly Journal of Experimental
Psychology, 17, 273-281.

Hubbard, C. P., & Prins, D. (1994). Word familiarity, syllabic
stress pattern, and stuttering. Journal of Speech and
Hearing Research, 37, 564-571.

Packman, A., Onslow, M., Coombes, T., & Goodwin, A.
(2001). Stuttering and lexical retrieval. Clinical Linguistics
and Phonetics, 15, 487-498.

Indefrey, P., & Levelt, W. J. M. (2004). The spatial and
temporal signatures of word production components.
Cognition, 92, 101-144.

Palen, C., & Peterson, J. M. (1982). Word frequency and
children's stuttering: The relationship to sentence structure.
Journal of Fluency Disorders, 7, 55-62.

Jescheniak, J. D., & Levelt, W. J. M. (1994). Word frequency
effects in speech production: Retrieval of syntactic information and of phonological form. Journal of Experimental
Psychology: Learning, Memory, and Cognition, 20, 824-843.

Pellowski, M., & Conture, E. G. (2005). Lexical priming in
picture naming of children who do and do not stutter.
Journal of Speech, Language, and Hearing Research, 48,
1-17.

Karniol, R. (1995). Stuttering, language and cognition:
A review and a model of stuttering as suprasegmental
sentence plan alignment (SPA). Psychological Bulletin, 117,
104-124.
Lachman, R., Shaffer, J. P., & Hennrikus, D. (1974).
Language and cognition: Effects of stimulus codability,
name-word frequency, and age of acquisition on lexical
reaction time. Journal of Verbal Learning and Verbal
Behavior, 13, 613-625.
Levelt, W. J. M. (1989). Speaking: From intention to
articulation. Cambridge, MA: MIT Press.
Levelt, W. J. M. (1991). Lexical access in speech production.
Cambridge, MA: Blackwell.
Levelt, W. J. M. (1999). Models of word production. Trends
in Cognitive Sciences, 3, 223-232.
Levelt, W. J. M. (2001). Spoken word production: a theory
of lexical access. Proceedings of the National Academy of
Sciences USA, 98, 13464-13471.
Levelt, W. J. M., Roelofs, A., & Meyer, A. S. (1999). A theory
of lexical access in speech production. Behavioral and Brain
Sciences, 22, 1-75.
Luce, P. A., & Pisoni, D. B. (1998). Recognizing spoken
words: The neighborhood activation model. Ear and
Hearing, 19, 1-36.
McFarlane, S., & Shipley, K. (1981). Latency of vocalization
onset for stutterers and nonstutterers under conditions of
auditory and visual cuing. Journal of Speech and Hearing
Disorders, 46, 307-312.
Melnick, K., Conture, E. G., & Ohde, R. N. (2003).
Phonological priming in picture naming of young children
who stutter. Journal of Speech, Language, and Hearing
Research, 46, 1428-1443.

Perkins, W., Kent, R., & Curlee, R. (1991). A theory of
neuropsycholinguistic function in stuttering. Journal of
Speech and Hearing Research, 34, 734-752.
Postma, A., & Kolk, H. H. J. (1993). The covert repair
hypothesis: prearticulatory repair hypotheses in normal and
stuttered disfluencies. Journal of Speech and Hearing
Research, 36, 472-487.
Prins, D., Main, V., & Wampler, S. (1997). Lexicalization in
adults who stutter. Journal of Speech, Language, and
Hearing Research, 40, 373-384.
Quarrington, B., Conway, J., & Siegel, N. (1962). An
experimental study of some properties of stuttered words.
Journal of Speech and Hearing Research, 5, 387-394.
Rastatter, M., & Dell, C. (1987). Vocal reaction times of
stuttering subjects to tachistoscopically presented concrete
and abstract words: A closer look at cerebral dominance and
language processing. Journal of Speech and Hearing
Research, 30, 306-310.
Reich, A., Till, J., & Goldsmith, H. (1981). Laryngeal and
manual reaction times of stuttering and nonstuttering
adults. Journal of Speech and Hearing Research, 24,
192-196.
Roelofs, A. (1992). A spreading activation theory of lemma
retrieval in speaking. Cognition, 42, 107-142.
Roelofs, A. (2000). WEAVER++ and other computational
models of lemma retrieval and word-form encoding.
In L. Wheeldon (Ed.), Aspects of language production
(pp. 71-114). New York: Psychology Press.
Ronson, I. (1976). Word frequency and stuttering: The
relationship to sentence structure. Speech and Hearing
Research, 19, 813-819.
Santiago, J., MacKay, D. G., Palma, A., & Rho, C. (2000).
Sequential activation processes in producing words and

Newman & Bernstein Ratner: Lexical Effects in Adults Who Stutter

211

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/17/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

syllables: Evidence from picture naming. Language and
Cognitive Processes, 15(1), 1-44.
Sasisekaran, J. (2006). Phonological decoding skills in
persons who stutter. Unpublished doctoral dissertation,
University of Toronto, Toronto, Ontario, Canada.
Sasisekaran, J., De Nil, L., Smyth, R., & Johnson, C.
(in press). Phonological encoding in the silent speech of
persons who stutter. Journal of Fluency Disorders.
Scripture, M., & Kittredge, W. (1923). An attempt to
determine another etiological factor of stuttering through
objective measurement. Journal of Educational Psychology,
14, 162-173.
Silverman, S., & Bernstein Ratner, N. (2002). Measuring
lexical diversity in children who stutter: Application of
VOCD. Journal of Fluency Disorders, 27, 289-305.
Smith, A., & Kleinow, J. (2000). Influences of length and
syntactic complexity on the speech motor stability of the
fluent speech of adults who stutter. Journal of Speech and
Hearing Research, 43, 548-559.
Soderberg, G. (1966). The relations of stuttering to word
length and word frequency. Journal of Speech and Hearing
Research, 9, 584-589.
Starkweather, C. W., Franklin, S., & Smigo, T. (1984).
Vocal and finger reaction times in stutterers and nonstutterers: Differences and correlations. Journal of Speech and
Hearing Research, 27, 193-195.

Vitevitch, M. S., & Sommers, M. S. (2003). The facilitative
influence of phonological similarity and neighborhood
frequency in speech production. Memory & Cognition, 31,
491-504.
Watson, B., Freeman, F., Devous, M., Chapman, S.,
Finitzo, T., & Pool, K. (1994). Linguistic performance and
regional cerebral blood flow in persons who stutter. Journal
of Speech and Hearing Research, 37, 1221-1228.
Weber-Fox, C. (2001). Neural systems for sentence processing in stuttering. Journal of Speech, Language, and
Hearing Research, 44, 814-825.
Weber-Fox, C., Spencer, R. M. C., Spruill, J. W., III, &
Smith, A. (2004). Phonologic processing in adults who
stutter: Electrophysiological and behavioral evidence.
Journal of Speech, Language, and Hearing Research, 47,
1244-1258.
Westby, C. (1974). Language performance of stuttering and
nonstuttering children. Journal of Communication Disorders,
12, 133-145.
Wijnen, F., & Boers, I. (1994). Phonological priming effects in
stutterers. Journal of Fluency Disorders, 19, 1-20.
Yaruss, J. S., & Conture, E. G. (1996). Stuttering and
phonological disorders in children: examination of the
Covert Repair Hypothesis. Journal of Speech and Hearing
Research, 39, 349-364.

Vasic(, N., & Wijnen, F. (2005). Stuttering as a monitoring
deficit. In R. J. Hartsuiker, R. Bastiaanse, A. Postma, &
F. Wijnen (Eds.), Phonological encoding and monitoring
in normal and pathological speech (pp. 226-247). Hove,
England: Psychology Press.

Received September 22, 2005

Vitevitch, M. S. (1997). The neighborhood characteristics of
malapropisms. Language and Speech, 40, 211-228.

Contact author: Rochelle S. Newman, Department of
Hearing and Speech Sciences, University of Maryland,
0100 Lefrak Hall, College Park, MD 20742.
E-mail: rnewman@hesp.umd.edu.

Vitevitch, M. S. (2002). The influence of phonological
similarity neighborhoods on speech production. Journal
of Experimental Psychology: Learning, Memory, and
Cognition, 28, 735-747.

212

Revision received January 18, 2006
Accepted May 25, 2006
DOI: 10.1044/1092-4388(2007/016)

Journal of Speech, Language, and Hearing Research * Vol. 50 * 196-213 * February 2007

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/17/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

Appendix. Complete set of words tested for each comparison, along with the
summary values for each set.
Low frequency words: ant, icicle, barn, bike, chin, clap,a dice, dime, phone, goggle, hanger, hose, heel,
leash, muffin, mummy, rake, shower, trash, tooth, web
Average log word frequency: 0.851 (0.425)
Average no. of neighbors: 10.15 (7.42)
Average neighborhood frequency: 1.399 (0.534)
High frequency words: apple, eye, boy, bee, chicken, car, door, dog, finger, girl, house, horse, hand, leg,
money, man, write,a shoulder, table, tree, witch
Average log word frequency: 2.678 (0.535)
Average no. of neighbors: 10.20 (8.33)
Average neighborhood frequency: 1.424 (0.452)
Low neighborhood density words: box, brush, beard, block, boy, dance,a dress, frog, flag, farm, goose,
house, horse, crib, queen, crawl,a clown, climb,a cow, mouth, knife, watch
Average log word frequency: 1.892 (0.610)
Average no. of neighbors: 4.36 (1.84)
Average neighborhood frequency: 1.594 (0.394)
High neighborhood density words: bell, bear, bowl, boat, bat, dime, deer, fan, fight,a phone, gun, heel,
hat, cake, car, kick,a cap, cat, coat, man, net, whale
Average log word frequency: 1.893 (0.474)
Average no. of neighbors: 22.50 (3.78)
Average neighborhood frequency: 1.596 (0.224)
Low neighborhood frequency words: apple, balloon, broom, box, egg, finger, fly, fence, girl, candle,
climb,a car, lamb, necklace, nail, swan, spider, sock, sink, shoulder, tractor, whistle
Average log word frequency: 1.764 (0.539)
Average no. of neighbors: 7.22 (6.86)
Average neighborhood frequency: 0.872 (0.376)
High neighborhood frequency words: ant, bike, bed, bottle, elephant, frog, flag, feather, glass, crawl,a
kite, key, leaves, needle, knee, snail, ski,a smile, snow, shoe, turtle, watch
Average log word frequency: 1.769 (0.392)
Average no.of neighbors: 7.32 (6.55)
Average neighborhood frequency: 2.003 (0.310)
Note. Numbers in parentheses are standard deviations.
a

Indicates a verb.

Newman & Bernstein Ratner: Lexical Effects in Adults Who Stutter

213

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/17/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

