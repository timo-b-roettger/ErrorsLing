512485

research-article2013

JLSXXX10.1177/0261927X13512485Journal of Language and Social PsychologyDonohue et al.

Article

Validating LIWC
Dictionaries: The Oslo I
Accords

Journal of Language and Social Psychology
2014, Vol. 33(3) 282-301
(c) 2013 SAGE Publications
DOI: 10.1177/0261927X13512485
jls.sagepub.com

William A. Donohue1, Yuhua Liang2,
and Daniel Druckman3,4

Abstract
This article presents a validation strategy for creating new LIWC (Linguistic Inquiry
and Word Count) dictionaries. The context used for this validation study is an analysis
of the Israeli-Palestinian rhetoric preceding the 1993 Oslo I accords by Donohue
and Druckman (2009). In that study, coders were trained to code six constructs in
the texts: looking forward, looking backward, power, affiliation, trust, and mistrust.
For the current study, six new dictionaries of words tapping these constructs were
developed and evaluated. Several data reduction strategies were used to identify the
most relevant words pertaining to the constructs. These reduced dictionaries were
correlated with the coder results from the earlier research. The forward-looking
construct emerged as a significant correlate with the forward-looking coder rating
across all data reduction techniques and the full dictionary list. These findings suggest
that both approaches be used. Automated dictionary coding is more efficient; human
coding is more sensitive to context.
Keywords
LIWC, Oslo, validation, dictionaries
An increasing number of papers in a wide variety of fields are using the Linguistic
Inquiry and Word Count (LIWC) software to analyze various texts (Tausczik &
1Michigan

State University, East Lansing, MI, USA
University, Orange, CA, USA
3George Mason University, Fairfax, VA, USA
4Macquarie University, Sidney, Australia
2Chapman

Corresponding Author:
William A. Donohue, Department of Communication, Michigan State University, 404 Wilson Road, East
Lansing, MI 48824-1212, USA.
Email: donohue@msu.edu

Donohue et al.

283

Pennebaker, 2010). LIWC is a software program that contains a number of dictionaries
associated with various constructs, such as negative emotions, positive emotions, causation, insight, inclusive, exclusive, and so on. The program searches a given text for
the words contained in each dictionary and outputs the percentage of hits associated
with the given dictionary. Pennebaker and King's (1999) original study correlated
LIWC results of essays that individuals created with variables such as neuroticism,
extraversion, openness, agreeableness, and conscientiousness. The authors found that
certain dictionaries in the areas of immediacy, making distinctions, referencing the
social past, and rationalization were significant predictors of these variables. These
dictionaries have become the "validated" set used most commonly in subsequent
research with the LIWC procedure.
As the use of LIWC continues to expand, an issue that many scholars must address
when using the software is how to validate new dictionaries that go beyond those
available in Pennebaker and King's (1999) validated lists. Using unvalidated dictionaries will certainly hamper the tool's empirical value and create uncertainty for journal
reviewers. Much of this uncertainty about a LIWC analysis arises from the conceptual
issue that counting words is antithetical to how communicators use language to create
meaning and build interactions. For communicators, the meaning of a specific phrase
or episode is determined by a complex interchange of factors such as history, relationship, and context and not simply the accumulation of specific words. Yet the rationale
for an LIWC analysis is that the accumulation of words uttered over the course of an
interaction can provide some estimate of important communication constructs of theoretical interest. The question for this study is what is an appropriate validation strategy
for new LIWC dictionaries that captures the concepts of, or estimates the value of, key
constructs of interest?
Thus, what should serve as comparison points for a LIWC validation? This article
will argue that there are perhaps three places to start in identifying these comparison
points: (a) comparing LIWC dictionary-based data with coded interaction data around
the same constructs, (b) giving undergraduate subjects the communication constructs
and asking them to generate words aimed at tapping these constructs, and (c) asking
subjects to write essays about the constructs and then creating an LIWC dictionary
using the words generated by these subjects to analyze the essays to see if the focused
constructs are prevalent in the essays.
The context that will be used for this validation study is an analysis of the Israeli-
Palestinian rhetoric preceding the 1993 Oslo I accords by Donohue and Druckman
(2009). The goal of this study was to understand the relationship between the external
context that the respective politicians were shaping through their public speeches and
the events at the secret bargaining table. This dynamic is interesting because political
leaders often try to take their issues to the court of public opinion for a hearing. Yet
there was very little research on how these public displays affected events at the bargaining table. This continues to be a very important question since so many international disputes are played out in public, which serves to set the stage for any private
talks on specific issues.

284

Journal of Language and Social Psychology 33(3)

In that study coders were asked to code 40 samples of speeches and interviews by
Palestinian (20) and Israeli (20) leaders leading up to the Oslo I accords. Coders
focused on the extent to which the rhetoric displayed indicators of several concepts:
looking forward, looking backward, trust, mistrust, power, and affiliation. These
results were then correlated with events at the secret talks to determine their relationship. The study found that progress in the secret talks was highly correlated with how
these concepts were displayed in the rhetoric.
The question driving this current study is whether LIWC dictionaries can be created to measure these same six constructs. More specifically, what procedures should
be used to validate new LIWC dictionaries that in this case could serve to automate the
analysis of the Israeli-Palestinian rhetoric if the dictionaries were valid? Answering
this question is important since many studies in communication are beginning to use
new LIWC dictionaries without any specific strategy for validation. While this article
offers one set of approaches to that question, it is vital to begin a validation dialogue
about LIWC to continuously develop its value for researchers. To lay the ground work
for this validation effort, this article will first discuss the theoretical foundations for
the previous Donohue and Druckman (2009) study.

Theoretical Foundations for the Dictionaries
Taking a cue from the classic work by Watzlawick, Bavelas, and Jackson (1967), the
Donohue and Druckman (2009) study referenced above as the starting point for this
validation study began with the theoretical argument that understanding the public
rhetoric displayed during the Oslo I period could best be accomplished by focusing on
how parties framed both their substantive and relational issues. In the field of conflict
and negotiation, understanding the substantive nature of disputants' positions can best
be estimated by focusing on peace and justice issues (Zartman & Kremenyuk, 2005).
Creating a climate for peace involves both parties looking forward to create options
for resolving the conflict, addressing the key issues dividing them, and building a
sustainable, peaceful vision for the future. However, creating this climate requires that
parties seek justice for prior transgressions. When parties feel as if some measure of
justice has been achieved, then they are able to look forward and focus on the future.
Thus, the interplay between messages focusing on the future and those focusing on the
past provide a good estimate of how parties are framing the substantive dimension of
their rhetoric.
Conceptually, backward-looking statements focus on ending the violence, accounting for past wrongs, and aiming for compromise outcomes that do not address the
underlying sources of conflict. These statements emphasize the symptoms of conflict,
often implying that the other party is responsible for the problem and that a resolution
depends largely on their concessions. They reflect and reinforce a competitive (or
distributive) bargaining process. In contrast, forward-looking statements are characterized by an attempt to address the underlying causes of the conflict by creating a new
framework intended to build a more constructive future. They focus on similarities,
the acknowledgement of mutual responsibility, and an awareness of the underlying

Donohue et al.

285

reasons for the conflict. The emphasis is on imagining a future in which peaceful relationships are sustained (Irmer & Druckman, 2009).
The messages that seem most capable of estimating the relational dynamics of the
Palestinian-Israeli dispute were derived from Relational Order Theory (Donohue &
Hoobler, 2002; Donohue & Roberto, 1993). Relational Order Theory holds that parties
are continuously negotiating relational frames across two dimensions--affiliation and
interdependence. The affiliation messages focus on trust, liking, friendliness, and
companionship, whereas the interdependence messages communicate how parties
view their rights and responsibilities in the relationship, or the amount of power they
have in influencing the other. These relational message combinations serve as proposals for how each party wants to frame the relationship between the parties making
them useful in estimating how the relationships evolve over time.
In terms of specific strategies, power is communicated through strong, forceful
acts; attempts to regulate, threaten, or manage the other; and giving unsolicited advice
or help. Affiliation is communicated through expressions of positive, friendly, or intimate feelings; sadness or regret for lost opportunities to restore relations; statements
of companionship or camaraderie; and trust or a willingness to share unique information and concede on key issues (Lewicki & Weithoff, 2000).
Examining both the substantive and relational features of the public language that
set the context for the original Oslo I study by Donohue and Druckman (2009) required
three pairs of constructs as a means of exploring both the integrative and distributive
intentions of the communicators. For the substantive dimension coders were asked to
identify instances of both looking forward (which is more integrative) and looking
backward (more distributive). For the relational dimensions they were asked to focus
on two pairs of relational markers in the language: power/affiliation and trust/mistrust.
Thus, these six pairs of constructs were used to understand both the substantive and
relational public contexts that speakers were creating during the course of the secret
Oslo I negotiations.
Using these constructs, coders were instructed to analyze these 40 speeches and
interviews focusing on these six constructs. This selection of documents consists of
statements made by official representatives in interviews and newspaper editorials.
There are a total of 40 articles, 20 from Palestinians and 20 from Israeli sources. The
timeframe of the documents ranges from the beginning of January 1993 to July 1993,
the month in which secret negotiations ended and 2 months before the agreement was
signed in Washington. All the documents were retrieved from the British Broadcasting
Corporation website and were written in English. Thus, no translations were needed.
The list of speakers and the time frames associated with the documents are shown in
Table 1.
Regarding the coding procedures, each thought unit (typically an independent
clause with a subject and verb or a meaningful, stand-alone utterance) in each speech
or interview was scored for each of the six constructs. The total for each construct was
summed and divided by the number of thought units in the document. This calculation
produced a ratio of the messages associated with each construct controlling for the size
of the document. The results indicated that

286

Journal of Language and Social Psychology 33(3)

Table 1. Speeches and Interviews by Group.
Palestinian documents
(1) 01.12.93 Arafat
(2) 01.13.93 Arafat
(3) 01.19.93 Sharif
(4) 02.10.93 Arafat
(5) 02.18.93 al-Qudwah
(6) 02-26-93 Ashrawi
(7) 03.10.93 Urayqat
(8) 03.14.93 Sharif
(9) 03.22.93 Arafat
(10) 03.31.93 Arafat
(11) 04-09-93 Arafat
(12) 04-21-93 Ashrawi
(13) 04-29-93 Ashrawi
(14) 05-11-93 Arafat
(15) 05-22-93 al-Sa'ih
(16) 05-23-93 Arafat
(17) 06-12-93 Sha'th
(18) 06-15-93 Arafat
(19) 06-30-93 Ashrawi
(20) 07.16.93 Sharif

1.
2.
3.

4.
5.
6.

Israeli documents
(1) 01-06-93 Beilin
(2) 01-15-93 Peres
(3) 01-21-93 Rabin
(4) 02.03.93 Yaacobi
(5) 02.04.93 Shoval
(6) 02-11-93 Rubinstein
(7) 03-09-93 Beilin
(8) 03.15.93 Rabin
(9) 03-30-93 Rabin
(10) 04-08-93 Rabin
(11) 04-13-93 Beilin
(12) 04-22-93 Rabin
(13) 05-06-93 Gal
(14) 05-14-93 Peres
(15) 05-23-93 Beilin
(16) 06-10-93 Rubinstein
(17) 06-19-93 Peres
(18) 06-22-93 Rubinstein
(19) 07.04.93 Peres
(20) 07.08.93 Sarid

The Palestinians used significantly more backward than forward-looking rhetoric, more mistrust than trust rhetoric, and more power than affiliation
messages
The Palestinians used more backward statements than Israelis while the Israelis
used more forward statements than the Palestinians
The Palestinians displayed more mistrust than Israelis while the Israelis displayed more trust messages and Palestinians displayed about twice as many
power messages as Israelis while both groups used about the same amount of
affiliation in their speeches
More mistrust statements were associated with progress in the talks for the
Israelis
More affiliation statements were correlated with retreat in the next week
For the Palestinians, looking backward was associated with lack of progress in
the talks

Methodological Issues
There are several interesting methodological issues related to the problem of using
specific dictionaries that count words as a means of assessing the presence of certain

Donohue et al.

287

constructs in the language. The first methodological issue we confronted relates to the
need to create new dictionaries or simply use those provided by the LIWC program.
As indicated above, our primary interest lies in creating LIWC dictionaries that tap
these three construct pairs to implement a more efficient strategy for analyzing additional Palestinian and Israeli speeches and interviews relevant to the Oslo II accords.
We felt a need to develop new dictionaries since it was clear that the validated dictionaries defined by Neiderhoffer and Pennebaker (2002) are not generally able to capture
the six constructs that were important to assess. For example, one of the validated
dictionaries is "past tense verbs" that might be able to estimate the construct of "looking backward." This dictionary includes a very long list of verbs that have no substantive focus, but are listed in the past tense such as accepted, cried, didn't, eaten, hated,
looked, paid, ran, said, and so on. The Looking Backward dictionary focuses on justice
related terms such as impasse, justice, stuck, unfair, wrong, and so on. Based on these
discrepancies, it was judged necessary to create new dictionaries that reflected the
specific substantive focus of the constructs.
The second methodological issue relates to the more fundamental question of
whether it makes sense conceptually to create LIWC dictionaries that simply count
words and decontextualize the language as a means of estimating the extent to which
speakers are expressing the six constructs of interest. Tausczik and Pennebaker (2010)
make the case that the context-free counting of words accurately estimates specific
psychological constructs such as emotion, social relationships, status, dominance,
social coordination, and honesty and deception. Of interest in this study, Tausczik and
Pennebaker cite several studies in which the use of certain word patterns was found to
be a reliable predictor of honesty and deception. When people lied or told the truth,
they varied words related to emotion, motion, exclusion, and first-person singular
words. In another study, Olekalns, Brett, and Donohue (2010) found that the use of
first-person pronouns (I, we), the use of future versus past tense, and the use of emotion words were significant settlement predictors in divorce mediation.
Based on these studies, it seems safe to conclude that counting certain kinds of
words can provide reliable estimates of at least some psychological states and specific
communication outcomes. However, the second conclusion from the Tausczik and
Pennebaker (2010) review is that the validity of these indicators must be established.
It should be clear that the collection of words intended to measure the constructs are
valid and reliable indicators. Unfortunately, there does not appear to be consensus
about the most appropriate strategy for conducting this validation process. As more
and more scholars begin to conduct LIWC-type analyses for text-based phenomenon
(e.g., online interactions), it becomes increasingly imperative to devise an appropriate
validation strategy.
Thus, the third and most important methodological issue is determining the most
effective validation strategy once it has been determined that (a) new dictionaries are
needed and (b) these dictionaries can be reliable markers of theoretically derived constructs. In our view, the validation strategy that makes the most sense will vary in how
abstractly or concretely the selected words capture the nature of the constructs. More
specifically, an abstract validation process would ask subjects to judge the relationship

288

Journal of Language and Social Psychology 33(3)

of the words to the constructs in a context-free task. The participants would simply be
given a set of words and the definition of the constructs and be asked to determine the
extent to which they generally matched one another independently of any given communication context. In the abstract, do these words generally define this psychological
state? Answering this question is a face validity task. The words that get the most
consensus become candidates for the second and more context-specific validation test.
A second-level and more concrete, contextually bound exploration of the relationship between the words and the psychological constructs would be the validation process used by Pennebaker and King (1999) in their original article. They asked subjects
to write essays about the constructs after which they conducted an LIWC analysis of
the essays using selected dictionaries. If the data revealed that the highest proportion
of the words in, for example, the negative emotion essay was from the negative emotion dictionary, then that would be evidence that the dictionary was a valid marker of
that construct.
Pennebaker and King (1999) did not stop there, however. They progressed to a third
validation level by linking the constructs to certain self-report psychological measurements of those constructs. They found that the derived dictionaries correlated highly
in the predicted direction with certain psychological orientations. While this strategy
is useful in validating the dictionaries in relation to external psychological constructs,
it is less useful as a means of tying the dictionaries to the analysis of speech text. In
other words, it would be important to know if the dictionaries are capable of capturing
the same constructs that coders identified when looking at the language in a very concrete context. If the dictionaries can do the same work as coders who looked at the
totality of language and then made judgments about the extent to which the language
communicated power, trust, or affiliation, then this would provide substantial evidence
about the validity of the dictionaries.
This last test is fairly rigorous in the sense that it holds the context-free LIWC
analysis to a context-dependent analysis standard derived from the judgment of coders. For example, coders might interpret a phrase as a high power move that does not
contain any power words from an LIWC dictionary. The assumption that LIWC makes
is that there are sufficient data available in the communication corpus to make it possible that communicators would eventually use words reflecting the constructs of
interest. If sufficient words are not available then it might be difficult to compare data
about the same constructs gathered from two very different methodologies. This issue
is particularly relevant where the LIWC dictionaries are potentially small. Since there
is a greater chance of detecting words from a larger dictionary, this validity test may
be too conservative.
However, since we have the data available from prior research and we aim to have
the LIWC dictionaries of the three paired constructs perform essentially the same
work as the coders, this validation test is essential to this project. As a result, we will
provide data from the three validation strategies outlined above: (a) surveying students
on whether the words abstractly fit the construct, (b) asking students to write essays
about the constructs and using all six LIWC dictionaries to analyze them to determine

Donohue et al.

289

if the hypothesized dictionary dominates, and (c) comparing the results of the coded
analysis with the LIWC dictionary results to see if they correlate.

LIWC Validation Study 1
Method
To derive the words related to the six constructs listed above, the authors asked experts
in the fields of conflict, negotiation, and international relations to look at each of the
six constructs and generate a list of words associated with each. In addition, the authors
consulted dictionaries and thesauruses for power, affiliation, trust, and mistrust and
assembled the words in a list. For the looking forward and backward constructs, the
authors assembled another list by referencing the chapters in the Zartman and
Kremenyuk (2005) book addressing this topic. After looking at the lists independently
and deciding on candidates for each construct, the authors then met together and discussed the lists that ultimately resulted in the first draft of the six dictionaries. The
number of words associated with each of the six constructs is as follows: Power = 16,
Affiliation = 28, Forward-looking = 29, Backward-looking = 22, Mistrust = 17, and
Trust = 18.
Examples of the words are: (a) Power: against, control, erupt, protect, take, warn;
(b) Affiliation: agree, connect, friend, kindness, listen, peace; (c) Forward-looking:
advance, bargain, future, hope, negotiate, peace; (d) Backward-looking: competitive,
fairness, injustice, impasse, past, return; (e) Mistrust: concern, dilemma, distrust,
doubt, hide, ulterior; and (f) Trust: appreciate, faith, depend, desire, empathic, share.
The dictionaries include the root version of these and the remaining words, so that, for
example, the word "faith" in the Trust dictionary would include "faithful" and any
other word that included "faith" in it. The entire list of words in each dictionary is
available from the first author.
To accomplish the first phase of the validation process, a total of 249 respondents
completed an online survey instrument via http://www.surveymonkey.com following
institutional review board approval. Respondents were recruited from the first author's
undergraduate communication course. On the survey instrument, respondents were
asked to evaluate the extent to which each of the derived words communicated one of
the six constructs (power, affiliation, forward-looking, backward-looking, trust, and
mistrust) using a 7-point Likert-type scale. Subjects completed the research as part of
their course requirements.
Because the number of derived words from the original lists varied greatly between
the six constructs, from 16 to 29 per construct, the next appropriate step was to use
several data reduction strategies and identify the subset of words that subjects perceived to most closely related to each of the constructs. As an exploratory study, four
general strategies were used to reduce the data: means analysis, t test analysis, ratio
analysis, and factor analysis.
The first strategy is to use the mean of each term to remove irrelevant words as
perceived by the participants. This method removed any words that students perceived

290

Journal of Language and Social Psychology 33(3)

to be less or somewhat related to the construct based on the 1 to 7 Likert-type scale.
Any mean of 3.5 or lower for the term was eliminated using this method. All other
words were included in the analysis. The weakness of this approach is that it establishes an arbitrary bar (3.5) over which all words must pass to be included. A word
might fall just below this bar but share a great deal of variance with the others on the
list, while a word that is above the bar might not exhibit a great deal of shared variance. Thus, it was decided to look at how each word fit with the shared variance of the
other words for each of the six constructs.
To accomplish this goal, t tests were used as a second possible data reduction strategy. This method assumes that deviation from the rest of the terms signals a lack of
conceptual coherence. To complete this analysis, the mean was computed for all the
words in a given construct. Then, a one-sample t test was computed testing each of the
terms against the mean for all terms in the construct. All words that were significantly
different at the .05 level from the average mean of the construct were eliminated using
this technique. Clearly, this method does not evaluate whether each term was perceived as more related to the construct in question; rather, it rids all terms that are not
similarly evaluated.
Another reduction technique that addresses the problem of how consistently a word
was perceived as part of the overall construct would use the mean in relation to the
standard deviation for each word. Referred to as a coefficient of variation, the mean
for each term was divided by its standard deviation. This generates a ratio of the number of standard deviations per word mean. Terms with a ratio of 3 and lower were
eliminated. This ratio value was selected arbitrarily as a cutoff because it indicated that
the mean to standard deviation was so low that a particular mean only ranged from
+1.5 SD to -1.5 SD. The ratio can be high if the mean is either high or low, and the SD
is also low. Or, the ratio can be low if the mean is either high or low, but the SD was
high, suggesting there were a lot of variation between subjects in their perception of
the term. Thus, the better terms are those with a relatively high mean and a low SD. All
terms at or below a ratio of 3 were eliminated using this approach. This approach
assumes that terms that were seen as more related to the construct and vary less should
be retained.
The last approach pursued a different conceptual stance based on the idea that the
terms ought to be examined in relation to one another. Those that appear related to the
shared variance of the construct should stay and those that fall outside of this shared
variance should be eliminated. To complete this analysis the subjects' judgments for
all the terms in a specific construct were factor analyzed. The underlying idea is that
any given set of terms should conceptually belong to at least one subdimension of that
construct. Exploratory factor analysis was computed for all the terms in a given construct since we had no hypotheses concerning how many factors might emerge for a
given list of words. Specifically, confirmatory factor analysis was not used in this case
since we did not have specific hypotheses about the number of factors that might
emerge in the course of the analysis. Our intent was to simply determine which words
loaded on some factor in the analysis. The logic is that if a word does not load on a
factor then its meaning to the subjects was ambiguous and should be deleted. A rotated

291

Donohue et al.
Table 2. Constructs and Frequency of Words With Each Data Reduction Strategy.

Full list
Mean analysis
Coefficient analysis
t-Test analysis
Factor analysis
Total number of words included from all analyses

Power

Affiliation

Forward

Backward

Mistrust

Trust

16
15
15
12
13
10

28
28
25
16
17
8

29
27
22
18
19
10

22
15
7
13
20
7

17
17
17
10
14
8

18
18
17
13
16
11

component matrix using Varimax rotation was generated and all factors with an eigenvalue of 1 or greater were extracted from the data. Any term with a factor loading of
less than .6 onto any of the factors was eliminated using this approach. The .6 limit
was selected to limit the likelihood that a given word would load on multiple factors.
In other words, lower limits are likely to include words that might load on multiple
factors, which would cast doubt in terms of how subjects are interpreting the word
relative to the intended construct.
The number of factors that emerged using these criteria for each of the six constructs include the following: Forward = 4 factors (62.1% of total variance), Backward
= 4 factors (65.2% of total variance), Affiliation = 6 factors (66.6% of total variance),
Power = 5 factors (70.2% of total variance), Trust = 3 factors (64.6% of total variance),
and Mistrust = 3 factors (58.9% of total variance).

Results
Table 2 shows the number of words associated with each of the six constructs from the
four data reduction strategies. The strategy that leaves the most words intact from the
original dictionary is the mean analysis. Yet it is interesting to note that there is some
significant variance among the four strategies. Specifically, the t test and coefficient
analysis significantly reduced words in the constructs of Forward, Backward, and
Mistrust. The last row of Table 2 lists the number of words that remain after using all
five reduction strategies. As might be expected, these numbers are quite small and
represent the most conservative list of words that might represent a given construct
based on the perceptions of the subjects.
The question is, which list should be used for subsequent analyses? Put another
way, which one is correct? There are at least two answers to this question. First, the
correct set of words might be those that make the cut from all these five strategies.
While this might provide the most correct list, it is also the most conservative since the
number of words left over from all these strategies is considerably less than the original lists increasing the probability of Type II error. Second, perhaps the list that makes
the most sense is the one that performs best on some external criterion. In this case, the
external criterion of most interest is the list's ability to mirror the results of the results
obtained from actual coders going through the documents of interest. Since this is a
validation study it makes sense to use five separate lists in the subsequent analyses to

292

Journal of Language and Social Psychology 33(3)

determine if any one list performs more effectively than any others. Study 3 provides
this analysis by correlating the results of each of the five different lists with coder
judgments about the speeches and interviews contained in Table 1.

Discussion
Asking subjects to evaluate the extent to which specific words are related to each of the
six constructs provides some feedback about the extent to which the words can tap the
constructs. However, the task is fairly abstract for undergraduate students who may not
be particularly interested in this kind of activity. Thus, we may not want to rely exclusively on external raters to provide cursory judgments about how specific words are
related to a construct to form an LIWC dictionary unless the raters are uniquely invested
in, or are familiar with, the context in which the dictionary will be used. For example,
perhaps we should have asked a group of political science students to comment on the
constructs after telling them that these will be used to analyze political speeches.
Nevertheless, this strategy provides at least a useful starting place to insure that the
words are not completely off base; however, it does not provide much information
about whether the words are useful in analyzing texts related to a specific context. In
addition, this approach requires that researchers decide on a strategy to determine
which words ought to be included in the final list. And that strategy really ought to be
theoretically based, if possible so there is some rationale about why it was selected. As
the data show, there is considerable variance associated with each of the strategies.
A final point about these dictionaries relates to the number of words in any given
dictionary regardless of whether it is newly created or is one of the currently available
dictionaries. Each dictionary contains a different number of words, and sometimes the
discrepancies are quite large. In this study, the original list of words contains a high of
29 and a low of 16. On the surface this discrepancy would appear to impact the hit
rates of each dictionary. The hypothesis is that the dictionary with the most words has
the greatest chance of picking up its respective construct. The logic against this kind
of thinking is that each construct is different so that it would not be expected to be
associated with the same number of words as any other construct. Some constructs
might be more visible than others or have a broader definition than others. Or, constructs might be more concrete and consist of a few number of specific terms whereas
others could be more abstract and associated with a large number of words. Ultimately
it comes down to whether or not the construct and the words predict the outcomes they
are intended to predict. In this vein, a second validation strategy was initiated that is
more in line with the Pennebaker and King (1999) approach to validation and tests this
idea that larger dictionaries might perform differently than smaller dictionaries.

LIWC Validation Study 2
Method
While the first validation strategy asks subjects to provide relatively abstract judgments about the relationship of each word to a general understanding of each

Donohue et al.

293

construct, we thought it might be useful to initiate an approach that asks subjects to
think more thoroughly about the constructs. Following Pennebaker and King's (1999)
original validation procedures, we asked 300 undergraduate students to provide openended essays for each of the six constructs in exchange for credit in their courses. Each
participant was given one of the six constructs (e.g., power) and asked to write an
essay in a free-flowing manner regarding what that particular word meant to them in a
political context for a period of 15 minutes. It was felt that casting the task in the context of politics would help participants describe several different ways in which each
of the six concepts could be understood. The resulting 300 essays (50 for each of the
six constructs) ranged from 59 words to 662 words in total with an average of 206
words.
We then analyzed each of the essays using the words from all six dictionaries with
each of the five lists produced from Study 1. The hypothesis is that the dictionary
related to the topic of the essay (e.g., power) would score significantly higher than
dictionaries unrelated to the topic for each of the six constructs across each of the five
reduction strategies. If this hypothesis is confirmed, then it would suggest that dictionary size does not necessarily influence the predictive capacity of the dictionary.

Results
The LIWC dictionary computes the frequencies of word use, in percentage, for each
construct. This frequency is cross-tabulated across data reduction methods. The full
results are tabulated in Table 3, which contains the average percentage of words
detected for each of the data reduction methods. For example, in the Power construct,
all the Power dictionaries picked up significantly more Power words than any of the
other construct dictionaries. Specifically, the Power dictionary picked up an average of
1.06% of the language in the power-focused essays, whereas the Affiliation dictionary
picked up only 0.26% of the words in the Power essays. Overall, the six constructs
were detected by the customized LIWC dictionary regardless of the data reduction
method used. When participants were asked to write about a particular construct (e.g.,
forward looking), the LIWC dictionary word count frequencies for that construct were
significantly higher than those from other constructs, demonstrating discriminant
validity. However, trust and affiliation differed less distinguishably. When participants
were asked to write about trust, the word count frequencies in the trust dictionary
across data reduction methods equated to those in the affiliation dictionary (average =
0.85%). Generally, the data in Table 3 indicate that the Full list and the Mean list pick
up the highest percentage of words in the essays. However, the Coefficient list also
performed fairly well across all six constructs, suggesting that creating a coefficient
that controls for the variance appears to be useful as well.

Discussion
This validation technique was somewhat more effective than the first technique in
providing information about the ability of the dictionaries to tap the specific constructs. When asked to write about each construct, the subjects used words appropriate

294

1. Power dictionary
2. Affiliation dictionary
3. Trust dictionary
4. Mistrust dictionary
5. Forward-looking dictionary
6. Backward-looking dictionary

0.26
0.22
0.49
0.52
0.68
4.38

Full

1.29
0.42
0.41
0.71
0.33
0.35

1.
2.
3.
4.
5.
6.

Power dictionary
Affiliation dictionary
Trust dictionary
Mistrust dictionary
Forward-looking dictionary
Backward-looking dictionary

Full

Data reduction strategy
1.21
0.41
0.38
0.69
0.33
0.34

t-Test
1.06
0.26
0.12
0.10
0.13
0.11

Factor

0.25
0.20
0.41
0.47
0.59
4.33

Mean
0.25
0.19
0.41
0.44
0.58
4.34

t-Test
0.26
0.18
0.42
0.45
0.63
4.27

Factor

Backward-focused essays

1.29
0.42
0.41
0.71
0.33
0.34

Mean

Power-focused essays

0.12
0.06
0.29
0.29
0.45
4.05

Coefficient

1.29
0.42
0.41
0.71
0.33
0.34

Coefficient

0.26
0.30
0.14
0.40
0.24
0.24

Full

0.85
1.83
1.12
0.57
0.83
0.79

Full
0.45
1.30
0.89
0.43
0.22
0.31

t-Test
0.56
1.34
1.04
0.52
0.78
0.72

Factor

0.26
0.30
0.14
0.40
0.24
0.24

Mean
0.04
0.00
0.08
0.20
0.05
0.04

t-Test

0.04
0.01
0.10
0.20
0.03
0.04

Factor

Mistrust-focused essays

0.85
1.83
1.12
0.57
0.83
0.79

Mean

Affiliation-focused essays

0.26
0.30
0.14
0.40
0.24
0.24

Coefficient

0.81
1.81
1.08
0.57
0.61
0.67

Coefficient

Table 3. Percentage of Words in Each Dictionary Across Constructs and Data Reduction Strategies.

0.55
0.86
0.86
0.52
0.31
0.30

Full

0.53
0.63
0.75
0.53
2.29
0.85

Full

0.35
0.18
0.28
0.26
2.21
0.69

t-Test

0.24
0.50
0.56
0.32
0.85
0.36

Factor

0.55
0.86
0.86
0.52
0.31
0.30

Mean

0.53
0.84
0.86
0.52
0.25
0.29

t-Test

0.48
0.85
0.83
0.51
0.31
0.30

Factor

Trust-focused essays

0.53
0.63
0.75
0.53
2.29
0.85

Mean

Forward-focused essays

0.53
0.84
0.86
0.52
0.31
0.29

Coefficient

0.43
0.48
0.70
0.50
2.08
0.72

Coefficient

Donohue et al.

295

to that construct and the dictionaries picked them up. The Full dictionary, Mean
Analysis, and Coefficient Analysis dictionaries were uniformly effective in discriminating between the constructs suggesting that either of these three approaches are good
candidates for determining which words should be included in the lists.
In general, this second validation process in combination with the first strategy
might be sufficient for most research purposes since all the dictionaries appear to do
their work effectively. In addition, the type of statistical process for eliminating words
also appears to be somewhat interchangeable. Three emerged as most useful in our
analysis. However, an even more rigorous test would be to apply these six dictionaries
to a set of documents that were coded for the presence of each of the six constructs. If
the LIWC dictionaries perform in a manner similar to the language perceived by coding each utterance in each text, then the dictionaries will become very useful in analyzing large data files that would be too difficult to code by hand.

LIWC Validation Study 3
Method
As indicated above, the context for this third validation study is the Donohue and
Druckman (2009) analysis of speeches surrounding the Oslo I accords. In that study,
40 speeches from Palestinian and Israeli leaders were analyzed for the presence of the
six constructs listed here. The authors and dates of those speeches are listed in Table 1.
The data from that study found that Palestinian and Israeli public rhetoric predicted
progress or retreat at the secret Oslo I accords. Coders were trained on each of the six
constructs and asked to analyze each utterance in each speech for the presence of these
constructs. Each speech received a score indicating the percentage of utterances that
contained information related to each of the six constructs. Thus, this Oslo I data set
allows us to correlate the results of that study with an LIWC analysis of each of the 40
speeches using the six dictionaries from each of the four data reduction strategies plus
the full list of terms. This analysis produced percentages of words used in a given text
file. The second author in this study cleaned all the interview files and prepared them
for analysis as suggested by Pennebaker and King (1999). All nonrelevant texts were
first removed, such as description of the interview/speech and time date location of
interview/speech.
To compare the efficacy of each data reduction technique, a separate LIWC dictionary was created for each data reduction technique. LIWC processed all the texts for the
40 interviews/speeches with each of the dictionaries independently. Then, LIWC produced a word percentage for each of the constructs across all four versions of the
techniques and the full list dictionary. The word percentages for each construct were
correlated with the coder-generated ratios in Donohue and Druckman (2009).

Results
The correlation among data reduction techniques and coder ratings are presented in
Table 4. Only one construct, forward-looking, emerged as a significant correlate with

296

Journal of Language and Social Psychology 33(3)

Table 4. Correlations Between Data Reduction Techniques and Coder Ratings.
Dimension correlations with coder rating
Data reduction
technique
1. Full list
p Value
2. Mean analysis
p Value
3. t-Test analysis
p Value
4. Ratio analysis
p Value
5. Factor analysis
p Value

Power

Affiliation

Forwardlooking

Backwardlooking

Trust

Mistrust

.08
.61
.08
.62
.06
.72
.08
.62
.26
.10

.20
.21
.20
.21
.32
.04
.16
.34
.18
.26

.46
.01
.46
.01
.41
.01
.42
.01
.31
.05

.05
.75
.01
.97
.02
.92
.08
.62
.06
.72

-.07
.69
.06
.72
-.09
.56
-.01
.72
.18
.27

.06
.72
-.07
.69
.16
.34
.06
.93
-.02
.92

the forward-looking coder ratings across all data reduction techniques and the full list
(average r = .41, p < .05). This is strong evidence that the LIWC dictionary terms for
forward-looking, regardless of the data reduction method, is sufficiently robust to
detect the construct of forward-looking. For the other constructs, the t test analysis
resulted in significant correlation for affiliation between LIWC and coder data, t(40) =
.41, p < .05. Factor analysis, on the other hand, produced a near significant correlation
for power, t(40) = .261, p = .10. None of the other constructs across data reduction
techniques produced a significant correlation between coder and LIWC data.

Discussion
The results of this third validation study make it clear that the words selected for the
Forward-looking construct reflect coders' perceptions in the original Donohue and
Druckman (2009) research. Regardless of the data reduction strategy used, the looking
forward construct correlates significantly with coders' perceptions of looking forward.
Results for the other five constructs were less revealing. To some extent the constructs
of Power and Affiliation were related to at least one data reduction strategy, but certainly not with the same kind of robust pattern observed for Forward-looking. The
dictionaries used to measure the constructs of affiliation, trust, and mistrust did not
pass this fairly conservative test.
How might we use this information to improve the ability of the LIWC dictionaries
to mirror what coders would find? One strategy would be to isolate each thought unit
coded in a particular way and ask coders to identify the word/words that prompted
their choice. Words that they cite most often for the same code might then be eligible
for inclusion in a revised dictionary. Then, that revised dictionary could be used to
determine if it is better at mirroring what coders find. Since so much of coding depends
on context this strategy may or may not work since word meaning changes with context. Yet it may stand the best chance of creating an LIWC dictionary that substitutes
for coding.

Donohue et al.

297

Discussion and Implications
The main purpose of these three studies was to identify a validation strategy for creating LIWC dictionaries to measure communication constructs of interest to researchers.
Since LIWC work is expanding, it seems vital that scholars engage in a robust effort
to identify the best strategy for building these dictionaries. Our goal was to provide a
range of strategies that might be useful in applying the LIWC process to the analysis
of actual texts. It should be recalled that the original Pennebaker and King (1999) validation strategy was aimed at correlating the dictionaries with various psychological
constructs. Our goal was to craft a validation process that was more in line with how
the LIWC dictionaries might be used. Specifically, if the goal is to identify dictionaries
that capture key themes of speeches then it makes sense to validate the dictionaries
against other strategies aimed at capturing these themes.
Unfortunately, the results of the studies reported here failed to validate the six dictionaries using all three strategies. As a result, it would be important to evaluate
whether the three-pronged validation process was ultimately effective. The first strategy for validating dictionaries is aimed primarily at establishing face validity to determine if a group of untrained subjects can reach a consensus about the extent to which
the various words are linked to the defined construct. The key challenge is identifying
a conceptually grounded statistical method for including or excluding words. The
results from Study 1 indicate that the Mean analysis retained the most words while the
t-test analysis eliminated the most. The results from Study 2 indicate that the Mean
analysis and the Coefficient analysis performed effectively in picking up the constructs from the student essays. The results from Study 3 found that only the LIWC
words from the Forward-looking construct correlate with coder perceptions of the
constructs. Forward-looking codes of the texts contained many of the terms found in
the Forward-Looking dictionary.
To better understand the disconnect between the LIWC analysis and the coder judgments about the constructs, it is useful to examine a specific paragraph of a speech to
see how both systems pick up, or fail to pick up, the intended meanings of the speakers. For example, consider this paragraph from an interview given by Yasser Arafat on
Radio Monte Carlo in Paris on Friday, January 1, 1993. Arafat gave the following
response to a question asking him to describe the atmosphere of the future of peace
talks with each sentence numbered as thought units:
1.
2.
3.
4.
5.
6.

"In fact, the atmosphere of the talks was positive.
We found a good response to our proposal that a speedy solution to this tragedy
be found.
This is not only a human tragedy, but a political tragedy as well.
It is a process of transfer [preceding word in English], an act of ethnic cleansing by Israel.
It is a war crime against our cadres and leadership . . . (Four additional thought
units were provided that are not relevant here.)
I told him (UN Secretary-General) what Rabin brazenly said after (US envoy
James) Jonah was sent.

298
7.
8.

Journal of Language and Social Psychology 33(3)
Rabin seemed as though he was uninterested, unaffected and oblivious to the
UN resolutions or their implementation, or even to international legitimacy.
I asked him whether international legitimacy was one or two standards. One
standard against Palestine and the Arab nation and one standard in Israel's
favor?"

Thought-Unit 1 was coded as an instance of affiliation. Yet none of the words in
that thought unit are contained in the LIWC affiliation dictionary. It might be possible
to include the word "positive" in the affiliation dictionary. However, this word can be
used in a nonaffiliative way by saying, "I am positively horrified by the aggressive
tactics!" Similarly, Thought-Unit 2 was coded as a Forward-looking unit by coders,
and also contains the word "positive," which is also included in the Forward-looking
LIWC dictionary. Thought-Units 4 and 5 were coded as Power units by coders, but
they contain no words in the LIWC Power dictionary. Thought-Units 6 and 7 were
both coded as Mistrust by coders, but do not contain any words in the LIWC Mistrust
dictionary. For example, the word "brazenly" in this context communicates mistrust,
but is sufficiently uncommon that including it in the Mistrust dictionary might not be
practical. Finally, in Thought-Unit 9, Arafat uses the word "against," which is included
in the LIWC Power dictionary and was coded as a Power thought unit by coders.
This example illustrates how difficult it can be to use lists of words to replicate coders' interpretations of events. Perhaps one reason for the greater success of the LIWC
dictionary for the Looking Forward construct is that this construct is more specific and
easier to detect than the others. Specifically, this dictionary contains words that have
specific behavioral referents that are strong indicators of looking forward such as bargain, concession, negotiate, recognize, resolution, hope, future, and so on. Coders
were instructed to look for these same kinds of words or activities in determining
whether an utterance is "looking forward." In contrast, the Power list is much less
behaviorally oriented with such words as against, alert, authority, concern, control,
disrupt, erupt, force, fool, hold, and so on. The example presented above illustrates
that coders were looking more broadly at utterances and more in the context of the
other thought units to determine if any given unit exhibits "power" or "trust" any of
the other similarly ambiguous constructs.
The important counter to this argument is that the three-pronged validation approach
may be too conservative for most purposes. It may be sufficient to create dictionaries
by asking experts to generate words they believe reflect the constructs and then extracting additional words from targeted texts that reflect the nature of the constructs.
Following this process it seems necessary to perform the validation tasks in Studies 1
and 2 to whittle down the lists. Requiring the third approach in which the lists are correlated with coder impressions may be too conservative a test since coders have the
added benefit of examining the context of each utterance to determine the presence or
absence of the targeted construct. When the constructs are fairly abstract, we discovered that researchers are opening themselves up to the possibility of a disconnect
between analyzing constructs using lists of words on the one hand and coder impressions on the other hand. In other words, LIWC perform more effectively in capturing

Donohue et al.

299

coder impressions when the constructs have specific behavioral referents, as in the
case of the forward-looking construct.
For our purposes, we began this project with the goal of using the dictionaries to
analyze additional Palestinian and Israeli speeches to determine if we can replicate the
results we observed for Oslo I for the Oslo II process. In other words, were the public
speeches made by leaders on each side once again driving progress at the bargaining
table? The Oslo II process was similarly protracted as Oslo I. The goal of Oslo II was
to implement the framework created in Oslo I. This second round of talks began in
August 1994 and concluded with the signing of the Oslo II agreement on September
28, 1995, in Washington, D.C. between Yasser Arafat, the Chairman of the PLO, and
Yitzhak Rabin, the Israeli Prime Minister. Unfortunately, Rabin was assassinated on
November 4 of that year making implementation of the agreement difficult. The question is which of the six dictionaries would be effective in examining the public speeches
surrounding the Oslo II accords? Since all six constructs passed both the face validity
test in Study 1, and the construct validity test in Study 2, we feel it is appropriate to use
all six dictionaries for our analysis of the speeches. Yet we understand that we may not
necessarily replicate the results we discovered in the first Oslo I study since we are not
using coders who use contextual information to make fairly abstract judgments about
constructs such as trust, mistrust, power, and affiliation. Thus, a mixed strategy may
work best.
A mixed coding process would use the LIWC dictionaries that demonstrate the
most validity, such as constructs with behavioral referents. Then, coders would be
used for constructs that are more abstract such as trust, mistrust, power, and affiliation,
for example. The primary advantage of this approach is that the overall time required
for coding the six constructs would be reduced by using the LIWC dictionaries for
some of the coding. A key disadvantage of this mixed approach is that mixing methodologies in a study can create ambiguous results. It may not be clear whether the results
are driven by one or the other coding method or by the theories underlying the hypotheses. The mixed strategy may risk confusing methods with concept variance.
Future research should continue to pursue the task of determining additional validation strategies for LIWC dictionaries. One strategy related to asking subjects to rate
the abstract connection between words and constructs, as we performed in Study 1, is
to ask trained experts to make these judgments rather than untrained subjects. Perhaps
the untrained subjects are less effective in imagining the full scope of the construct and
to reflect carefully on the particular words that capture that construct. If experts are not
available perhaps a more extensive training program for subjects would be useful to
enable them to see the construct at work in various contexts. For example, for the
power construct, subjects might be trained to watch videos, read a paragraph, or perform some other task that helps them understand how political leaders or negotiators
communicate power in those situations.
A second validation strategy that might be more appropriate than the one we
attempted for Study 3 would be to code the essays generated in Study 2. Using this
methodology, the coders would be trained to score their impressions of each utterance
in each of the generated essays. Then, the correlations between the dictionaries for

300

Journal of Language and Social Psychology 33(3)

these essays and the coder impressions might make more sense. In our study, English
was not the native language of the Palestinian and Israeli leaders whose speeches we
analyzed. For abstract constructs, in which context and linguistic variation matter a
great deal, it would probably be best to validate them on native English speakers rather
than on native speakers.
The final issue of relevance in crafting a dictionary validation process relates to the
strategies that were used to reduce the number of words in each list. Three of the four
data reduction strategies looked at the list of words independently from one another.
Only the factor analysis procedure made an attempt to look at shared variance among
the words. Work on the constructs must develop conceptually so that we can hypothesize that different words ought to hold together in specific ways. Accomplishing this
goal requires developing conceptually meaningful dimensions of each construct. For
example, what are the key dimensions of power? It might be meaningful to derive
words that concentrate on coercive power and others to concentrate on interpersonal
influence. The conceptual dimensions of trust that included calculus, knowledgebased, and identity-based forms were also ignored in this study. Thus, future attempts
at validating the LIWC dictionaries should be based on more rigorous conceptual
work.
Looking forward toward next steps in the research, it would be helpful to expand
the number and range of transcripts to be coded for validation. The validation study
would benefit as well from the development of specific hypotheses. This would have
the advantage of providing theoretically informed analyses that focus the statistical
work on the hypotheses. It would also reduce the number of correlations to be calculated, thus lowering the risk of Type I errors. The study reported in this article is
regarded as a first step. It provides a model for validation analysis and prepares the
groundwork for the next generation of studies.
Acknowledgments
We thank Howie Giles and the anonymous reviewer for helpful comments.

Declaration of Conflicting Interests
The author(s) declare no potential conflicts of interest with respect to the research, authorship,
and/or publication of this article.

Funding
The author(s) received no financial support for the research, authorship, and/or publication of
this article.

References
Donohue, W. A., & Druckman, D. (2009). Message framing surrounding the Oslo I Accords.
Journal of Conflict Resolution, 53, 119-145.
Donohue, W. A., & Hoobler, G. D. (2002). Relational ripeness in the Oslo I and Oslo II negotiations. In E. Gilboa (Ed.), Media and conflict: Framing issues, making policy, shaping
opinions (pp. 65-88). Ardsley, NY: Transnational.

Donohue et al.

301

Donohue, W. A., & Roberto, A. J. (1993). Relational development as negotiated order in hostage negotiation. Human Communication Research, 20, 175-198.
Irmer, C., & Druckman, D. (2009). Explaining negotiation outcomes: Process or context?
Negotiation and Conflict Management Research, 2, 209-235.
Lewicki, R. J., & Weithoff, C. (2000). Trust, trust development, and trust repair. In M. Deutsch
& P. Coleman (Eds.), The handbook of conflict resolution: Theory and practice (pp. 86107). San Francisco, CA: Jossey-Bass.
Neiderhoffer, K. G., & Pennebaker, J. W. (2002). Linguistic style matching in social interaction.
Journal of Language and Social Psychology, 21, 337-360.
Olekalns, M., Brett, J., & Donohue, W. A. (2010). Words are all I have: Linguistic cues as
predictors of settlement in divorce mediation. Negotiation and Conflict Management
Research, 3, 145-168.
Pennebaker, J. W., & King, L. A. (1999). Linguistic styles: Language use as an individual difference. Journal of Personality and Social Psychology, 77, 1296-1312.
Tausczik, Y. R., & Pennebaker, J. W. (2010). The psychological meaning of words: LIWC
and computerized text analysis methods. Journal of Language and Social Psychology, 29,
24-54.
Watzlawick, P., Bavelas, J. B., & Jackson, D. D. (1967). Pragmatics of human communication:
A study of interactional patterns, pathologies, and paradoxes. New York, NY: Norton.
Zartman, I. W., & Kremenyuk, V. (2005). Peace versus justice. Negotiating forward and backward-looking outcomes. Lanham, MD: Rowan & Littlefield.

Author Biographies
William A. Donohue is currently a professor in the Department of Communication at Michigan
State University. His research focuses on various conflict-resolution contexts such as hostage
negotiation, divorce mediation, and international negotiation. He has published widely in various communication and conflict journals and produced several books focusing on communication and conflict issues.
Yuhua Liang is currently an instructor at Chapman University with an emphasis in strategic
and corporate communication. His research involves understanding how online users select and
process information from social media sources. He has published in several journals including
Journal of Computer-Mediated Communication and Media Psychology.
Daniel Druckman is a professor of public and international affairs at George Mason University
and an eminent scholar at Macquarie University in Sydney Australia. Among his many publications are two recent books: Doing Research: Methods of Inquiry for Conflict Analysis (Sage,
2005) and, with Paul F. Diehl, Evaluating Peace Operations (Lynne Reinner, 2010). Both these
books received the outstanding book award from the International Association for Conflict
Management (IACM). He also received a lifetime achievement award from the IACM and coedits a book series on International Negotiation with William Donohue.

