Language, Cognition and Neuroscience

ISSN: 2327-3798 (Print) 2327-3801 (Online) Journal homepage: www.tandfonline.com/journals/plcp21

Effect size matters: the role of language statistics and
perceptual simulation in conceptual processing
Max M. Louwerse, Sterling Hutchinson, Richard Tillman & Gabriel Recchia
To cite this article: Max M. Louwerse, Sterling Hutchinson, Richard Tillman & Gabriel
Recchia (2015) Effect size matters: the role of language statistics and perceptual simulation
in conceptual processing, Language, Cognition and Neuroscience, 30:4, 430-447, DOI:
10.1080/23273798.2014.981552
To link to this article: https://doi.org/10.1080/23273798.2014.981552

Published online: 01 Dec 2014.

Submit your article to this journal

Article views: 1175

View related articles

View Crossmark data

Citing articles: 3 View citing articles

Full Terms & Conditions of access and use can be found at
https://www.tandfonline.com/action/journalInformation?journalCode=plcp21

Language, Cognition and Neuroscience, 2015
Vol. 30, No. 4, 430-447, http://dx.doi.org/10.1080/23273798.2014.981552

Effect size matters: the role of language statistics and perceptual simulation in
conceptual processing
Max M. Louwersea,b*, Sterling Hutchinsona, Richard Tillmana and Gabriel Recchiab
a

Tilburg Center for Cognition and Communication(TiCC), Tilburg University, Tilburg, The Netherlands; bDepartment of Psychology, The
University of Memphis, Memphis, TN, USA
The cognitive science literature increasingly demonstrates that perceptual representations are activated during conceptual
processing. Such findings suggest that the debate on whether conceptual processing is predominantly symbolic or
perceptual has been resolved. However, studies too frequently provide evidence for perceptual simulations without
addressing whether other factors explain dependent variables as well, and if so, to what extent. The current paper examines
effect sizes computed from 126 experiments in 51 published embodied cognition studies to clarify the conditions under
which perceptual simulations are most important. Results showed that effects of language statistics tend to be as large or
larger than those of perceptual stimulation. Moreover, factors that can be associated with immediate processing (button
press, word processing) tend to reduce the effect size of perceptual simulation. These findings are considered in respect to
the Symbol Interdependency Hypothesis, which argues that language encodes perceptual information, with language
statistics explaining quick, good-enough representations and perceptual simulation explaining more effortful, detailed
representations.
Keywords: embodied cognition; language statistics; symbol interdependency; conceptual processing

A central topic in the cognitive sciences concerns the
question of how linguistic symbols attain meaning.
Attempts to answer this question have clarified the nature
of conceptual processing and have generated heated
debates, with some researchers arguing that the nature of
conceptual processing is predominantly determined by an
amodal system (Fodor, 1975; Tulving, 1983) and others
arguing that it is instead determined by a modal system
(Barsalou, 1999; Glenberg, 1997). The amodal cognition
account holds that perceptual states are transduced into a
representational system that describes these states symbolically. In contrast, the embodied cognition account
holds that perceptual states are transduced into a representational system that describes these states as modal
and related to the perceptual state that produced them
(Barsalou, 1999).
The debate between symbolic and embodied cognition
(de Vega, Glenberg, & Graesser, 2008) is occurring in
many fields within the cognitive sciences, from psychology (Pecher & Zwaan, 2005), philosophy (Shapiro, 2011)
and education (Sadoski & Paivio, 2012) to neuroscience
(Hauk & Tschentscher, 2013) and linguistics (Knott,
2012). It is hard to argue that it is a moot debate, since
hundreds of journal articles, book chapters and conference
proceedings have given rise to some answers and many
new, important questions about the role that perception
plays in various cognitive processes.

*Corresponding author. Email: M.M.Louwerse@uvt.nl
(c) 2014 Taylor & Francis

The symbolic and embodied accounts of cognition
have been presented as being divergent from each other
(de Vega et al., 2008; Fodor, 2008; Glenberg, 2010;
Glenberg & Robertson, 1999; van Dantzig, Pecher,
Zeelenberg, & Barsalou, 2008). At first, it seems unlikely
that anyone would argue for an extreme symbolic or
embodied viewpoint. The literature, however, does frame
symbolic and embodied accounts as contrary to one
another. First, in those studies that emphasise a symbolic
view, researchers in the field of embodied cognition are
excluded (Landauer, McNamara, Dennis, & Kintsch,
2007) and vice versa (Pecher & Zwaan, 2005; Semin &
Smith, 2008). Second, despite the fact that the debate
takes place in many areas of the cognitive sciences, the
divergence between the accounts can also be seen in
the methodologies. Experimental methods are typically
applied in studies that conclude cognition is predominantly embodied, and computational methods typically
are applied in studies that conclude it is predominantly
symbolic. In various papers, extreme viewpoints are even
explicitly stated: "I don't find direct realism remotely
plausible as epistemology, still less as psychology"
(Fodor, 2008, p. 6); "At one time, psychological theory
asserted that symbols become meaningful by participating
in a network of other symbols, such as semantic networks
or high-dimensional spaces. It is now relatively well
accepted that this story won't do" (Glenberg, 2010,

Language, Cognition and Neuroscience
p. 587); "Such [symbolic] notations may be adequate for
the purpose of the particular theory, but they constitute a
problem for the question how these symbols are given
meaning" (van Dantzig et al., 2008, p. 580).
Divergent views are not uncommon to the cognitive
sciences (e.g., the nature versus nurture debate, the freewill versus determinism debate). In fact, the history of the
debate in the cognitive sciences of whether behavioural
traits are primarily genetic or environmental can be
characterised by a pendulum that swings from one
extreme view to the other over the span of many centuries.
In the early part of the twentieth century the nature view
was most dominant, followed by the nurture view. The
cognitive revolution in the 1950s (Miller, 2003) shifted
the focus back to nature. The symbolic and embodied
cognition debate seems no different. With respect to the
embodied versus symbolic debate, the pendulum has
already swung multiple times within the past century
(Barsalou, 2008). The importance of the perceptual system
dominated in the 1950s-1970s (Gibson, 1966; Skinner,
1957). Around the cognitive revolution in the 1970-
1980s, an appreciation for a symbolic system began to
dominate with the mind-as-a-computer metaphor yielding
proposals for symbolic formats of mental representations
(Fodor, 1975; Kintsch, 1998; Tulving, 1983). From the
1990s onward, an emphasis was again placed on perceptual representations rather than non-perceptual symbolic
representations (Barsalou, 1999; Glenberg, 1997; Zwaan,
2004). In fact, over the last two decades many studies
have supported this view and have shown evidence for
the activation of perceptual representations in cognitive
processing.
The evidence that perceptual simulation plays a role in
language processing is still accumulating and is diverse.
For instance, studies have shown that when animal names
were presented at the top of the screen or the bottom of
the screen, animals that fly were processed faster when
there was a match with the location, i.e., upper screen
(Pecher, van Dantzig, Boot, Zanolie, & Huber, 2010; Setic
& Domijan, 2007). Similarly, Estes, Verges, and Barsalou
(2008) showed participants a context word (e.g., cowboy)
followed by an upper location (e.g., hat) or lower location
(e.g., boot) cue. A target letter then appeared at the top or
bottom of the screen. Participants identified the target
faster in the matching location than in the mismatching
location. Meteyard, Zokaei, Bahrami, and Vigliocco
(2008) conducted a lexical decision study in which motion
words (e.g., rise, climb, fall, drop) were superimposed on
a visual motion pattern. They found that lexical decision
times were slower when the semantic content of a motion
word was incongruent with the direction of a visual
motion pattern near the participant's threshold of vertical
motion perception. This effect was also found for less
concrete concepts: words such as God and Devil are
processed faster in their matching high or low vertical

431

position on the screen (Meier, Hauser, Robinson, Friesen,
& Schjeldahl, 2007), and evaluations of positive words
(e.g., ambitious) were faster when words were at the top
rather than the bottom of the screen, whereas evaluations
of negative words (e.g., bitter) showed the opposite
pattern (Meier & Robinson, 2004). Schubert (2005)
demonstrated a similar effect for the concept of power,
where powerful words were processed faster at the top of
the screen. In a similar vein, Bergen, Lindsay, Matlock,
and Narayanan (2007) asked participants to listen to
sentences like the mule climbed or the chair toppled
followed by a geometric shape in the upper or lower
region of the screen. Results demonstrated that sentences
matching the position of the shape on the screen facilitated
processing, suggesting that language triggers visual
imagery.
Evidence for perceptual simulation extends beyond
words to sentences, with sentence descriptions matching
pictorial representations. Stanfield and Zwaan (2001) and
Zwaan, Stanfield, and Yaxley (2002) presented participants with a shape of an object or animal that matched its
function of its location in a sentence (e.g., The ranger saw
the eagle in the sky or The ranger saw the eagle in a nest)
and found that matching pictures facilitated processing.
These findings were modulated by individual differences,
for instance the age of the participant or the familiarity
with the object. Dijkstra, Yaxley, Madden, and Zwaan
(2004) showed that the mismatch effect (e.g., There was
spaghetti in the bowl/box followed by a picture of raw or
cooked spaghetti) was larger in older participants (74
years old) than in younger participants (18 years old). Holt
and Beilock (2006) asked sport experts (ice hockey and
football players) and novices to read sentences describing
a sports action (e.g., The referee saw the hockey helmet on
the bench) and non-sports situations (e.g., The child saw
the balloon in the air), followed by a picture of a target
object. Both novice and expert athletes responded more
quickly to a picture matching the action described, but
only experienced athletes showed an effect for matching
sports.
The evidence for perceptually simulating the location
and shape can also be found for simulation of colour.
Connell and Lynott (2009) asked participants to read a
sentence with implicit colour information, such as Jane
tasted the tomato when it was ready to eat or Jane tasted
the tomato before it was ready to eat, followed by the
presentation of a colour-associated object word, such as
tomato in typical red, atypical green or unrelated brown
ink. When the colour word matched the colour implied by
the previous sentence colour naming was easier. Meier,
Robinson, and Clore (2004) found a similar Stroop-like
relationship between brightness and affect in a categorisation task in which participants had to classify words as
positive or negative, observing categorisation interference
in a condition in which positive words were presented

432

M.M. Louwerse et al.

in a dark font and negative words were presented in a
bright font.
But language activates more than visual perceptual
simulations. Myung, Blumstein, and Sedivy (2006) found
that when a word such as typewriter was presented
auditorily, participants made faster decisions about the
target word following a related prime that shared manipulation features (e.g., piano) than an unrelated prime (e.g.,
blanket). These manipulation features can be translated
into concrete actions. Borreggine and Kaschak (2006)
asked participants to make sensibility judgements on
sentences that describe action towards their body (i.e.,
Mark dealt the cards to you) or away from the body (i.e.,
You dealt the cards to Mark). Response times were faster
if the participant's arm movement was in the same
direction as the action described by the sentence. And
this action effect is not limited to literal meaning. In
Santana and de Vega (2011), participants read orientational literal sentences (e.g., she climbed up the hill),
metaphors (e.g., she climbed up in the company) and
abstract sentences with similar meaning to the metaphors
(e.g., she succeeded in the company). When participants
were asked to perform a speeded upward or downward
hand motion while reading the verb in the sentence, the
hand motion matching the direction described by the
sentence facilitated processing in both the literal and
figurative meaning. And when Buccino et al. (2005)
asked participants to listen to hand-motor action sentences
(he turned the key) or foot-related action sentences (he
kicked the ball), they too found activation of the motor
system. Both motor-evoked potentials through transcranial
magnetic stimulation (TMS) as well as hand- versus footresponse times showed a facilitating effect for an actionmatching-effector. Motor activation can also be found for
emotions. Havas, Glenberg, and Rinck (2007) measured
respond times to sentences describing emotionally laden
events when the participant was in a matching (smiling) or
mismatching (frowning) emotional state. Pleasant sentences (e.g., You and your lover embrace after a long
separation) were processed faster when smiling, whereas
unpleasant sentences (e.g., The police car rapidly pulls up
behind you) were processed faster when frowning.
Finally, in Borghi, Glenberg, and Kaschak (2004),
participants read a sentence describing an object or a
location from an inside (e.g., You are eating in a restaurant),
an outside (e.g., You are waiting outside a restaurant) or a
mixed (e.g., You are walking toward and entering a
restaurant) perspective. Probe words referred to objects
typically found inside (e.g., table) or outside (e.g., sign).
Borghi et al. (2004) found that the speed of part verification
varied with the perspective, again demonstrating evidence
for perceptual simulation in language processing.
This overview of studies is by no means exhaustive.
Barsalou (2008, 2010), Bergen (2012), Pecher and Zwaan
(2005), and Semin and Smith (2008) describe additional

studies. Indeed, the hundreds of studies that provide
evidence for perceptual simulation in conceptual processing are valuable in that they point out that perceptual
simulations in conceptual processing should not be
dismissed. However, what these experimental studies
typically do not address is the question whether factors
other than perceptual simulation also explain response
times, and, if so, whether they explain the response times
to the same extent. Moreover, the question can be raised to
what extent the effect of perceptual simulation on
conceptual processing varies across different situations.

1. Symbol interdependency
Recently, we have proposed the Symbol Interdependency
Hypothesis (Louwerse, 2007; Louwerse, 2011a). According to this hypothesis, language processing involves both
language statistical processes and perceptual simulation.
However, the extent to which these types of processing
dominate is modulated by various factors such as the
cognitive task, individual differences, the stimulus and
the time course of processing. The starting point for the
Symbol Interdependency Hypothesis is that language
encodes perceptual information (Louwerse, 2008). That
is, evolutionary processes have shaped the language
system into a convenient tool (Christiansen & Chater,
2008) where verbal and nonverbal knowledge gets
encoded in utterances of language users, so that as a
function of language use, perceptual information gets
encoded (Louwerse, 2008). Comprehenders utilise these
structures in their conceptual processing, at least when
quick, good-enough representations are formed (Ferreira,
Bailey, & Ferraro, 2002). For more full-fledged, detailed
mental representations, comprehenders rely on the richness that perceptual simulations provide. Consequently,
both symbolic and perceptual processes play a role in
conceptual processing, but the extent to which one
outperforms the other depends on the language use and
the task with which it is used.
The Symbol Interdependency Hypothesis is similar to
Paivio's (1971, 1986) Dual Coding Theory, which also
allows for interconnections between verbal and non-verbal
representational processes. Verbal stimuli allow for pictorial representations (linking word to picture) and imaginal stimuli allow for linguistic representations (linking
picture to word). However, in the Dual Coding Theory,
the role of the linguistic system in cognition remains
limited. This role is clearer in the language and situated
simulation (LASS) theory (Barsalou, Santos, Simmons, &
Wilson, 2008), where the activation of the linguistic
system is argued to peak first, prior to a peak in activation
of the perceptual system. However, different than LASS,
the Symbol Interdependency Hypothesis builds upon the
language system encoding perceptual information, so that

Language, Cognition and Neuroscience
with limited grounding, the meaning is bootstrapped
through language statistics.
1.1. Statistical linguistic cues
There is an increasing amount of evidence that language
encodes perceptual information. Perhaps this is most
obvious in the frequency of two-word combinations,
such as up-down, high-low and top-bottom. The frequency of a [high concept] [low concept] pair is considerably higher than the [low concept] [high concept]
alternative (Louwerse, 2008). This is true for inanimate
concepts in the world around us, as well as concepts such
as body parts, with head-shoulders, arms-legs, knees-
toes being more frequent than the reverse ordering (Tillman, Hutchinson, & Louwerse, 2013). Similarly, positive
concepts tend to be mentioned before negative concepts
(happy-sad, positive-negative, heaven-hell), and this
pattern can be extended to concepts related to authority
and gender (Hutchinson & Louwerse, 2013a). In fact, for
many concept words used in embodied cognition experiments, the frequency pattern matches the perceptual
relation.
How the perceptual order gets translated into language
statistics can perhaps be explained by the theory of
markedness, proposed by Greenberg (1966). According
to Greenberg, a more frequent word in a word pair is
unmarked (i.e., most natural, simplest, first learned) and
the less frequent is the marked, with unmarked members
preceding marked members. The idea of markedness
ranges over phonological, grammatical and semantic
elements (Chomsky & Halle, 1968). Hutchinson and
Louwerse (2013a) have shown that markedness can even
be used as an explanation to the spatial-numerical
association of response codes (SNARC) effect. A standard
SNARC effect shows that when subjects make even/odd
judgements about numbers, response times are faster for
smaller numbers when responding with their left hand,
with the opposite result for right-hand responses and
larger numbers. This occurs supposedly because participants perceptually simulate number magnitude on a
mental number line. However, Hutchinson and Louwerse
(2013b) showed that a negative correlation between
number magnitude and frequency might explain the
SNARC effect too. They found that response times to
high-frequency words (unmarked words) were faster when
responding with the left hand, with the opposite result for
right-hand responses, suggesting that those words that are
unmarked are naturally processed faster when they appear
before (to the left of) marked words.
Examples of language encoding perceptual information
indicate that language is far less arbitrary than what is
often assumed in the perceptual simulation literature
(Glenberg & Robertson, 1999). Language statistics is not
restricted to word combinations. In fact, there is increasing

433

evidence that the claim that language is arbitrary (De
Saussure, 1916) needs to be weakened, with sound
patterns predicting the meaning of a word (Monaghan,
Christiansen, & Fitneva, 2011; Monaghan, Shillcock,
Christiansen, and Kirby, 2014). However, the effect of
language statistics is most prominent in the language
system at large. For instance, we have found that the
geographical location of cities can be predicted based on
the way city words are mentioned in language. Cities that
are located together tend to appear in similar linguistic
contexts, allowing for an estimate of the longitude and
latitude of a city in a country, whether that country is the
USA (Louwerse & Zwaan, 2009), China or the Middle
East (Louwerse, Hutchinson, & Cai, 2012), the UK
(Davies, 2013), or the fictional Middle Earth from the
Lord of the Rings trilogy (Louwerse & Benesh, 2012). In
fact, with sufficient language input, the accuracy of the
geographical estimates is rather high (Recchia, 2014;
Recchia & Louwerse, 2014). For the 50 largest US cities,
location estimates based solely on linguistic statistics from
three different corpora are consistently correlated with
both human geographical estimates and actual geographic
locations (r > .5) across a wide variety of parameter
settings. It is also possible to supplement linguistic
statistics with spatial knowledge. Language statistics alone
can reveal that San Francisco is closer to Los Angeles than
it is to Atlanta, but this information is much more useful if
we already know the locations of Los Angeles and
Atlanta. Consistent with the Symbol Interdependency
Hypothesis, correlations to both human geographical
estimates and actual geographic locations improve markedly when linguistic statistics are supplemented with such
spatial information (Recchia & Louwerse, 2014). Cooccurrences between city names and nicknames (e.g., New
York City and The Big Apple) have also been used to
successfully match English municipalities with their
colloquial names (Recchia, 2014), and hierarchical clustering analyses have demonstrated that the topographic
organisation of administrative regions in China is encoded
in patterns of place name co-occurrences on web pages
(Liu et al., 2014).
The answer to the question whether language encodes
perceptual information leaves another question - the
central question in the symbolic and perceptual debate -
unanswered: whether language users utilise these language
structures in their conceptual processing. After all, it
might well be the case that because of perceptual
simulations, language happens to be encoding perceptual
information, but that language users do not rely on these
structures. The experimental evidence shows a different
picture. In studies whereby participants made semantic
judgements for words like attic-basement, researchers had
strongly argued in favour of a perceptual simulation
account (Setic & Domijan, 2007; Zwaan & Yaxley,
2003). However, Louwerse (2008) investigated whether

434

M.M. Louwerse et al.

the vertical configuration of word pairs like [attic-
basement] could be best explained by perceptual ratings
(ratings of how likely is it that attics appear above
basements) or language statistics (the frequency with
which attic precedes basement versus the frequency with
which basement precedes attic in the English language).
The results showed that both factors, perceptual ratings
and language statistics, explained the response times in a
semantic judgement task. Importantly, in the few cases for
which the two accounts made opposite predictions (the
low word preceded the high word), the language statistics
account outperformed the perceptual simulation account.
The studies that showed that geographical information
is encoded in language called for a similar experiment: do
language users rely on the language statistics in the first
place? It is difficult to distinguish perceptual processes
(e.g., memories of maps, locomotion) from processes
operating on language statistics. After all, the two are
assumed to be intertwined. However, a world that
participants have not experienced visually might provide
a solution. Middle Earth provides such a world. Readers
of the Lord of the Rings trilogy, who had not seen a map
of Middle Earth, were asked to estimate the geographical
location of the cities in Middle Earth. Participants who
had not read the Lord of the Rings trilogy were asked to
do the same. In addition, we estimated the geographical
location of the cities computationally, such that place
names that co-occurred in the Lord of the Rings were
placed more closely together. The results showed that the
estimates between the Lord of the Rings readers were
more correlated with the computational estimates than
with the actual estimates, whereas an opposite result was
found for those who studied the maps. In other words, the
task at study time influenced whether participants relied
on perceptual information or symbolic information to
generate perceptual map estimates (Louwerse & Benesh, 2012).
The findings that language users rely on language
statistical patterns are not conclusive, but at least they
indicate that the role of language statistics should not be
ruled out in perceptual simulation experiments.
1.2. Modulators of statistical linguistic and perceptual
processing
The conclusion in most embodied cognition studies that
perceptual simulation is activated in conceptual processing
assumes a one-size-fits-all approach. It seems plausible,
however, that the effect of perceptual simulation is
modulated by the experimental variables being used. The
question of whether conceptual processing activates
perceptual simulations can then be replaced by the
question of under what conditions perceptual simulations
are most active. That question seems to be more productive, as it considers the extent various factors, including

perceptual simulation and language statistics factors, play
a role, rather than simply asking if these factors play a
role. In various studies, we have attempted to answer that
question, by considering the nature of the stimulus being
used, individual differences, the cognitive task and the
time course of processing.
1.2.1. Nature of the stimulus
Barsalou (1999) argues convincingly that it is unlikely
that processing a picture will simply generate an amodal
symbolic representation. Instead, perceptual processes
lead to perceptual representations. Others would agree
with this view. For instance, Kintsch (1998, p. 47) states
that perceptual symbols, imagery and actions are among
the building blocks of cognition, and Landauer and
Dumais (1997, p. 235) argue that perceptual world
knowledge underlies an associative learning theory. The
important question, however, is whether linguistic symbols must always be transduced into perceptual symbols.
Barsalou (1999, p. 652) acknowledges the importance of
structured representations, propositions, frequency effects
and pattern completion in conceptual processing. Similarly, Paivio's (1971, 1986) Dual Coding Theory postulates that both visual and verbal information are processed
differently and along distinct channels. Others strongly
argue that linguistic symbols must be transduced into
perceptual simulations (Pecher & Zwaan, 2005), leaving
little room for an amodal symbol system (Glenberg &
Robertson, 1999).
In our research, we have argued that comprehenders
interpret both linguistic and non-linguistic stimuli with
both linguistic and non-linguistic processes, but the extent
to which a particular type of process will dominate
processing can be expected to depend on the nature of
the stimuli (e.g., Louwerse & Jeuniaux, 2010). That is,
pictures also activate linguistic representations and words
also activate perceptual representations. Louwerse and
Jeuniaux (2010) investigated this question by comparing
the effect of both language statistics and perceptual ratings
on the response times in a semantic judgement task of
words and pictures. Concept pairs such as monitor and
keyboard were presented in a vertical configuration. In
one set of experiments, the concept stimuli were words; in
the other the concept stimuli were pictures. Participants
were asked to evaluate the relationship between the two
concepts. The results showed that language statistics and
perceptual simulations both explained the response times
to both pictorial and linguistic stimuli, but language
statistics explained word processing better than perceptual
ratings did, but for pictures the effect of perceptual ratings
dominated the effect of language statistics.
Many embodied cognition studies have shown that an
independent variable associated with perceptual simulation explains response times. What is often unknown is

Language, Cognition and Neuroscience
what the effect size is of this association and whether
another factor (e.g., language statistics) explains the
response times equally well or - in the case of linguistic
stimuli - much better.
1.2.2. Individual differences
Do people activate perceptual simulations similarly? A few
studies have provided insight for this question. Dijkstra
et al. (2004) found that the effect of a picture mismatching a
sentence was stronger for older than for younger adults.
The authors explained this effect by older adults being
involved in deeper processing, whereas younger adults
focus more on the surface structure of the sentence,
resulting in a weaker perceptual simulation effect. Holt
and Beilock's (2006) finding that comprehenders with
experience on a topic yield perceptual representations that
are more differentiated than comprehenders without experience suggests a similar direction. Deeper understanding of
the stimuli yields (deeper) perceptual simulations.
Hutchinson and Louwerse (2013a) investigated individual differences on a dimension other than experience.
They found that gender differences also impact how much
participants rely on perceptual or linguistic representations
in conceptual processing as men typically perform better
on spatial and perceptual tasks (Benbow & Stanley, 1983;
Casey, Nuttall, & Pezaris, 2001), whereas females typically outperform men on language tasks (Andreano &
Cahill, 2009; Bornstein, Haynes, Painter, & Genevro,
2000; Burman, Bitan, & Booth, 2008). Male and female
participants made semantic judgements for related metaphorical word pairs. When making semantic judgements
on word pairs, female participants relied more on statistical linguistic frequency patterns whereas males relied less
so on linguistic representations. Such findings indicate
that factors related to gender can also impact the extent to
which individuals rely on statistical linguistic frequencies
during language processing.
The effect of perceptual simulations and linguistic
representations on conceptual processing seems to be
modulated by individual differences, such as age or
expertise. The effect size might even be affected by
participant gender, making it a relevant factor to take
into account in drawing conclusions on the nature of
conceptual processing.
1.2.3. Cognitive task
The Dijkstra et al. (2004) and Holt and Beilock (2006)
studies show that experience yields larger effect sizes in
the relation between perceptual simulation and response
times. It can thereby be argued that experience seems to
yield deeper processing, and deeper processing yields
perceptual simulations. Can deeper processing also be
manipulated by the cognitive task participants need to
perform? There is some evidence from the embodied

435

cognition literature that this is the case. Borreggine and
Kaschak (2006) asked participants to hold a keyboard on
their lap in a 90 angle, so that the Q key was located near
the participant and the P key away from the participant.
They then listened to a sentence like Joe kicked you the
soccer ball or You kicked Joe the soccer ball. Participants
were asked whether the sentence was sensible. Near-body
responses yielded faster responses for Joe kicked you the
soccer ball with an opposite effect for You kicked Joe the
soccer ball and reverse for the away-from-body responses.
When the participant was able to prepare and execute the
motor response, the effect was strongest. Knowing what
motor action was required elicited an action-sentence
compatibility effect, perhaps because of the deep conceptual processing of the stimuli.
Louwerse and Jeuniaux (2010) tested the effect of the
cognitive task on the extent to which language statistics or
perceptual ratings predicted RT values. Participants were
asked to either make semantic judgements or iconic
judgements regarding words that shared iconic and
semantic relationships. That is, for semantic judgements participants were asked to determine whether the
concept pairs had a similar meaning, whereas for the
iconicity judgements participants were asked whether
the concepts had the same relation in the perceptual
world, as the relation presented on the screen (e.g.,
monitor above keyboard). We argued that cognitive
processing in the iconicity judgement task was deeper
than in the semantic judgement task, because a prerequisite for the iconicity judgement was a semantic judgement.
Effect sizes for perceptual simulation were larger for
the deeper cognitive task (iconicity judgement) than the
shallow cognitive task (semantic judgement) with the
opposite result for effect sizes for language statistics.
These findings suggest that when participants form
detailed, full-fledged representations of the concepts being
presented to them, because they have the experience to do
so, because they plan their response or because the
cognitive tasks requires them to do so, the effect size of
perceptual simulation seems to be larger.
1.2.4. Time course of cognitive processing
If language statistics dominate in shallow cognitive tasks
and perceptual simulation dominates in deeper cognitive
tasks, and if deeper cognitive tasks imply shallow
cognitive tasks, the prediction is that in conceptual
processing language statistics precede perceptual simulation. This is what the Language and Situated Simulation
(LASS) theory predicts (Simmons, Hamann, Harenski,
Hu, & Barsalou, 2008). In conceptual processing, both the
linguistic system and the simulation system become active
initially, but activation in the linguistic system peaks first.
In an fMRI experiment, Simmons et al. (2008) found that
activations early in processing overlapped with activations

436

M.M. Louwerse et al.

for word associations (Broca's area in the left inferior
frontal gyrus), whereas activations late in processing
overlapped with activations for situation generation (right
posterior Superior Temporal Sulcus). "When linguistic
forms and associated statistical information are sufficient
for adequate performance, no retrieval of conceptual
information is necessary. This does not mean that these
strategies are insignificant, given their obvious heuristic
value" (p. 107). The Symbol Interdependency Hypothesis
(Louwerse, 2007; Louwerse & Jeuniaux, 2008) makes the
same prediction. Because the linguistic system encodes
perceptual information, language statistics allows for
good-enough representations, whereas perceptual simulation allows for deeper conceptual representations. Louwerse and Connell (2011) tested this on modality words,
in both a computational linguistic and an experimental
setting. The computational linguistic analysis showed
categorising modality words based on linguistic frequency
resulted in three categories: visual/haptic, auditory and
olfactory/gustatory. Whereas a perceptual account clearly
distinguishes between five modalities, the language statistics account only allowed for a less fine-grained classification. They predicted that if language statistics
dominate early in conceptual processing, the effect size
of language statistics should be highest for fast response
times and lowest for slow response times, whereas the
opposite should hold true for perceptual simulations. In a
response time experiment, they found that the coarsegrained language statistics variable best explained fast
response time and fine-grained perceptual simulation
variable best explained slow response times, with both
variables explaining medium response times.
Louwerse and Hutchinson (2012) extended this conclusion in an electroencephalography (EEG) experiment.
In a task where subjects made semantic or iconic
judgements about word pairs, neural activity over the
time course of each trial was recorded. The objective was
to compare activity, over the trial's duration, between
regions of the brain either commonly associated with
linguistic processing or with perceptual processing. They
found linguistic cortical regions were relatively more
active than perceptual cortical regions early in a trial.
However, the reverse was true later in the trial, supporting
the notion that language statistics dominate in early
processing and perceptual representations become more
important as a trial progresses.
Linguistic forms and associated statistical information
allow for heuristic processing (Simmons et al., 2008), fast,
good-enough representations (Louwerse & Connell, 2011;
Louwerse & Hutchinson, 2012), whereas perceptual
simulation allows for a deeper conceptual understanding.
Another way to think about the relationship between
shallow and deep processing is by analogy to the
distinction between "System 1" and "System 2" (Stanovich & West, 2000) popularised by Kahneman (2003).

Kahneman does not support a modular view of mind and
emphasises the two systems are not actual systems but
are merely used for illustrative purposes. System 1 refers
to a set of cognitive processes that occur quickly,
automatically, in parallel, and below the level of conscious
awareness, while System 2 refers to more effortful,
controlled, sometimes rule-governed processes that generally involve the deployment of limited, cognitively
expensive resources such as attention and willpower.
While some embodied processes certainly belong to
System 1 as well - particularly processes involving
associations between words and emotions, or words and
basic percepts - we have argued that it is unlikely that
language users construct a complete mental simulation
for every sentence they comprehend (Louwerse, 2011a).
Perceptual simulations that go beyond simple association,
therefore, are more in the domain of System 2: too
resource-intensive to be undertaken in circumstances
under which associations among words will suffice
for the completion of the task at hand (Louwerse &
Connell, 2011).
In conclusion, factors such as stimulus and cognitive
task modulate the effect of perceptual simulation on
conceptual processing. We have given an overview of
our own evidence and placed this in the theoretical
framework of the Symbol Interdependency Hypothesis.
What we do not know, however, is to what extent
modulators such as stimulus and cognitive task affect the
results of published embodied cognition studies.
2. Effect size matters
2.1. Perceptual simulation
Knowing the estimated magnitude of results reported in
published embodied cognition studies would allow for (1)
measuring whether the average effect size of perceptual
simulation variables is small or large and (2) determining
factors which influence the effect size. The problem with
an investigation like this is that the modulators we
identified earlier are often not specified in embodied
cognition studies. The following overview of embodied
cognition studies below should therefore be seen as an
exploration.
Searches for the studies to be included in the analysis
were conducted between 2010 and 2012. Search terms for
PsycInfo and Google Scholar were embodiment, embodied
cognition and perceptual simulation. We extracted 51
studies on the basis of the following criteria: (1) studies
had to address some component of embodiment (e.g.,
action compatibility, spatial orientation), (2) be published
between 1999 and 2012 in a peer-reviewed journal with
an impact factor >1 (M = 3.6, SD = 1.46), (3) include
experiments; theoretical papers were not included; (4)
include language stimuli; gesture studies or studies using
only pictorial or video stimuli but not language were

Language, Cognition and Neuroscience
excluded; (5) include statistically analysable and comparable results, such as ANOVAs or mixed effects models,
and their details, such as F values, df's, M and SD.
From the 126 experiments in these 51 studies, we
extracted information regarding the type of response (e.g.,
response time or rating), the method of response (e.g.,
button press or otherwise), stimulus type (e.g., pictures,
words), and when relevant to the experimental design, we
also collected information regarding the domain of stimuli
(e.g., configuration of the stimuli).
For each experiment, we collected df, t, N and F values
from critical analyses demonstrating embodied effects.
Because only 33 out of the 126 experiments (27%)
reported effect sizes, we computed the variance explained
(partial 2 or R2 values) for each experiment using the
method in Fritz, Morris, and Richler (2012) and Louwerse
and Jeuniaux (2010). That is, the strength of a model
association is represented as a weighted ratio of the F
statistic. R2 and F used in ordinary regression analysis are
R2 =k
where k is the
closely related, since F1/4 1R2 =Nk1
number of model parameters and N is the number of cases,
such that F has (k, N - k - 1) df. See also Pedhazur (1997,
p. 105). Thus, partial eta squared (g2p ) can be calculated as
dfeffect Feffect
dfeffect Feffect dferror . This formula represents the sum of
squares of the effect of interest, divided by the sum of
squares of the error plus the sum of squares of the effect.
This means that for any experiment that reports df and F
values, an effect size of partial eta squared can be
calculated.
The average effect size of the 126 experiments was
2 = .185 (SD = .177). According to Cohen (1988, p.
287), this can be viewed as a large (2 > .14) effect size,
explaining approximately 19% of the variance of the
dependent variable.
Next we aimed to determine which factors best
explained the effect sizes. Four variables occurred frequently in the selected studies: the use of response time as
the dependent variable, the use of vertical configuration of
the stimuli, button press as the method of response and the
use of single words rather than sentences as stimuli
(Appendix 1). We dummy-coded (Cohen & Cohen,
1983) stimulus type (i.e., single words), type of response
(i.e., RT), method of response (i.e., button press) and
domain of stimuli (i.e., vertical configuration), and ran a
mixed effects regression model using the four dummycoded variables as independent variables and the effect
sizes as dependent variables. Whether or not a response
time method was used did not affect the 2 effect size, F
(4, 121) = 1.82, p = .18, 2 = .057, (M = .194, SD = .134
vs. M = .182, SD = .185) and neither did the vertical
configuration of the stimuli, F (4, 121) = .536, p = .47, 2
= .017, (M = .184, SD = .178 vs. M = .184, SD = .176).
Whether or not single words (as opposed to sentences,
paragraphs or pictures) were used as stimuli did influence

437

2, with the use of single words reducing effect size, F(4,
121) = 3.52, p = .04, 2 = .104, (M = .162, SD = .144 vs.
M = .227, SD = .221). Similarly, whether or not
participants were asked to respond to stimuli with button
presses influenced 2 with the use of button presses
marginally reduced the effect size, F(4, 121) = 4.29,
p = .06, 2 = .124, (M = .140, SD = .111 vs. M = .197,
SD = .190).
Computing the effect size 2 is useful, because the
cognitive science community is most familiar with this
measure of effect size. However, the use of 2 comes at a
price. Fritz et al. (2012) caution that 2 as an effect size
value becomes less meaningful when comparing different
studies with different error terms. In this paper, we
therefore also calculated the less common but in case of
different error terms more accurate Hedge's g effect size.
However, some experimental designs are not optimal for
computing Hedge's g (e.g., three or more groups, unspecified number of subjects), so both measures of effect size
were included.
Hedge's g is a measure of effect
does
not rely on df
rffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
 that 
   ffi
1
1
but instead is calculated as t 
n1  n2



3
 1  4n1 n
for between subject designs and

  2 9
 3 
2pffiffi t
 1  4n9 for within subject designs. The
as
n
average effect size of Hedge's g was = .965 (SD = .711),
considered a large effect (Lakens, 2013). The correlation
between Hedge's g measure of effect and 2 was strong at
r (126) = .857.
However, performing the same analysis now using
Hedge's g, only the use of single words explained the
dependent variable of effect size, F (4, 121) = 10.452,
p = .002, 2 = .257, (M = .826, SD = .438 vs. M = 1.224,
SD = 1.002). Type of response (e.g., RT) F (4, 121) =
.384, p = .536, 2 = .013, (M = .898, SD = .387 vs. M =
.976, SD = .762), stimuli configuration F (4, 121) = 2.31,
p = .131, 2 = .071, (M = .982, SD = .731 vs. M = .892,
SD = .626) and method of response (e.g., button press)
F (4, 121) = 2.35, p = .128, 2 = .072, (M = .795, SD =
.310 vs. M = 1.011, SD = .781) did not explain the effect
sizes, even though the patterns were the same as with 2.
These results suggest that if the stimulus is simple, for
instance a word, the effect sizes supporting an embodied
cognition account are smaller than those responses that
move beyond button presses or word level stimuli. When
responses are quick, for instance by means of button
presses, there are indications that effect sizes may be
smaller, but this was not confirmed by a Hedge's g
analysis.
There are a number of explanations for the finding that
the use of single words reduces the effect size in embodied
cognition findings. One explanation is that responses to
simple stimuli such as words are noisier than responses
that are more complex, such as sentences. That is, without

438

M.M. Louwerse et al.

being constrained by context single words exhibit greater
variance than responses to sentences, which can likely
be explained by single words being semantically noisier
than context-specific sentences (see for an identical
argument that responses to individual sentences are
noisier than combinations of sentences Yang, Mo, and
Louwerse [2012]).
Another explanation is that larger text units such as
sentences or paragraphs require deeper processing and
higher engagement and hence yields larger effect sizes.
The smaller effect sizes for single word stimuli would then
be explained by the cognitive task. Indeed, Louwerse and
Jeuniaux (2010) have demonstrated that a deeper cognitive task, one that implies another task (e.g., an iconicity
task that implies a semantic judgement task) yields a
larger effect size for a perceptual simulation factor than for
language statistics factor, whereas a relatively shallow
cognitive task yields a larger effect for a language
statistics factor than a perceptual simulation factor.
A third explanation focuses on the time course of
processing: single words yield quicker processing and
quicker processes are better explained by language statistics than by perceptual simulation. This explanation is
supported by Louwerse and Connell (2011) who showed
that slower response times are best explained not only by
perceptual simulation, but also by Louwerse and Hutchinson (2012) who showed that perceptual cortical regions
compared to linguistic cortical regions were more active
late in a trial.
These three explanations are not mutually exclusive.
What these findings and their explanations demonstrate is
that the effect size matters depending on constraints
placed on the cognitive processes.
2.2. Language statistics
The effect sizes found for embodied cognition studies are
large, warranting the conclusion that cognition is embodied. We have made the argument that this conclusion
should be drawn with caution. Different constraints
modulate these effect sizes, and throughout this article,
we have made the argument that other factors such as
language statistics explain cognitive processes. The question needs to be answered whether the effect sizes for
language statistics are as large as those for perceptual
simulation.
We extracted 16 studies on the basis of the following
criteria: (1) studies had to be peer-reviewed in a journal or
conference proceedings article; (2) include response time
experiments; theoretical papers were not included; (3)
include language stimuli, where word frequencies were
used as an independent variable; (4) include statistically
analyzable and comparable results such as ANOVAs or
mixed effects models, and their details, such as F values,
df's, M and SD. The selected studies are presented in

(Appendix 2). These studies included a total of 58
experiments. The average 2 of the language statistics
variables in these studies was large (M = .169, SD = .188).
Partial eta squared (g2p ) for language statistics analyses did
not statistically differ from the effect sizes found in the
embodied cognition analyses reported earlier, F (1, 182) =
.672, p = .280, 2 = .004, M = .185, SD = .177 vs. M =
.169, SD = .188.
As in the perceptual studies, the use of single words
again explained the dependent variable of effect size, F (4,
52) = 4.34, p = .042, 2 = .257, (M = .022, SD = .030 vs.
M = .186, SD = .195). Type of response (e.g., RT) F (4,
52) = .005, p = .942, 2 = .013, (M = .245, SD = .186 vs.
M = .158, SD = .191), stimuli configuration F (4, 52) =
.584, p = .448, 2 = .071, (M = .189, SD = .202 vs. M =
.136, SD = .175) and method of response (e.g., button
press) F (4, 52) = 1.952, p = .168, 2 = .072, (M = .446,
SD = .031 vs. M = .156, SD = .186) did not explain the
effect sizes.
However, as pointed out earlier, 2 is not ideal for
computing effect sizes from studies with different error
terms (Roberts & Monaco, 2006). Particularly, because the
majority of the language statistics studies used mixed
effects models with - consequently - larger degrees of
freedom than ANOVAs, 2 as the measure of effect size
underestimates the effect sizes of these studies. We
therefore again calculated Hedge's g to allow for comparability of the results between studies.
As with the 2 as the effect size, the average Hedge's g
was high (M = 1.31, SD = .805), and so was the
correlation between the 2 and Hedge's g, r (58) = .79.
The same analysis for Hedge's g resulted in significant
differences for linguistic and perceptual effect sizes, F (1,
175) = 8.07, p = .005, 2 = .044, with embodied factors
having weaker effects than linguistic factors, M = .965,
SD = .711 vs. M = 1.31, SD = .805. This finding is in line
with Hutchinson and Louwerse (2013a) and Louwerse
(2008) who found that when perceptual simulation and
language statistics are compared ceteris paribus, language
statistics turns out to be the strongest predictor of
cognitive processing.
3. General discussion
Language processing activates the simulation of perceptual experiences. This conclusion has been drawn in many
studies that have argued that cognition is embodied. With
the wealth of evidence in favour of perceptual simulations,
there can be little doubt that embodiment plays a role in
numerous cognitive processes. Questions that have been
much less closely investigated include whether cognitive
processes always rely on perceptual processes, whether
these processes also rely on other factors and to what
extent and whether any effects are modulated by individual differences, the nature of the cognitive task, the

Language, Cognition and Neuroscience
nature of the stimulus and the time course of processing.
In the current paper, we have called for an exploration of
these questions.
In earlier work, we proposed the Symbol Interdependency Hypothesis, which argues that language has encoded
perceptual simulations. Consequently, language users can
rely on language statistics, on perceptual simulation or on
both factors in conceptual processing. Indeed, we have
found that for various studies that have reported an effect
of perceptual simulation, a complementary factor, language statistics, explained results equally well or better
(Louwerse, 2011a). We argued that because linguistic
statistical frequencies are built on perceptual information,
with very limited symbol grounding, language users can
bootstrap meaning from these statistics, at least when
forming quick, good-enough representations.
In the current paper, we evaluated patterns in the effect
sizes of reported studies. For a total of 51 studies including
126 experiments, we computed the effect sizes for a
perceptual simulation variable. There have been concerns
that effect sizes for some embodied cognition studies are
small (e.g., Wilson & Golonka, 2013) but the overview
shows that effect sizes reported for embodied cognition
studies overall tend to be large. However, the conclusion that
large effect sizes demonstrate that perceptual simulation
therefore explains cognitive processing needs to be put in
perspective. A factor that many of our studies have shown to
be complementary to perceptual simulation, language statistics, has also been shown to have large effect sizes.
The effect sizes also allow for some exploratory
analyses on their nature. In a regression analysis, we
have found that when single words are used as stimuli, the
effect sizes for perceptual simulation are reduced. This is
in line with studies that have argued that perceptual
simulation is relatively slower than statistical linguistic
results (Hutchinson & Louwerse, 2012; Louwerse &
Connell, 2011) and dominates in deeper cognitive tasks
(Louwerse & Jeuniaux, 2010). Moreover, when the effect
sizes of perceptual simulation and language statistics from
published studies are compared, the effect sizes for
language statistics are significantly higher than for perceptual simulation.
It is important to emphasise that we do not argue that
perceptual simulation does not play a role early in
processing, or that perceptual experiences are not activated in shallow cognitive tasks. Instead, the effect of
perceptual simulations compared to for instance language
statistics is less in shallow cognitive tasks that yield faster
processing, compared to deeper cognitive tasks that yield
slower processing (in which cases language statistics play
a less prominent role).
We started this paper stating that the cognitive sciences
can be characterised by debates in which the proverbial
pendulum swings from one extreme view to the other. In
the late 1990s, the pendulum started to move towards

439

embodied accounts of cognition. We would like to caution
against extreme views. Barsalou (1999) took a more
moderate stance. He argues three basic approaches to
knowledge can be distinguished: classic representational
approaches based on amodal symbols, statistical and
dynamical approaches and embodied approaches. Theories should try "to integrate the positive contributions of all
three approaches" (Barsalou, 1999, p. 652). We wholeheartedly agree and would like to call for studies that
measure the effects on conceptual processing of
approaches that are perhaps not as divergent as debates
in meaning and cognition would like us to believe.
References
Andreano, J. M., & Cahill, L. (2009). Sex influences on the
neurobiology of learning and memory. Learning & Memory,
16, 248-266. doi:10.1101/lm.918309
Barsalou, L. W. (1999). Perceptual symbol systems. Behavioral
and Brain Sciences, 22, 577-660.
Barsalou, L. W. (2008). Grounded cognition. Annual Review of
Psychology, 59, 617-645. doi:10.1146/annurev.psych.59.103
006.093639
Barsalou, L. W. (2010). Grounded cognition: Past, present, and
future. Topics in Cognitive Science, 2, 716-724. doi:10.1111/
j.1756-8765.2010.01115.x
Barsalou, L. W., Santos, A., Simmons, W. K., & Wilson, C. D.
(2008). Language and simulation in conceptual processing.
In M. De Vega, A. M. Glenberg, & A. C. Graesser (Eds.),
Symbols, embodiment, and meaning (pp. 245-283). Oxford,
UK: Oxford University Press.
Bergen, B. K. (2012). Louder than words: The new science of
how the mind makes meaning. New York, NY: Basic Books.
Beilock, S. L., & Goldin-Meadow, S. (2010). Gesture changes
thought by grounding it in action. Psychological Science, 21,
1605-1610. doi:10.1177/0956797610385353
Beilock, S. L., & Holt, L. E. (2007). Embodied preference
judgments: Can likeability be driven by the motor system?
Psychological Science, 18(1), 51-57. doi:10.1111/j.14679280.2007.01848.x
Benbow, C. P., & Stanley, J. C. (1983). Sex differences in
mathematical reasoning ability: More facts. Science, 222,
1029-1031. doi:10.1126/science.6648516
Bergen, B. K., Lindsay, S., Matlock, T., & Narayanan, S. (2007).
Spatial and linguistic aspects of visual imagery in sentence
comprehension.
Cognitive Science,
31, 733-764.
doi:10.1080/03640210701530748
Borghi, A. M., Glenberg, A. M., & Kaschak, M. P. (2004).
Putting words in perspective. Memory & Cognition, 32, 863-
873. doi:10.3758/BF03196865
Borreggine, K. L., & Kaschak, M. P. (2006). The action-sentence
compatibility effect: It's all in the timing. Cognitive Science,
30, 1097-1112. doi:10.1207/s15516709cog0000_91
Bornstein, M. H., Haynes, O. M., Painter, K. M., & Genevro, J. L.
(2000). Child language with mother and with stranger at home
and in the laboratory: A methodological study. Journal of
Child Language, 27, 407-420. doi:10.1017/S0305000
900004165
Buccino, G., Riggio, L., Melli, G., Binkofski, F., Gallese, V., &
Rizzolatti, G. (2005). Listening to action-related sentences
modulates the activity of the motor system: A combined
TMS and behavioral study. Cognitive Brain Research, 24,
355-363. doi:10.1016/j.cogbrainres.2005.02.020

440

M.M. Louwerse et al.

Burman, D. D., Bitan, T., & Booth, J. R. (2008). Sex differences in
neural processing of language among children. Neuropsychologia, 46, 1349-1362. doi:10.1016/j.neuropsychologia.2007.
12.021
Casey, M. B., Nuttall, R. L., & Pezaris, E. (2001). Spatialmechanical reasoning skills versus mathematics self-confidence
as mediators of gender differences on mathematics subtests
using cross-national gender-based items. Journal for Research
in Mathematics Education, 32(1), 28-57. doi:10.2307/749620
Chomsky, N., & Halle, M. (1968). The sound pattern of English.
New York: Harper and Row.
Christiansen, M. H., & Chater, N. (2008). Language as shaped
by the brain. Behavioral and Brain Sciences, 31, 489-509.
Cohen, J. (1988). Statistical power analysis for the behavioral
sciences (2nd ed.). Hillsdale, NJ: Erlbaum.
Cohen, J., & Cohen, P. (1983). Applied multiple regression/
correlation analysis for the behavioral sciences (2nd ed.).
Hillsdale, NJ: Erlbaum.
Connell, L., & Lynott, D. (2013). Flexible and fast: Linguistic
shortcut affects both shallow and deep conceptual processing. Psychonomic Bulletin and Review, 20, 542-550.
doi:10.3758/s13423-012-0368-x
Connell, L., & Lynott, D. (2009). Is a bear white in the woods?
Parallel representation of implied object color during language comprehension. Psychonomic Bulletin & Review, 16,
573-577. doi:10.3758/PBR.16.3.573
Connell, L., Lynott, D., & Dreyer, F. (2012). A functional role
for modality-specific perceptual systems in conceptual
representations. PLoS One, 7, e33321. doi:10.1371/journal.
pone.0033321.t001
Davies, C. (2013). Reading geography between the lines:
Extracting local place knowledge from text. In T. Tenbrink,
J. Stell, A. Galton, & Z. Wood (Eds.), Conference on spatial
information theory (COSIT) (pp. 320-337). Scarborough,
UK: Springer.
de Saussure, F. (1916). Cours de linguistique generale (C. Bally
& A. Sechehaye, eds.), trans. W. Baskin, Course in General
Linguistics, Glasgow: Fontana/Collins, 1977.
de Vega, M., Glenberg, A. M., & Graesser, A. C. (Eds.). (2008).
Symbols and embodiment: Debates on meaning and cognition. Oxford, UK: Oxford University Press.
Dijkstra, K., Yaxley, R. H., Madden, C. J., & Zwaan, R. A.
(2004). The role of age and perceptual symbols in language
comprehension. Psychology and Aging, 19, 352-356.
doi:10.1037/0882-7974.19.2.352
Gagne, C. L. (2002). Lexical and relational influences on the
processing of novel compounds. Brain and Language, 81,
723-735. doi:10.1006/brln.2001.2559
Estes, Z. (2003). Attributive and relational processes in nominal
combination. Journal of Memory and Language, 48, 304-
319. doi:10.1016/S0749-596X(02)00507-7
Estes, Z., Verges, M., & Barsalou, L. W. (2008). Head up, foot
down: Object words orient attention to the objects' typical
location. Psychological Science, 19, 93-97. doi:10.1111/
j.1467-9280.2008.02051.x
Ferreira, F., Bailey, K. G. D., & Ferraro, V. (2002). Good-enough
representations in language comprehension. Current Directions in Psychological Science, 11(1), 11-15. doi:10.1111/
1467-8721.00158
Fodor, J. A. (1975). The language of thought. Cambridge:
Harvard University Press.
Fodor, J. A. (2008). LOT 2: The language of thought revisited.
Oxford: Oxford University Press.
Fritz, C. O., Morris, P. E., & Richler, J. J. (2012). Effect size
estimates: Current use, calculations, and interpretation.

Journal of Experimental Psychology: General, 141(1), 2-
18. doi:10.1037/a0024338
Gibson, J. J. (1966). The senses considered as perceptual system.
Boston: Houghton Mifflin.
Glenberg, A. M. (1997). What memory is for. Behavioral &
Brain Sciences, 20, 1-55.
Glenberg, A. M. (2010). Embodiment as a unifying perspective
for psychology. Wiley Interdisciplinary Reviews: Cognitive
Science, 1, 586-596.
Glenberg, A. M., & Robertson, D. A. (1999). Indexical
understanding of instructions. Discourse Processes, 28(1),
1-26. doi:10.1080/01638539909545067
Glenberg, A. M., Becker, R., Klotzer, S., Kolanko, L., Muller, S.,
& Rinck, M. (2009). Episodic affordances contribute to
language comprehension. Language and Cognition, 1, 113-
135. doi:10.1515/LANGCOG.2009.006
Glenberg, A. M., Robertson, D. A., Jansen, J. L., & JohnsonGlenberg, M. C. (1999). Not propositions. Cognitive Systems
Research, 1(1), 19-33. doi:10.1016/S1389-0417(99)00004-2
Greenberg, J. (1966). Language universals, with special reference to feature hierarchies. The Hague: Mouton.
Hauk, O., & Tschentscher, N. (2013). The body of evidence:
What can neuroscience tell us about embodied semantics?
Frontiers in Psychology, 4. doi:10.3389/fpsyg.2013.00050
Havas, D. A., Glenberg, A. M., & Rinck, M. (2007). Emotion
simulation during language comprehension. Psychonomic
Bulletin & Review, 14, 436-441. doi:10.3758/BF03194085
Holt, L. E., & Beilock, S. L. (2006). Expertise and its
embodiment: Examining the impact of sensorimotor skill
expertise on the representation of action-related text. Psychonomic Bulletin & Review, 13, 694-701. doi:10.3758/
BF03193983
Hutchinson, S., & Louwerse, M. M. (2012). The upbeat of
language: Linguistic context and embodiment predict processing of valence words. In N. Miyake, D. Peebles, & R. P.
Cooper (Eds.), Proceedings of the 34th Annual Conference
of the Cognitive Science Society (pp. 1709-1714). Austin,
TX: Cognitive Science Society.
Hutchinson, S., & Louwerse, M. (2013a). Language statistics and
individual differences in processing primary metaphors. Cognitive Linguistics, 24, 667-687. doi:10.1515/cog-2013-0023
Hutchinson, S., & Louwerse, M. M. (2013b). Language statistics
explain the spatial-numerical association of response codes.
Psychonomic Bulletin & Review, 21, 470-478. doi:10.3758/
s13423-013-0492-2
Hutchinson, S., & Louwerse, M. M. (2013c). What's up can be
explained by language statistics. In M. Knauff, M. Pauen, N.
Sebanz, & I. Washsmuth (Eds.), Proceedings of the 35th
Annual Conference of the Cognitive Science Society (pp.
2596-2601). Austin, TX: Cognitive Science Society.
IJzerman, H., & Semin, G. R. (2010). Temperature perceptions as a
ground for social proximity. Journal of Experimental Social
Psychology, 46, 867-873. doi:10.1016/j.jesp.2010.07.015
Jostmann, N. B., Lakens, D., & Schubert, T. W. (2009). Weight
as an embodiment of importance. Psychological Science, 20,
1169-1174. doi:10.1111/j.1467-9280.2009.02426.x
Kahneman, D. (2003). Maps of bounded rationality: Psychology
for behavioral economics. American Economic Review, 93,
1449-1475. doi:10.1257/000282803322655392
Kaschak, M. P., Madden, C. J., Therriault, D. J., Yaxley, R. H.,
Aveyard, M., Blanchard, A. A., & Zwaan, R. A. (2005).
Perception of motion affects language processing. Cognition,
94, B79-B89. doi:10.1016/j.cognition.2004.06.005
Kaschak, M. P., Zwaan, R. A., Aveyard, M., & Yaxley, R. H.
(2006). Perception of auditory motion affects language

Language, Cognition and Neuroscience
processing. Cognitive Science, 30, 733-744. doi:10.1207/
s15516709cog0000_54
Kintsch, W. (1998). Comprehension: A paradigm for cognition.
New York, NY: Cambridge University Press.
Kaup, B., Ludtke, J., & Maienborn, C. (2010). "The drawer is
still closed": Simulating past and future actions when
processing sentences that describe a state. Brain and
Language, 112, 159-166. doi:10.1016/j.bandl.2009.08.009
Kaup, B., Yaxley, R. H., Madden, C. J., Zwaan, R. A., & Ludtke,
J. (2007). Experiential simulations of negated text information. The Quarterly Journal of Experimental Psychology, 60,
976-990. doi:10.1080/17470210600823512
Koch, S., Holland, R. W., Hengstler, M., & van Knippenberg, A.
(2009). Body locomotion as regulatory process: stepping
backward enhances cognitive control. Psychological Science,
20, 549-550. doi:10.1111/j.1467-9280.2009.02342.x
Knott, A. (2012). Sensorimotor cognition and natural language
syntax. Cambridge, MA: MIT Press.
Lakens, D. (2013). Calculating and reporting effect sizes to
facilitate cumulative science: A practical primer for t-tests
and ANOVAs. Frontiers in Psychology, 4, 863. doi:10.3389/
fpsyg.2013.00863
Landauer, T. K., & Dumais, S. T. (1997). A solution to Plato's
problem: The latent semantic analysis theory of acquisition,
induction, and representation of knowledge. Psychological
Review, 104, 211-240. doi:10.1037/0033-295X.104.2.211
Landauer, T. K., McNamara, D. S., Dennis, S., & Kintsch, W.
(2007). Handbook of latent semantic analysis. Mahwah, NJ:
Erlbaum.
Liu, Y., Wang, F., Kang, C., Gao, Y., & Lu, Y. (2014). Analyzing
relatedness by toponym co-occurrences on web pages.
Transactions in GIS (Geographic Information Systems), 18,
89-107.
Louwerse, M. M. (2007). Symbolic embodied representations: A
case for symbol interdependency. In T. Landauer, D. McNamara, S. Dennis, & W. Kintsch (Eds.), Handbook of latent
semantic analysis (pp. 107-120). Mahwah, NJ: Erlbaum.
Louwerse, M. M. (2008). Embodied relations are encoded in
language. Psychonomic Bulletin & Review, 15, 838-844.
doi:10.3758/PBR.15.4.838
Louwerse, M. M. (2011a). Symbol interdependency in symbolic
and embodied cognition. TopiCS in Cognitive Science, 3,
273-302. doi:10.1111/j.1756-8765.2010.01106.x
Louwerse, M. M. (2011b). Stormy seas and cloudy skies: conceptual
processing is (still) linguistic and perceptual. Frontiers in
Psychology, 1-4. doi:10.3389/fpsyg.2011.00105/full
Louwerse, M. M., & Benesh, N. (2012). Representing spatial
structure through maps and language: Lord of the Rings
encodes the spatial structure of Middle Earth. Cognitive
Science, 36, 1556-1569. doi:10.1111/cogs.12000
Louwerse, M. M., & Connell, L. (2011). A taste of words:
Linguistic context and perceptual simulation predict the
modality of words. Cognitive Science, 35, 381-398.
doi:10.1111/j.1551-6709.2010.01157.x
Louwerse, M. M. & Hutchinson, S. (2012). Neurological
evidence linguistic processes precede perceptual simulation
in conceptual processing. Frontiers in Psychology, 3, 385.
doi:10.3389/fpsyg.2012.00385
Louwerse, M. M., & Jeuniaux, P. (2010). The linguistic and
embodied nature of conceptual processing. Cognition, 114,
96-104. doi:10.1016/j.cognition.2009.09.002
Louwerse, M. M., & Jeuniaux, P. (2008). How fundamental is
embodiment to language comprehension? Constraints of
embodied cognition. In V. Sloutsky, B. Love, & K. McRae
(Eds.), Proceedings of the 30th annual conference of the

441

cognitive science society (pp. 1313-1318). Austin, TX:
Cognitive Science Society.
Louwerse, M. M., & Zwaan, R. A. (2009). Language encodes
geographical information. Cognitive Science, 33(1), 51-73.
doi:10.1111/j.1551-6709.2008.01003.x
Louwerse, M. M., Hutchinson, S., & Cai, Z. (2012). The Chinese
route argument: Predicting the longitude and latitude of cities
in China and the Middle East using statistical linguistic
frequencies. In N. Miyake, D. Peebles, & R. P. Cooper
(Eds.), Proceedings of the 34th Annual Conference of the
Cognitive Science Society Proceedings of the 34th annual
conference of the cognitive science society (pp. 695-700).
Austin, TX: Cognitive Science Society.
Markman, A. B., & Brendl, C. M. (2005). Constraining theories
of embodied cognition. Psychological Science, 16(1), 6-10.
doi:10.1111/j.0956-7976.2005.00772.x
Matlock, T. (2004). Fictive motion as cognitive simulation. Memory
& Cognition, 32, 1389-1400. doi:10.3758/BF03206329
Meier, B. P., & Robinson, M. D. (2004). Why the sunny side is
up: Associations between affect and vertical position. Psychological Science, 15, 243-247. doi:10.1111/j.09567976.2004.00659.x
Meier, B. P., Hauser, D. J., Robinson, M. D., Friesen, C. K., &
Schjeldahl, K. (2007). What's `up' with God? Vertical space
as a representation of the divine. Journal of Personality and
Social Psychology, 93, 699-710. doi:10.1037/0022-3514.93.
5.699
Meier, B. P., Robinson, M. D., & Clore, G. L. (2004). Why good
guys wear white: Automatic inferences about stimulus
valence based on brightness. Psychological Science, 15,
82-87. doi:10.1111/j.0963-7214.2004.01502002.x
Meteyard, L., Bahrami, B., & Vigliocco, G. (2007). Motion
detection and motion verbs: Language affects low-level
visual perception. Psychological Science, 18, 1007-1013.
doi:10.1111/j.1467-9280.2007.02016.x
Meteyard, L., Zokaei, N., Bahrami, B., & Vigliocco, G. (2008).
Visual motion interferes with lexical decision on motion
words. Current Biology, 18, R732-R733. doi:10.1016/j.
cub.2008.07.016
Miller, G. A. (2003). The cognitive revolution: A historical
perspective. TRENDS in Cognitive Sciences, 7, 141-144.
doi:10.1016/S1364-6613(03)00029-9
Monaghan, P., Christiansen, M. H., & Fitneva, S. A. (2011).
The arbitrariness of the sign: Learning advantages from
the structure of the vocabulary. Journal of Experimental Psychology: General, 140, 325-347. doi:10.1037/a0022924
Monaghan, P., Shillcock, R. C., Christiansen, M. H., & Kirby, S.
(2014). How arbitrary is language? Philosophical. Transactions of the Royal Society B, 369, 20130299. doi:10.1098/
rstb.2013.0299
Myung, J.-Y., Blumstein, S. E., & Sedivy, J. C. (2006). Playing on
the typewriter, typing on the piano: Manipulation knowledge
of objects. Cognition, 98, 223-243. doi:10.1016/j.cognition.
2004.11.010
Nuthmann, A., & van der Meer, E. (2005). Time's arrow
and pupillary response. Psychophysiology, 42, 306-317.
doi:10.1111/j.1469-8986.2005.00291.x
Paivio A. (1986). Mental representations: A dual coding
approach. Oxford, UK: Oxford University Press.
Paivio, A. (1971). Imagery and verbal processes. New York,
NY: Holt, Rinehart, and Winston.
Pecher, D., van Dantzig, S., Boot, I., Zanolie, K., & Huber, D. E.
(2010). Congruency between word position and meaning is
caused by task-induced spatial attention. Frontiers in Psychology, 1, 1-8. doi:10.3389/fpsyg.2010.00030

442

M.M. Louwerse et al.

Pecher, D., van Dantzig, S., Zwaan, R. A., & Zeelenberg, R. (2009).
Language comprehenders retain implied shape and orientation
of objects. The Quarterly Journal of Experimental Psychology,
62, 1108-1114. doi:10.1080/17470210802633255
Pecher, D., & Zwaan, R. A. (Eds.). (2005). Grounding cognition:
The role of perception and action in memory, language, and
thinking. New York, NY: Cambridge University Press.
Pedhazur, E. (1997). Multiple regression in behavioral research.
New York, NY: Holt, Rinehart and Winston.
Rapp, D. N., & Horton, W. S. (2003). Out of sight, out of mind:
Occlusion and the accessibility of information in narrative
comprehension. Psychonomic Bulletin & Review, 10, 104-110.
Recchia, G., & Louwerse, M. M. (2014). Grounding the
ungrounded: Estimating locations of unknown place names
from linguistic associations and grounded representations. In
P. Bello, M. Guarini, M. McShane, & B. Scassellati (Eds.),
Proceedings of the 36th annual conference of the cognitive
science society (pp. 1270-1275). Austin, TX: The Cognitive
Science Society.
Recchia, G. (2014, September 8). Computationally estimating
geographical information from user-contributed data Presented at NARP (NGA Academic Research Program Symposium and Workshops) 2014, Washington, DC.
Richardson,D., & Matlock, T. (2007). The integration of
figurative language and static depictions: An eye movement
study of fictive motion. Cognition, 102(1), 129-138.
doi:10.1016/j.cognition.2005.12.004
Richardson, D. C., Spivey, M. J., Barsalou, L. W., & McRae, K.
(2003). Spatial representations activated during real-time
comprehension of verbs. Cognitive Science, 27, 767-780.
doi:10.1207/s15516709cog2705_4
Richter, T., & Zwaan, R. A. (2009). Processing of color words
activates color representations. Cognition, 111, 383-389.
doi:10.1016/j.cognition.2009.02.011
Roberts, J. K., & Monaco, J. P. (2006). Effect size measures for
the two-level linear multilevel model. Paper presented at the
Annual Meeting of the American Educational Research
Association, San Francisco, CA.
Sadoski, M., & Paivio, A. (2012). Imagery and text: A dual
coding theory of reading and writing. New York, NY:
Routledge.
Santana, E., & de Vega, M. (2011). Metaphors are embodied,
and so are their literal counterparts. Frontiers in Psychology,
2. doi:10.3389/fpsyg.2011.00090
Santiago, J., Lupanez, J., Perez, E., & Funes, M. J. (2007). Time
(also) flies from left to right. Psychonomic Bulletin &
Review, 14, 512-516. doi:10.3758/BF03194099
Santos, A., Chaigneau, S. E., Simmons, W. K., & Barsalou, L.
W. (2011). Property generation reflects word association and
situated simulation. Language & Cognition, 3(1), 83-119.
doi:10.1515/langcog.2011.004
Schubert, T. W. (2005). Your highness: Vertical positions as
perceptual symbols of power. Journal of Personality and
Social Psychology, 89, 1-21. doi:10.1037/0022-3514.89.1.1
Sell, A. J., & Kaschak, M. P. (2010). Processing time shifts
affects the execution of motor responses. Brain and Language, 117, 39-44. doi:10.1016/j.bandl.2010.07.003
Semin, G. R., & Smith, E. R. (Eds.). (2008). Embodied
grounding: Social, cognitive, affective, and neuroscientific
approaches. Cambridge, MA: Cambridge University Press.
Setic, M., & Domijan, D. (2007). The influence of vertical
spatial orientation on property verification. Language and
Cognitive Processes, 22, 297-312. doi:10.1080/01690960
600732430
Shapiro, L. (2011). Embodied cognition. New York, NY:
Routledge.

Simmons, W. K., Hamann, S. B., Harenski, C. N., Hu, X. P., &
Barsalou, L. W. (2008). fMRI evidence for word association
and situated simulation in conceptual processing. Journal of
Physiology - Paris, 102, 106-119.
Skinner, B. F. (1957). Verbal behavior (pp. 53-54). New York,
NY: Appleton-Century-Crofts.
Solomon, K. O., & Barsalou, L. W. (2004). Perceptual simulation in property verification. Memory & Cognition, 32, 244-
259. doi:10.3758/BF03196856
Stanfield, R. A., & Zwaan, R. A. (2001). The effect of implied
orientation derived from verbal context on picture recognition. Psychological Science, 12, 153-156. doi:10.1111/14679280.00326
Stanovich, K. E. & West, R. F. (2000). Individual differences in
reasoning: Implications for the rationality debate? Behavioral
and Brain Sciences, 23, 645-665.
Tagalakis, G., & Keane, M. T. (2006). Familiarity and relational
preference in the understanding of noun-noun compounds.
Memory & Cognition, 34, 1285-1297. doi:10.3758/
BF03193272
Taylor, L., Lev-Ari, S., & Zwaan,R. (2008). Inferences about
action engage action systems. Brain and Language, 107(1),
62-67. doi:10.1016/j.bandl.2007.08.004
Tillman, R. N., Hutchinson, S., & Louwerse, M. M. (2013).
Geographical estimates are explained by perceptual simulation and language statistics. In M. Knauff, M. Pauen, N.
Sebanz, & I. Wachsmuth (Eds.), Proceedings of the 35th
annual conference of the cognitive science society (pp.
3557-3562). Austin, TX: The Cognitive Science Society.
Tulving, E. (1983). Elements of episodic memory. New York,
NY: Oxford University Press.
van Dantzig, S., Pecher, D., Zeelenberg, R., & Barsalou, L. W.
(2008). Perceptual processing affects conceptual processing.
Cognitive Science, 32, 579-590. doi:10.1080/036402108020
35365
van Dantzig, S., Zeelenberg, R., & Pecher, D. (2009). Unconstraining theories of embodied cognition. Journal of Experimental Social Psychology, 45, 345-351. doi:10.1016/j.
jesp.2008.11.001
Vermeulen, N., Mermillod, M., Godefroid, J., & Corneille, O.
(2009). Unintended embodiment of concepts into percepts:
Sensory activation boosts attention for same-modality concepts in the attentional blink paradigm. Cognition, 112, 467-
472. doi:10.1016/j.cognition.2009.06.003
Wilson, A. D. & Golonka, S. (2013). Embodied cognition is not
what you think it is. Frontiers in Psychology 4, 58.
doi:10.3389/fpsyg.2013.00058
Yang, F., Mo, L., Louwerse, M. M. (2012). Effects of local and
global context on processing sentences with subject and
object relative clauses. Journal of Psycholinguistic Research,
42, 227-237.
Wu, L.-l., & Barsalou, L.W. (2009). Perceptual simulation in
conceptual combination: Evidence from property generation.
Acta Psychologica, 132, 173-189. doi:10.1016/j.actpsy.2009.
02.002
Yaxley, R. H. & Zwaan, R. A. (2006). Simulating visibility
during language comprehension. Cognition, 105, 229-236.
Zwaan, R. A. (2004). The immersed experiencer: Toward an
embodied theory of language comprehension. In B. H. Ross
(Ed.), The psychology of learning and motivation (Vol.44,
pp. 35-62). New York, NY: Academic Press.
Zwaan, R. A., & Yaxley, R. H. (2003). Spatial iconicity affects
semantic relatedness judgments. Psychonomic Bulletin &
Review, 10, 954-958. doi:10.3758/BF03196557
Zwaan, R. A., Madden, C. J., Yaxley, R. H., & Aveyard, M. E.
(2004). Moving words: Dynamic representations in language

Language, Cognition and Neuroscience
comprehension. Cognitive Science, 28, 611-619. doi:10.1016/
j.cogsci.2004.03.004
Zwaan, R. A., Stanfield, R. A., & Yaxley, R. H. (2002).
Language comprehenders mentally represent the shapes of
objects. Psychological Science, 13, 168-171. doi:10.1111/
1467-9280.00430

443

Zwaan, R. A., & Taylor, L. J. (2006). Seeing, acting, understanding: Motor resonance in language comprehension.
Journal of Experimental Psychology: General, 135(1), 1-
11. doi:10.1037/0096-3445.135.1.1

444

M.M. Louwerse et al.

Appendix 1. Effect sizes for 126 embodied cognition experiments

Publication
Beilock and Goldin-Meadow (2010)
Beilock and Holt (2007)
Bergen et al. (2007)

Borghi, Glenberg, and Kaschak (2004)

Borreggine and Kaschak (2006)
Buccino et al. (2005)
Connell, and Lynott (2009)
Connell, Lynott, and Dreyer (2012)
Dijkstra et al. (2004)
Estes et al. (2008)

Glenberg et al. (2009)

Glenberg, Robertson, Jansen, and Johnson-Glenberg (1999)

Havas et al. (2007)

Holt and Beilock (2006)
IJzerman and Semin (2010)

Jostmann, Lakens, and Schubert (2009)

Kaschak et al. (2005)
Kaschak, Zwaan, Aveyard, and Yaxley (2006)

Kaup, Ludtke, and Maienborn (2010)
Kaup, Yaxley, Madden, Zwaan, and Ludtke (2007)

Experiment
a

1
1
2
1abd
2abd
3abd
4abd
5abd
1ab
2abc
3ab
1ab
4ab
1
2ab
1abc
1ac
2ac
1ab
1abcd
2abcd
3abcd
1ab
2ab
3ab
4ab
1
2ab
3ab
1ab
2ab
3aabc
1ab
2ab
1
2
3
4
1
2
3
4
1ab
2ab
1ab
2ab
3ab
1ab
2ab
1ab

2

Hedge's g

0.174
0.094
0.109
0.074
0.09
0.007
0.002
0.013
0.281
0.638
0.813
0.152
0.034
0.455
0.348
0.056
0.005
0.006
0.481
0.703
0.078
0.465
0.133
0.304
0.06
0.112
0.409
0.056
0.378
0.044
0.169
0.019
0.065
0.059
0.081
0.076
0.062
0.151
0.111
0.081
0.093
0.176
0.097
0.109
0.135
0.098
0.048
0.565
0.238
0.193

0.856
0.648
0.671
0.55
0.597
0.163
0.09
0.217
1.164
2.289
2.496
0.797
0.351
1.487
1.327
0.461
0.918
1.005
1.691
2.846
0.562
1.689
0.757
1.216
0.467
0.687
1.646
0.46
1.487
0.425
0.555
0.271
0.52
0.506
0.574
0.56
0.503
0.803
0.683
0.577
0.616
0.882
0.611
0.644
0.729
0.638
0.389
1.999
0.965
0.91

Language, Cognition and Neuroscience

445

(Continued)
Publication
Koch, Holland, Hengstler, and van Knippenberg (2009)
Louwerse and Jeuniaux (2010)

Markman and Brendl (2005)
Matlock (2004)
Meier and Robinson (2004)

Meier et al. (2007)
Meier et al. (2004)

Meier et al. (2004)

Meteyard, Bahrami, and Vigliocco (2007)
Meteyard et al. (2008)
Myung et al. (2006)
Nuthmann and Van Der Meer (2005)
Pecher et al. (2010)
Pecher, van Dantzig, Zwaan, and Zeelenberg (2009)
Rapp and Horton (2003)
Richardson and Matlock (2007)
Richardson, Spivey, Barsalou, and McRae (2003)
Richter and Zwaan (2009)
Santana and de Vega (2011)

Schubert (2005)

Experiment

2

Hedge's g

2ab
1ac
1abc
1aabc
1bbc
1babc
2ab
2aab
2bbc
2babc
1ab
2ab
1ab
1ab
2ab
3ab
4abc
1abcd
2ab
1abc
2abcd
3bd
4d
5abd
1aabc
1babc
2abc
2bbc
3abc
3bbc
4aabc
5aabc
1abc
1ab
2-4ab
1ab
1c
abcd
1
1b
1ab
2ab
1a
abd
1
2abd
1abc
2abc
1ab
2ab
3ab
abcd
2
3abcd
4abcd
5abcd
6bd

0.101
0.171
0.001
0.000
0.353
0.124
0.027
1.010
0.031
0.031
0.17
0.286
0.409
0.134
0.26
0.118
0.108
0.156
0.23
0.854
0.422
0.128
0.257
0.441
0.357
0.212
0.362
0.327
0.181
0.228
0.029
0.015
0.292
0.03
0.079
0.129
0.317
0.021
0.074
0.241
0.198
0.174
0.07
0.063
0.525
0.214
0.284
0.446
0.136
0.16
0.263
0.112
0.197
0.048

0.58
0.879
1.323
0.062
2.734
1.290
1.575
1.196
2.218
2.145
0.845
0.845
1.632
0.869
1.246
0.753
0.674
0.828
1.042
4.506
1.664
0.737
1.12
1.742
1.252
0.897
1.32
1.123
0.837
0.921
0.299
0.219
1.2
0.622
0.924
0.741
1.305
0.286
0.553
1.078
0.947
0.897
0.538
0.513
2.01
1.011
1.171
1.73
0.762
0.8
1.151
0.68
0.953
0.442

446

M.M. Louwerse et al.

(Continued)
Publication

2

Hedge's g

0.074
0.031
0.27
0.307
0.15
0.051
0.068
0.069
0.071
0.145
0.868
0.135
0.145
0.089
0.081
0.25
0.076
0.221
0.071
0.188
0.048
0.046

0.396
0.35
1.156
1.294
0.782
0.457
.514
.517
.526
.766
4.791
0.763
0.783
0.575
0.572
1.079
0.531
1
0.536
0.93
0.427
0.418

Experiment
1ab
2ab

Sell and Kaschak (2010)
Setic and Domijan (2007)

1abcd
2abcd
1ab
1a
1a
1ac
2ac
3ac
1abc
1ab
1abcd
3abc
1ab
1ab
2a
1a
2a
3ab
4ab
5ab

Stanfield and Zwaan (2001)
Taylor, Lev-Ari, and Zwaan (2008)
van Dantzig et al. (2008)
van Dantzig, Zeelenberg, and Pecher (2009)

Vermeulen, Mermillod, Godefroid, and Corneille (2009)
Yaxley and Zwaan (2006)

Zwaan, Madden, Yaxley, and Aveyard (2004)
Zwaan et al. (2002)
Zwaan and Taylor (2006)

a

Response time; bButton press; cWord; dVertical configuration.

Appendix 2. Effect sizes for 58 language statistics experiments

Publication
Connell and Lynott (2013)
Estes (2003)
Gagne (2002)
Hutchinson and Louwerse (2012)

Hutchinson and Louwerse (2013a)

Hutchinson and Louwerse (2013b)

Experiment

2

Hedge's g

1
2
1
2
1
2
1
1
2
2
1a
1b
2a
2b
3a
3b
4a
4b
1
1
1
1

0.014
0.013
0.153
0.274
0.238
0.308
0.454
0.406
0.524
0.402
0.41
0.489
0.417
0.265
0.485
0.478
0.369
0.439
~0
0.001
~0
0.004

1.096
1.033
0.781
1.162
1.431
1.814
2.821
2.286
3.257
2.408
2.568
2.814
1.752
1.28
1.714
1.936
1.867
2.167
0.026
0.53
0.111
0.97

Language, Cognition and Neuroscience

447

(Continued)
Publication

Hutchinson and Louwerse (2013c)

Louwerse and Hutchinson (2012)
Louwerse and Jeuniaux (2010)

Louwerse (2011b)
Santiago, Lupanez, Perez, and Funes (2007)

Solomon and Barsalou (2004)
Tagalakis and Keane (2006)
Tillman et al. (2013)

Wu and Barsalou (2009)
1

= error rate;

2

= response times.

Experiment

2

Hedge's g

1
1
2
2
2
2
2
3
1
1
1
1
1
1
1
1a1
1a2
1b1
1b2
2a1
2a2
2b1
2b2
1
1
1
2
1
1
2
1
1
1
1
1
2

0.001
0.002
~0
0.009
0.003
0.02
0.004
0.002
0.001
0.001
0
0.005
0.004
0.002
0.005
0.146
0.152
0.099
0.112
0.190
0.009
0.086
0.207
0.203
0.272
0.048
0.58
0.273
0.325
0.019
0
0.006
0.001
0.004
0.425
0.468

0.47
0.492
0.456
1.268
1.131
1.924
0.796
0.506
NA
NA
NA
NA
NA
NA
1.007
1.559
1.543
1.124
1.225
0.324
1.196
0.938
2.145
NA
1.172
0.828
2.936
2.466
1.273
0.245
0.196
0.728
0.318
0.573
1.071
1.257

