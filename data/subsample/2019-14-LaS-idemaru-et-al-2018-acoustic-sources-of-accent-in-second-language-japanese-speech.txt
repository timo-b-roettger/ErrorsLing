773118

research-article2018

LAS0010.1177/0023830918773118Language and SpeechIdemaru et al.

Article

Acoustic Sources of Accent
in Second Language Japanese
Speech

Language
and Speech
Language and Speech
2019, Vol. 62(2) 333-357
(c) The Author(s) 2018
Article reuse guidelines:
sagepub.com/journals-permissions
https://doi.org/10.1177/0023830918773118
DOI: 10.1177/0023830918773118
journals.sagepub.com/home/las

Kaori Idemaru

University of Oregon, USA

Peipei Wei

University of Oregon, USA

Lucy Gubbins

University of Oregon, USA

Abstract
This study reports an exploratory analysis of the acoustic characteristics of second language
(L2) speech which give rise to the perception of a foreign accent. Japanese speech samples
were collected from American English and Mandarin Chinese speakers (n = 16 in each group)
studying Japanese. The L2 participants and native speakers (n = 10) provided speech samples
modeling after six short sentences. Segmental (vowels and stops) and prosodic features
(rhythm, tone, and fluency) were examined. Native Japanese listeners (n = 10) rated the
samples with regard to degrees of foreign accent. The analyses predicting accent ratings
based on the acoustic measurements indicated that one of the prosodic features in particular,
tone (defined as high and low patterns of pitch accent and intonation in this study), plays an
important role in robustly predicting accent rating in L2 Japanese across the two first language
(L1) backgrounds. These results were consistent with the prediction based on phonological
and phonetic comparisons between Japanese and English, as well as Japanese and Mandarin
Chinese. The results also revealed L1-specific predictors of perceived accent in Japanese. The
findings of this study contribute to the growing literature that examines sources of perceived
foreign accent.
Keywords
Foreign accent, vowels, consonants, prosody, Japanese

Corresponding author:
Kaori Idemaru, Department of East Asian Languages and Literatures, University of Oregon, 308 Friendly Hall, 1248
University of Oregon, Eugene, OR 97403-1248, USA.
Email: idemaru@uoregon.edu

334

1

Language and Speech 62(2)

Introduction

1.1 Studies of second language (L2) speech
It has been well documented that unless we begin to learn a foreign language by the age of 6 or 7,
most of us will retain a discernible accent, however fluent we might otherwise become (Oyama,
1976; Patkowski, 1994; Scovel, 1969). Understanding the nature of foreign accents is important
because the perception of an accent can lead listeners to think that the speaker is not understandable, even when the message is accurately conveyed (Munro & Derwing, 1995), and also because
accented speakers may be judged as less credible than non-accented speakers, even when they are
conveying the same message (Lev-Ari & Keysar, 2010).
Forty years of research in the field of L2 speech learning have led us to a better understanding
of foreign-accented speech (Flege, 1999; Munro & Derwing, 2011, 2015; Piske, MacKay, & Flege,
2001). A broad range of speaker characteristics has been examined, and many studies converge in
demonstrating that the onset age of learning and length of residency in the community where the
language is spoken exert a crucial influence on the development of a foreign accent, whereas studies are inconclusive about the influence of other factors, such as gender, formal instruction, and
motivation (for a review, see Munro & Derwing, 2011; Piske, et al., 2001).
In addition to understanding the influence of speaker characteristics on L2 speech learning, it is
also important to understand what acoustic components of non-native speech influence the perception of a foreign accent. Whereas the investigation of speaker characteristics (e.g., onset age of
learning) may deepen our understanding of the possible cause of a foreign accent, an acoustic
investigation helps us better understand what it is that we call a "foreign accent" in the first place.
A number of studies investigating intelligibility, comprehensibility and accentedness of L2
speech (Derwing & Munro, 1997; Munro & Derwing, 1999) have revealed interesting patterns. For
example, Derwing and Munro (1997) found that native English listeners, while accurately identifying the content of L2 utterances (thus the L2 utterances were "intelligible" to the listeners), judged
the same utterances to be "incomprehensible" and/or "foreign accented." While comparison of
these aspects of L2 speech reveals important issues of perception and judgment, the current study
focuses on perceived foreign accent and its acoustic sources. We were motivated to focus our
research on the question of foreign accent because native listeners' harshest ratings of L2 speech
seem related to accentedness (Derwing & Munro, 1997), and perceptions of accentedness in turn
seem to be related to judgements of reduced intelligibility and truthfulness of the information conveyed (Lev-Ari & Keysar, 2010). Investigating the acoustic sources of foreign accents will have
important implications for L2 speech learning and teaching. In this paper, the term "foreign accent"
is used when referring to the general idea and phenomenon of foreign accents, whereas "accentedness" is used, following the prior literature, when referring to degree of a foreign accent and the
state of having a foreign accent.1

1.2 Studies of foreign (L2) accent
The findings of previous studies regarding the acoustic sources of perceived foreign (L2) accents
vary considerably, likely reflecting the various research methods employed and the various native
and target L2 languages investigated. Some found that a vowel feature, but not a consonant feature,
among segmentals affected perceived accent (Wayland, 1997, examining L2 Thai by L1 English
speakers). Others reported that not only segmentals but prosodic features too affected perceived
foreign accent (Munro, 1995, examining L2 English by L1 Mandarin speakers; Trofimovich &
Baker, 2006, examining L2 English by L1 Korean speakers). Yet others have suggested that perhaps

Idemaru et al.

335

prosodic features affect perceived accent more strongly than segmentals do (Wayland, 1997;
Anderson-Hsieh, Johnson, & Koehler, 1992, examining L2 English by speakers of various L1s;
Kang, 2010, also examining L2 English by speakers of various L1s; Trofimovich & Isaacs, 2012,
examining L2 English by L1 French speakers). And some researchers have reported that segmentals
influence perceived foreign accent more strongly than prosodic features do (Jilka, 2000, examining
L2 German by L1 English speakers; Sereno, Lammers, & Jongman, 2016, examining L2 English by
L1 Korean speakers; Winters & O'Brien, 2013, examining L2 English by L1 German speakers).
Some of these divergent findings may be due to the different methodologies employed in the studies. It is also possible that acoustic sources of learners' accents may change in the course of learning
a language. In other words, acoustic features that cause a perceived foreign accent may differ between
beginning learners and fluent learners (e.g., Isaacs & Trofimovich, 2012; Saito, Trofimovich, &
Isaacs, 2017). However, it is also possible that the acoustic sources of a perceived foreign accent have
a differential influence depending on the target L2 and learners' L1s, as L2 speech learning is influenced, at least initially, by the acoustic and perceptual relationship between learners' L1 and their
target L2 sound systems (Best, 1995; Flege, 1995). Accordingly, at least some of the acoustic features
that may give rise to a perceived foreign accent may be predicted by comparative analyses of learners' L1 and the target L2. Not many studies of foreign accent are based on careful phonological analyses of L1 and L2. To address this gap, this study attempts to provide a comparative analysis of the
participants' L1s and their target language (see the next section). Furthermore, the majority of studies
of foreign accent have examined English as the target L2 (see reviews in Munro & Derwing, 2011;
Piske et al., 2001). Examination of languages other than English may provide new insights into our
understanding of L2 foreign accents, or may converge with studies on English, suggesting that foreign accentedness is essentially a cross-linguistic phenomenon. To this end, the current study focuses
on Japanese as the target L2, a language that is less frequently the focus of studies on this topic, with
two groups of learners, L1 Mandarin learners and L1 English learners.

1.3 Japanese as the target L2
The Japanese vowel inventory includes five distinctive vowel qualities /i, e, a, o, / (Maddieson &
Disner, 1984; Nishi, Strange, Akahane-Yamada, Kubo, & Trent-Brown 2008; Vance, 2008), with all
five contrasting in quantity (e.g., short /i/ vs. long /ii/). English and Mandarin have more complex
vowel systems. English is considered to have 11 nonrhotic monophthongal vowels /i, , e, , ae, u, ,
o, , , / (Gay, 1970; Hillenbrand, Getty, Clark, & Wheeler, 1995). Commonly accepted analyses of
the Mandarin vowel inventory include five /i, y, , a, u/ (Lin, 2007; Mok, 2012; Wiese 1997) or six /i,
y, , a, , u/ monophthong phonemes (Chen, Robb, Gilbert, & Lerman, 2001; Howie, 1976; Jia,
Strange, Wu, Collado, & Guan, 2006; Lin, 1989; Sun, 2006) and numerous allophonic variations for
the mid-vowel //, including [e, , (), , o].
Here we have a situation in which learners with large and complex L1 systems are learning an
L2 that has a simpler vowel system, which may facilitate L2 vowel learning (Iverson & Evans,
2009). L2 learners are thought to use their L1 sound categories to process or produce L2 phonemes,
at least at the outset (Best, 1995; Best, McRoberts, & Goodell, 2001; Flege, 1995). As applied to
this study, many of the L1 American English (/i, e, , o, u/) and Mandarin vowels (/i, a, u/ and [e,
o] as allophones of //) may serve as initial vowel categories for the Japanese vowels. However,
one notable feature often discussed in the literature is the tendency for the Japanese // to be produced in the central position as opposed to the back vowel /u/ (e.g., Vance, 2008).
The Japanese consonant inventory is also uncontroversial. It has the same number of sounds in
stops as English and Mandarin, and has fewer numbers in fricatives, affricates, and sonorants than
English and Mandarin. Like vowels, voiceless obstruents contrast in phonological length with

336

Language and Speech 62(2)

singleton (e.g., [p]) and geminate (e.g., [pp]) obstruents. Seen in this way, Japanese consonants,
like vowels, seem to present a fairly straightforward learning task for L1 English and L1 Mandarin
learners. However, it has often been noted that Japanese stop voicing categories are slightly at variance with the typical short-lag versus long-lag voice onset time (VOT) distinction (Kong, Beckman,
& Edwards, 2012; Riney, Takagi, Ota, & Uchida, 2007; Vance, 2008). While Japanese voiced stops
/b, d, g/ have short-lag VOTs like many other languages, its voiceless counterparts have relatively
shorter VOTs (e.g., 29-57 milliseconds (ms), Riney et al., 2007), substantially shorter than longlag VOTs in English (42-70 ms, Klatt, 1975) or Mandarin (70-100 ms, Chao & Chen, 2008; Chen,
Chao, & Peng, 2007; Liu, Ng, Wan, Wang, & Zhang, 2007). Here, L1 influence may result in VOT
that is too long for Japanese voiceless stops, a point often noted in the Japanese pronunciation
instruction literature (Tanaka & Kubozono, 1999; Toda, 2004).
In contrast, Japanese, English, and Chinese differ more markedly in terms of prosodic systems.
Japanese is characterized as a mora-timed language (Homma, 1981; Port, Al-Ani, & Maeda, 1980).
In contrast, English is a canonical stress-timed language, and Mandarin is characterized as syllable-timed (e.g., Grabe & Low, 2002). In addition, L1-L2 differences in syllable structure have
been shown to affect L2 speech learning (Cheng & Zhang, 2015). The difference in unit structure,
mora for Japanese and syllable for English and Mandarin, relates to differential durational implementation. For example, while /e.e.ga/ ("movie") has two syllables, it has three moras, and while
/to.sho.ka.N/ ("library") has three syllables, it has four moras. Applying stress-timing (e.g., English)
or syllable-timing (e.g., Mandarin) to Japanese may result in non-native-like shortening of some
mora durations (i.e., a mora in a heavy syllable).
In standard Japanese, the tonal pattern is realized with each mora carrying a high tone (H) or a low
tone (L), and pitch accent is realized as a sharp fall from a high tone to an immediately following low
tone (Vance, 2008).2 Pitch accent, realized solely by pitch, thus differs from the metrical structure of
the stress accent (e.g., English) (Hyman, 2009), which typically correlates with duration, intensity,
and pitch (Beckman & Pierrehumbert, 1986). Pitch accent is similar to the tonal system (e.g.,
Mandarin) in that pitch variation alone gives the tonal structure (Hyman, 2009). For L1-Mandarin
learners, the tonal system in their L1 perhaps facilitates the learning of the Japanese pitch-accent
system. If L1-English learners, on the other hand, rely on their L1 stress-accent in L2 Japanese production, this would result in a non-native-like use of duration and intensity in marking pitch accent.
In summary, comparison of Japanese, American English and Mandarin segmentals suggests that
L1-English and L1-Mandarin learners may have an advantage in learning Japanese segmentals, as
the Japanese segmental inventory is less complex than those of the learners' L1s. Although there
are some sub-phonemic differences (i.e., the vowel // and VOT in stops), the learners' L1 segments map fairly straightforwardly onto L2 target segments, and could, at least initially, facilitate
the perception and production of L2 Japanese sounds. English and Mandarin contrast in a more
marked way with Japanese in the domain of prosody; both English and Mandarin are different from
Japanese in terms of timing mechanism, and English, in addition, departs further in terms of accentuation patterns. On the basis of these comparisons, we predicted that: (1) the foreign accent in L2
Japanese production would be heavily influenced by prosodic features for L1-English and
L1-Mandarin learners; and that (2) the foreign accent in L1-English speakers would be more
strongly associated with Japanese tonal pattern than that of L1-Mandarin speakers.

1.4 Methodological considerations
Methodological choices adopted by studies of foreign accent have varied considerably over time,
and the matter warrants some discussion here. One method of investigating the acoustic source of
a foreign accent is to measure acoustic features of L2 speech and relate the acoustic measurements

Idemaru et al.

337

to the accent rating of the L2 speech provided by native listeners. This method is particularly well
suited for uncovering acoustic sources of a perceived foreign accent in an exploratory approach
(Anderson-Hsieh et al., 1992; Trofimovich & Baker, 2006; Wayland, 1997).
In this method, more detailed analysis of speech materials leads to stronger explanatory power. For
example, conducting fine-grained acoustic analysis of consonants and vowels (e.g., vowel formants
and VOT in Wayland, 1997) provides more detailed and informative results than an analysis that collapses the two domains (e.g., Anderson-Hsieh et al., 1992). As for prosody, while rating of speech
materials with regards to the accuracy/inaccuracy of prosodic features has been widely used as an
appropriate way to characterize prosody (e.g., Bosker, Pinget, Quene, Sanders, & De Jong, 2013),
another approach may be to employ measurement-based characterization of prosodic features, which
are now also available. We have seen the introduction of global linguistic rhythm measures (Dellwo,
2006; Ling, Grabe, & Nolan, 2000; Ramus, Nespor, & Mehler, 1999; White & Mattys, 2007) and a
systematic framework for coding tonal patterns (e.g., Tones and Break Indices (ToBI) by Beckman &
Hirshberg, 1994; Japanese ToBI (J_ToBI) by Venditti, 2005). The measures of global linguistic rhythm
and tonal patterns have not yet been used extensively in the research on foreign accent.
As a method of eliminating segmental errors and allowing perception of prosodic errors without
segmental influence, a number of studies have employed a technique of filtering speech samples.
Low-pass filtering eliminates or degrades segmental information from speech samples while
retaining prosodic information such as pitch and intonation, duration, and rhythmic properties
(Munro, 1995; Trofimovich & Baker, 2006; van Els & De Bot, 1987). Such studies have shown
that in the absence of segmental information, prosodic characteristics provided enough information
for native listeners to distinguish native speakers' speech from L2 speakers' speech (Munro, 1995),
and that some prosodic features, that is, pause duration and speech rate, exert a stronger influence
on perceived foreign accent than others, namely pause frequency, stress timing and pitch peak error
(Trofimovich & Baker, 2006). The current research has taken advantage of these methodological
advances.

1.5 Aim and overview of this study
This study aims to explore potential acoustic sources of accent in L2 Japanese produced by learners of
two L1s, English and Mandarin. Based on the cross-linguistic comparisons, we predict that prosodic
features strongly affect the perception of foreign accent in these learners' Japanese, and that the pitch
accent may show a relatively stronger effect on English speakers than it does on Mandarin speakers.
The segmental features measured were vowel formants and stop features (please see below for
more details). Stops were selected from the consonant inventory for several reasons. First, there is
a notable and well-documented acoustic difference between Japanese and the two L1 languages,
and it is known to affect L2 Japanese productions as discussed earlier. Second, while the measurement method and typical characteristics are well documented for Japanese stops, the same is not
true for other consonants. Establishing and validating such acoustic analysis methods for the
Japanese fricatives, affricates and sonorants would be beyond the focus of this study. For these
reasons, we have chosen to investigate stops as one of the more likely sources of foreign accent.
We recognize that this is not a comprehensive investigation of Japanese consonants. This limitation
of the study is revisited in the discussion section. The prosodic features examined were global
rhythm, tonal patterns, and fluency.
The acoustic features were then related to foreign accent ratings of the speech samples provided
by linguistically naive native Japanese listeners, in order to examine the relationship between the
acoustic features and the accent ratings. We obtained accent ratings of the speech samples in two
ways: by using a filtered version of the speech; and also by using a non-filtered version.

338

Language and Speech 62(2)

Table 1. Characteristics of second language participants. The numbers not in parentheses indicate the
mean, and the numbers in parentheses indicate the range.

Age (years)
Age of acquisition (years)
Japanese instruction (years)
Length of stay in Japan (days)

2

L1-English learners
(n = 16)

L1-Mandarin learners
(n = 16)

21.3 (19-26)
16.8 (14-21)
4.6 (2-8)
152.4 (0-1277)

22.3 (18-32)
19.6 (15-28)
2.1 (0.5-4)
35.7 (0-180)

Methods

2.1 Participants
Sixteen L1-English learners (10 female and 6 male) and 16 L1-Mandarin learners (10 female and
6 male), as well as 10 native-Japanese speakers (3 female and 7 male) provided speech samples.
All L1-English learners were native speakers of American English.3 Among the 16 L1-Mandarin
learners, 12 were from mainland China, and four were from Taiwan. All four Taiwanese participants reported exposure to Mandarin from birth and identified Mandarin as the most fluent language. The mean age of the L1-English learners was 21.3 (range: 19-26) and that of the L1-Mandarin
learners was 22.3 (range: 18-32) (see Table 1). Seventeen of the learners (7 L1-English and 10
L1-Mandarin) were enrolled in a second-year Japanese language course at a university in the
Pacific Northwest at the time of testing. Fifteen learners (9 L1-English and 6 L1-Mandarin) were
either enrolled in a fourth-year Japanese language course or had completed the level at the same
university at the time of testing. Learners were recruited from these levels so that the speech samples included a range of Japanese language abilities.
All 10 native Japanese speakers who provided speech samples were from Tokyo. Their mean
age was 21.1 (range: 20-22) and all were attending the above-mentioned university at the time of
testing. Their average length of stay in the US was 12.8 months (range: 3 months-6 years). These
Japanese speakers had no formal linguistic training or Japanese language teaching experience. All
reported daily use of Japanese.
Additionally, 22 native Japanese listeners (14 female and 8 male) participated as raters in the foreign accent rating task. None of the raters provided speech samples. The raters were on average 21.8
years old (range: 18-35), attending the above-mentioned university or a nearby community college,
and had been in the US no more than seven months at the time of testing. Seventeen of the raters were
from Tokyo or its adjacent prefectures, where standard Japanese is spoken. The other five raters were
from regions where regional dialects are spoken (e.g., Osaka).4 Eleven raters (Rater group 1) were
assigned to rate the L1-English learners' and native Japanese speakers' speech samples, while the
other eleven raters (Rater group 2) were assigned to rate L1-Mandarin learners' and native Japanese
speakers' samples.5 Each group of raters showed high agreement in rating within the group, with the
intra-class correlation coefficient r = 0.987 for Rater group 1, and r = 0.988 for Rater group 2.

2.2 Speech material
The test materials used to elicit speech samples comprised six short Japanese sentences (see
Appendix). The sentences were chosen from a beginning level Japanese language course book
(Tohsaku, 1995) for their length and comprehensibility, which were deemed appropriate for the

Idemaru et al.

339

participants, as well as for the range of segments included in them. These sentences included simple sentence structures. As often is the case for spoken Japanese, four sentences (1, 4, 5, and 6 in
the Appendix) included a sentence-final particle, which may carry various intonational tones (e.g.,
high, rising). One sentence was a question. The lexical items in the sentences included both
accented words (e.g., kurasu-wa (class-topic) HLLL) and unaccented words (e.g., nihongo-no
(Japanese-possessive) LHHHH).
The L2 and native-speaker productions of the test sentences were collected using a delayed
repetition task, an elicitation technique used in L2 research as a method that facilitates relatively natural production while maintaining control of the speech materials (Flege, Munro, &
MacKay, 1995; Trofimovich & Baker, 2006). Two native Japanese speakers, a female (the first
author) and a male, recorded six prompts for the task (see Appendix), each comprising a
question-response-question sequence as in (1). In each sequence, the response is one of the
six test sentences:
(1) Question (male):
Nihongo no kurasu wa doo desu ka? "How is your Japanese class?"
Response (female): Tanoshii desu yo. "It is fun."
Question (male):
Nihongo no kurasu wa doo desu ka? "How is your Japanese class?"
As the example shows, the first speaker asked a question, followed by a response by the second
speaker. Then, the first speaker repeated the question. The repetition of the response was not
included in the prompt, so as to cue the participants to produce their own responses. This design
allows elicitation of target utterances while avoiding immediate repetition of the model (Piske
et al., 2001). The six prompts for the task were recorded in a sound booth using a flash digital
recorder (Marantz PMD 670) and a standing microphone (Shure Beta 87) at a sampling rate of 44
kHz and 16-bit quantization. These two native speakers only recorded the task prompts and did not
participate in the subsequent study.

2.3 Production task
The six recorded prompts were presented to participants auditorily, and participants were
recorded producing the test sentences in response to the questions. Each participant was given
two practice prompts, which were followed by the six test prompts in random order. Each prompt
(question, response, and question) was presented three times consecutively. The recordings were
conducted individually in a sound booth, the same setting used for recording the prompts. The
experimenter (the second or the third author) was present in the sound booth during the recording to present the prompts using E-Prime experimental software (Psychology Software Tools,
Inc.) and to ensure production of the target sentences. All measures reported in this paper were
taken from either the second or third repetition of the target sentences. Typically, the third repetition was used, but if the third repetition included disfluency (e.g., wrong word or false start), the
second repetition was selected.

2.4 Accent rating task
The selected speech samples, the second or the third repetition of L2 learner and native speaker
productions of the six test sentences, were presented to native Japanese raters to examine the
perceived accentedness of each production. None of the raters participated in the production task
or in the creation of the production prompts. The raters rated both filtered and unfiltered speech
samples.

340

Language and Speech 62(2)

A filtering technique was used to degrade segmental information, following earlier studies that
used this technique (e.g., Anderson-Hsieh et al., 1992; Munro, 1995; Trofimovich & Baker, 2006).
The speech samples collected (original speech samples) were band-path filtered at 700-1300 Hz,
around the region of the second formant, and amplitude normalized to 75dB, resulting in a new set
of speech samples (filtered speech samples). The application of a band-pass filter eliminated a portion of the frequency information; however, the speech was still intelligible and retained prosodic
information intact. Band-pass filtering, instead of low-pass filtering, has been used to investigate
speech rhythms, as the resulting signal retains the alternation of vocalic and non-vocalic intervals,
critical information for the perception of speech rhythms (Cummins & Port, 1998; Tilsen &
Johnson, 2008). The original speech samples were also amplitude normalized to 75dB.
The original speech samples were used to obtain accent ratings for speech that retains all acoustic information, both segmental and prosodic. The filtered speech samples were used to obtain
accent ratings for speech that only retains prosodic information intact. Native speakers' speech
samples were included in the stimuli of the rating task, to serve as anchor samples in the task.
Eleven raters heard and rated a total of 310 stimuli (16 L1-English learners and 10 Japanese x
6 sentences x 2 sets (original and filtered), excluding two utterances that contained a lexical error
or syntactic disfluency). Two utterances (produced by two different L2 speakers) were excluded
from this experiment so that raters could remain focused on phonetic features rather than on errors
arising from a wrong word or false start of a word. The same utterances were also excluded from
the acoustic analysis. The other eleven raters heard and rated a total of 311 stimuli (16 L1-Mandarin
learners and 10 Japanese x 6 sentences x 2 sets (original and filtered), excluding one utterance
containing syntactic disfluency).
In the rating task, the native Japanese raters listened to each utterance and rated it on its degree
of foreign accentedness. Prior to the task, the experimenter (one of the three authors) explained the
task and verified that the participants understood what gaikokugo namari ("foreign accent")--the
term appearing on the experiment screen--meant and that it was different from regional accent.
The experiment began with a practice block of four trials, two using original stimuli and two using
filtered stimuli, in that order, so that participants understood the procedure prior to the test trials.
The practice stimuli were different from the test stimuli. Within the test block, filtered stimuli and
original stimuli were blocked, and presented in that order. Within each block, the stimuli were
presented in a random order.
Each trial began with an auditory presentation of an utterance and the presentation of a visual
analog scale (Urberg-Carlson, Munson, & Kaiser, 2009). Raters were then prompted to rate each
utterance for degree of foreign accentedness by sliding the bar in the middle of the scale using a
computer mouse. The leftmost point on the bar corresponded to the rating of "like a native speaker"
and the rightmost point corresponded to "extremely strong foreign accent" as indicated in Japanese
on the screen. Raters were instructed that they could drag the bar anywhere between these points
according to their judgment of accentedness. An accent score between 0 and 100 was registered
depending on where the bar came to rest between the two points (the leftmost point = 0, the rightmost point = 100). The raters had an option of listening to an utterance as many times as they wished
by clicking the visual display. All raters completed the rating task in approximately 30 minutes.

2.5 Acoustic measurements
2.5.1 Vowel. The frequencies of the first and second formants (F1 and F2) were measured in short
vowels, [i], [e], [a], [u], and [o], and in long vowels, [i:] and [e:], at the vowel mid-point, by using
waveform and spectrographic displays in Praat 5.2.18 (Boersma & Weenink, 2005). The symbol
[u] instead of [] is used in this section for simplicity. The vowel formants were then normalized

Idemaru et al.

341

to control for individual differences using the Lobanov method (Nearey, 1977; Thomas & Kendall,
2015), with the formula
Fn[V]N = (Fn[V] - MEANn)/Sn.
As described in Thomas and Kendall (2015), "Fn[V]N is the normalized value for Fn[V] (i.e., for
formant n of vowel V), MEANn is the mean value for formant n for the speaker in question and Sn
is the standard deviation for the speaker's formant n."
2.5.2 Stop. The duration of closure was measured from the offset of the preceding vowel to the onset of
the burst, and VOT was measured from the onset of the burst to the onset of periodicity in the following
vowel. It was not possible to measure the duration of stop closure at the initial position in the sentence.
In this case, only VOT was submitted for analysis. Also, it was sometimes difficult to determine if the
silent interval before a VOT was a closure or a combination of closure and pause. A silent period longer
than 100 ms was defined as a pause (Trofimovich & Baker, 2006), and a silent interval longer than 100
ms before a VOT was considered and coded as an interval including a stop closure and a pause. These
were not submitted for analysis of stop closure duration. To normalize the closure and VOT durations
against articulation rate, the ratio of closure and VOT duration to the average consonant-vowel (CV)
mora was computed for each sentence and speaker. The normalized closure and VOT durations were
then averaged separately for voiceless and voiced stops across six sentences for each speaker.
2.5.3 Global rhythm. The measures of global linguistic rhythm examined in this study were VarcoV,
VarcoC, V%, and normalized pairwise variability index (nPVI) (Dellwo, 2006; Ramus, Nespor,
& Mehler, 1999; White & Mattys, 2007). VarcoV and VarcoC are the standard deviation of
vowel durations and consonant durations, respectively, in each utterance corrected for speech rate.
V% is the percentage of the total duration of vowels in each utterance, and nPVI indicates the
deviations of durations of vowels in adjacent syllables corrected for speech rate. These indices
were measured in each test sentence and were averaged across six sentences for each speaker.
2.5.4 Tonal pattern. The J_ToBI (Venditti, 2005) was adapted to characterize the tonal patterns of the
speech samples collected. Among a number of tone types and break indices described in J_ToBI, a
subset of tone types sufficiently characterized the tonal patterns of the six test sentences we used in
this study. Accordingly, the following tone types were coded: (1) lexical pitch accent (denoted as
H*+L in J_ToBI) is an accentuation at the lexical level marked by a high tone immediately followed
by a pitch fall; (2) an accentual phrase in Japanese is characterized by a rise and a fall in pitch across
a phrase (e.g., daigaku-no "of the university"). The boundaries of the accentual phrase are marked by
an initial low tone (%L) and a final low tone (L%); (3) pitch rises from the initial low tone to a high
tone. This high tone typically occurs at the second mora in the accentual phrase (H-). If this second
mora high tone coincided with the lexical pitch accent, it was marked as such; and (4) intonation
boundary tones mark the end of the utterance. Three types of intonation boundary tones, rising (H%),
falling (L%), and falling-rising (LH%), were observed in our speech samples and were coded. For
the pitch accent and intonation measures, the patterns observed for the native Japanese samples were
taken as the target patterns for each of the six sentences, including variation across the 10 native Japanese speakers. The first and the second authors, who are trained in phonetics, conducted coding of
these critical tone types in 249 utterances (16 L1-English learners, 16 L1-Mandarin learners, 10
native speakers x 6 sentences, excluding three utterances that contained syntactic disfluency). When
there was a disagreement, the two authors discussed the case till they reached agreement. The tone
pattern of each L2 speech sample was then compared to the target patterns, and for each L2 tone that
did not match the target tone(s), one error score was recorded. Again, the first and the second authors

342

Language and Speech 62(2)

conducted the analysis separately and discussed discrepancies until they reached agreement. The
pitch accent/intonation error score ("pitch error score" henceforth) was then tallied for each sentence
and averaged across six sentences for each L2 speaker.
2.5.5 Fluency. Fluency characteristics may have an important role in perceived foreign accent
(Munro & Derwing, 2001; Trofimovich & Baker, 2006). Three variables characterizing production
fluency, that is, speaking rate, pause duration and pause frequency, were examined. Speaking rate,
the rate of speech including the pauses, was computed by dividing the duration of each utterance,
including the pause durations, by the number of moras of the sentence. A pause was defined as a
silent period within an utterance that was longer than 100 ms (Trofimovich & Baker, 2006). Pause
duration was computed for each speaker as an average of all pauses across six sentences. Pause
frequency was the average number of pauses across six sentences for each speaker.

2.6 Analysis
Foreign accent ratings were z-score normalized for each rater. An accent rating score for the original and filtered speech was then obtained for each speaker (16 L1-English learners, 16 L1-Madarin
learners, and 10 native Japanese speakers) as the mean normalized accent ratings averaged across
six sentences and 11 raters, with a greater value denoting a greater degree of foreign accentedness.
Rater group 1 and Rater group 2 rated the same set of native speaker samples. Accent scores of the
native speaker samples did not differ across the two rater groups, p = 0.35 for the original samples,
p = 0.61 for filtered samples. As the accent ratings of native speakers typically do not vary substantially, this is not an ideal test of similar rating patterns. Nonetheless, since both rater groups rated
this subset of speech samples, we report a comparison of these ratings. These results suggest that
the native Japanese raters reliably perceived some degree of foreign accent in L2 speech samples,
and that the groups did not differ in the rating of native speaker samples.
We examined the question of how the acoustic characteristics of the speech samples explained
the perceived foreign accent using regression analyses. More specifically, for each of the L1-English
and L1-Mandarin speech samples (with each including the native speaker samples), two separate
multiple regression analyses were conducted. The first analysis, prosodic analysis, examined the
accent rating scores of the filtered speech samples as the dependent with prosodic features as predictors. The second analysis, full analysis, examined the accent rating scores of the original (unfiltered) speech samples as the dependent with both segmental and prosodic features as predictors.
Prior to the regression analyses, we examined the correlations between the accent ratings and
each of the acoustic features to first understand the basic relationship between the dependent and
predictor variables (detailed results are reported below). Only those factors that showed statistically significant correlation, at p < 0.05, were considered for the subsequent regression analyses.
Also, as some predictor variables showed significant and strong correlation with the dependent,
sequential regression was used to explore the effects of other predictors before the strongly correlating predictors were included in the model.
Some considerations were made to address the issue of small sample size (n = 26 in each data
set) and the large number of acoustic features examined in this study. Researchers recommend
that sample size be considered against the effect size (Larson-Hall, 2015 for review; Knofczynski
& Mundfrom, 2008; Maxwell, 2000). Recent studies that modeled accent rating using phonetic
predictors suggest a potentially large effect size for this type of modeling, R2 = 0.76 in Trofimovich
and Isaacs (2012) and R2 = 0.41 in Kang (2010). According to the recommendation of Larson-Hall
(2015), which is based on Cohen, Cohen, West, and Aiken (2003), 26 observations are needed for
a regression equation with 10 predictors when the effect size is expected to be R2 = 0.50. In this

343

Idemaru et al.
Table 2. Summary of foreign accent rating scores.

L1-English learners
Native speakers
L1-Mandarin learners
Native speakers

Stimulus type

Mean

Standard error

Minimum

Maximum

Original
Filtered
Original
Filtered
Original
Filtered
Original
Filtered

0.64
0.43
-0.99
-0.68
0.64
0.51
-1.03
-0.81

0.07
0.09
0.04
0.05
0.05
0.08
0.05
0.05

0.00
-0.32
-1.16
-0.96
0.28
-0.02
-1.34
-1.12

1.14
1.00
-0.85
-0.39
1.06
1.10
-0.84
-0.56

study, the predictor variables were under 10 in each regression equation as a result of the procedure described above. In addition, a bootstrapping procedure (e.g., Larson-Hall, 2015) was used
to implement a repeated sampling (1000 times) of the original data with replacement, fitting the
model each time. This procedure ensures the robustness of the analysis and imparts a measure of
accuracy to model estimates.
The statistical analyses were conducted using R version 3.3.1, and the WRS package (Wilcox &
Shonbrodt, 2014) was used for the bootstrapping procedure. The relaimpo package (Gromping,
2006) was used to obtain the measure of relative importance of each predictor in the regression
equation. Multicollinearity and redundancy of the predictor variables were considered using the
variance inflation factor (VIF). The recommendations in the literature vary; however, a VIF greater
than 4-10 seems to merit further investigation (O'Brien, 2007 for a review; Larson-Hall, 2015).

3

Results

As the summary of foreign accent rating scores show (Table 2), the scores of native Japanese speaker
samples ranged below zero, indicating that they were all rated as being less accented than the mean.
Preliminary t-tests showed that native Japanese speakers' scores were significantly lower than the
scores of L1-English learners', p < 0.001 for both ratings of original and filtered samples (Rater
group 1), and the scores of L1-Mandarin speakers, p < 0.001 for both ratings of original and filtered
samples (Rater group 2). These results suggest that the native Japanese raters reliably perceived
some degree of foreign accent in L2 speech samples. It is also noted that the range of accent scores
for the learner group does not overlap with that of the native speaker group, either for the original
samples or the filtered samples. This lack of overlap of accent scores across the learners' and native
speakers' filtered speech samples seems to indicate that prosodic information alone could distinguish L2 accented speech and native speech, a finding also reported by Munro (1995).

3.1 L1-English learners
3.1.1 Correlation analysis. A preliminary analysis examined bivariate correlation between the accent
rating of the original samples and all acoustic measures, and between the accent rating of the filtered samples and prosodic measures. Table 3 reports statistically significant correlations. The
pitch error score strongly correlated with the ratings, r = 0.87 for original samples and r = 0.92 for
filtered samples, while other factors in Table 3 mildly correlated with the accent ratings. The high
level of correlation has implications for the application of regression analysis, and this issue is
addressed in the next section.

344

Language and Speech 62(2)

Table 3. Segmental and prosodic features significantly correlating with the accent rating of the original
speech samples (top), and prosodic features significantly correlating with the accent rating of the filtered
speech samples (bottom). The mean values and standard deviation (in parentheses) are also provided for
the L1-English learners and native speaker (NS) groups.
Original sample

r

p

L1-English

NS

F1 in [a]
F1 in [o]
F2 in [e]
F2 in [i]
Voiceless closure
Voiceless voice onset time
VarcoV
Pitch error score

0.41
-0.43
-0.65
0.41
-0.45
0.63
-0.59
0.87

0.036
0.027
< 0.001
0.035
0.022
0.001
0.001
< 0.0001

1.15 (0.98)
-0.16 (0.19)
0.43 (0.18)
1.21 (0.13)
0.38 (0.06)
0.30 (0.04)
44.87 (6.06)
1.02 (0.45)

1.03 (0.21)
-0.02 (0.22)
0.74 (0.18)
1.01 (0.33)
0.43 (0.06)
0.22 (0.06)
54.35 (5.56)
0.00 (0.00)

Filtered sample
VarcoV
Pitch error score

-0.56
0.92

0.003
< 0.0001

44.87 (6.06)
1.02 (0.45)

54.35 (5.56)
0.00 (0.00)

The L1-English learners made, on average, about one pitch and intonation error per sentence as
the mean indicates (Table 3), and the learners who had a higher number of errors were rated as
more heavily accented. The significant correlations between the vowel acoustics and the accent
rating are illustrated in Figure 1. Front-back position, that is, F2, correlated with the accent rating
for [i] and [e]: more fronted [i] and more central [e] were associated with a greater accent rating
("more heavily accented"). Vowel height, that is, F1, correlated with an accent rating of [o] and [a]:
higher [o] and lower [a] correlated with a greater accent rating. These learners also tended to have
shorter closure and longer VOT in voiceless stops, and these tendencies correlated with accent rating. Native Japanese speakers showed the greater mean value of VarcoV, indicating that their
vowel duration was more variable than that of learners. Smaller variation in vowel duration correlated with greater accent ratings.
A number of acoustic factors also correlated with other acoustic factors. The correlation coefficient 0.70 or higher was used as the criterion of high correlation, warranting caution in this study
following Larson-Hall (2015) and Tabachnick and Fidell (2007). Among the eight predictors in this
analysis (see Table 3), we found strong correlation between F1 in [a] and F2 in [i], r = 0.74, and
between F1 in [o] and F2 in [i], r = 0.71. VIFs of these vowel factors and others are examined in
the regression analysis sections below.
3.1.2 Regression modeling--prosodic analysis. The prosodic features considered here were pitch error
score and VarcoV, the two features found to correlate with the accent rating. A very strong correlation between the accent rating and pitch error score, r = 0.92, indicated that this factor was
likely to explain a large portion of the variance in the accent rating. Given this, a sequential regression analysis was conducted, entering VarcoV in the equation first (Model 1), and then adding
pitch error score to the model (Model 2) in order to examine the effect of VarcoV before the
strong factor, pitch error score, was entered into the equation.
The results showed (Table 4) that whereas the model with VarcoV as the sole predictor
(Model 1) explained 31% of the variance in the accent rating, when pitch error score was added
in Model 2, the coefficient for VarcoV was no longer statistically significant. The coefficient
for pitch error score was statistically significant. The significance of the coefficients is based

Idemaru et al.

345

Figure 1. The vowel formants correlating with the accent score of the Original samples plotted
in the Lobanov normalized first and second formants space. L1-English learners are indicated by
filled circles, L1-Mandarin learners by triangles (see the discussion on the Mandarin group in a later
section), and native Japanese speakers by asterisks. The arrows indicate the direction of increased
accent rating.

on the bootstrapped estimates. This model (Model 2) explained 86% of the variance in the
accent rating, and the R2 increase in Model 2 over Model 1 was statistically significant, F(23,1)
= 89.50, p < 0.001. Low VIF values indicate that there was little evidence of multicollinearity
between the two predictors.
These results indicate that when only prosodic factors were available as intact features in speech
samples, control of pitch accent and intonation strongly influenced native Japanese listeners' perception of a foreign accent in English-accented Japanese. When pitch accent and intonation was
controlled for, however, the control of vowel duration (i.e., VarcoV) was a reliable factor and
explained over 30% of the variance in the dependent variable.
3.1.3 Regression modeling--full analysis. The factors listed in Table 3, excluding VarcoV, were
considered in this analysis (a total of seven predictors). As explained in the Analysis section,
VarcoV was excluded as it was found to be non-significant in the final model in the prosodic
analysis. Given the strong correlation between pitch error score and the accent rating of the
original samples, r = 0.87, pitch error score was likely, in this analysis too, to explain a substantial portion of the rating data. Accordingly, two models were examined, as in the last section.
Model 1 included all factors except for pitch error score, and Model 2 added the highly correlating pitch error score.
Model 1 explained 60% of the variance in the accent rating (Table 5). In this model, only the
coefficient for F2 in [e] (i.e., the front-back dimension) was statistically significant. There was no
redundancy of effects with other predictors, as indicated by the low VIFs. This indicates that vowel
predictors did not overlap in their effects on the model, although we found some intercorrelation
among some of them (see the correlation analysis section above). The model estimates suggested
that the more centrally produced [e] was rated as more heavily accented. None of the other vowel

346

Language and Speech 62(2)

Table 4. Regression model statistics for L1-English learners prosodic analysis.
Model

Model 1
Model 2
VIF
Rel

R2

R2

0.31
0.86

Unstandardized coefficients

0.31
0.55

Intercept

VarcoV

Pitch error

2.25
-0.03

-0.05**
-0.01
1.33
0.16

0.87*
1.33
0.70

Note: `Rel' = relative importance of each coefficient; * = significant at p < 0.05, ** = p < 0.01, *** = p < 0.001 based on
boot-strapped estimates.

features or consonant features was a reliable predictor. However, when pitch error score was added
to the model (Model 2), pitch error score was the only significant predictor. This model explained
87% of the variance in the dependent variable, and the increase of R2 over Model 1 was meaningful, F(18, 1) = 38.10, p < 0.0001.
It is noteworthy that pitch error score showed strong bivariate correlation, r = 0.87, with the
accent rating of the original, unfiltered speech, and was the only reliable predictor among several in the model predicting the rating, R2 = 0.87. Whereas a vowel feature, F2 in [e], showed a
reliable effect in Model 1, its effect disappeared when pitch error score was added in Model 2.
Previously (and in this study too), out of a concern that the strong influence of segmental features (e.g., vowels) could possibly overwhelm perception of prosodic features (e.g., pitch
accent), researchers took the step of filtering speech samples to reduce or eliminate segmental
information so that they could examine the effect of prosody alone on foreign accent. The current results indicate that listeners can be sensitive to prosodic features even in the presence of
segmental features. And in fact, in the current study, the effect of a prosodic feature (i.e., pitch
error score) seemed to overwhelm the effects of segmental features, at least in the modeling
results.
The results here show that among the segmental and prosodic features examined in this study,
the control of pitch accent and intonation has the most critical influence on the extent to which
native English speakers' Japanese is judged as accented. It appears that if pitch accent is controlled
for, the production of the vowel [e], specifically the front-back dimension of its production, has a
strong effect on accent perception.

Table 5. Regression model statistics L1-English learners full analysis.
Model

R2

R2 Unstandardized coefficients
Intercept F1.[a]

1
VIF
Rel
2
VIF
Rel

0.60 0.60 -1.52

0.87 0.27 -1.86

1.36
2.54
0.06
1.02
2.56
0.04

F1.[o] F2.[e]

F2.[i] Closure VOT Pitch

-0.02 -1.61*
2.38 1.43
0.05 0.24
-0.07 -0.94
2.38 1.56
0.04 0.17

-0.14 -0.36
3.26 1.65
0.04 0.05
-0.17 0.88
3.26 1.68
0.03 0.04

4.55
1.90
0.17
2.08 0.90*
2.04 1.59
0.12 0.43

Note: Rel = relative importance of each coefficient, closure = voiceless stop closure, VOT = voiceless stop VOT,
* = significant at p < 0.008 for Model 1 and at p < 0.007 for Model 2 based on boot-strapped estimates.

347

Idemaru et al.

3.2 L1-Mandarin learners
3.2.1 Correlation analyses. We found a number of segmental and prosodic features correlating with the
accent ratings of the speech samples produced by L1-Mandarin learners (Table 6). Among these factors, as in L1-English learners' data, pitch error score strongly correlated with the accent ratings of
Table 6. Segmental and prosodic features significantly correlating with the accent rating of the original
(top) and the filtered speech samples (bottom). The mean values and standard deviation (in parenthesis)
are also provided for the L1-English learners-Mandarin and native speaker (NS) groups.
Original sample

r

p

L1-Mandarin

NS

F1 in [o]
F2 in [u]
Voiceless closure
Voiceless VOT
Voiced closure
Voiced VOT
VarcoV
VarcoC
Pause duration
Pause frequency
Speaking rate
Pitch accent error

-0.39
-0.87
-0.74
0.46
0.45
0.44
-0.52
-0.63
0.41
0.56
0.72
0.88

0.049
< 0.001
< 0.001
< 0.001
0.020
0.025
0.007
0.001
0.036
0.003
< 0.001
< 0.001

-0.19 (0.22)
-0.72 (0.24)
0.32 (0.05)
0.28 (0.06)
0.25 (0.04)
0.10 (0.03)
46.72 (5.78)
49.82 (6.03)
60.11 (60.55)
0.39 (0.21)
172.66 (15.81)
0.85 (0.34)

-0.02 (0.23)
-0.03 (0.20)
0.43 (0.06)
0.22 (0.06)
0.20 (0.03)
0.07 (0.03)
54.40 (5.56)
59.28 (7.34)
22.49 (26.01)
0.15 (0.12)
147.62 (10.83)
0.00 (0.00)

Filtered sample
VarcoV
VarcoC
Pause duration
Pause frequency
Speaking rate
Pitch accent error

-0.52
-0.62
0.45
0.54
0.75
0.88

0.006
0.001
0.020
0.005
< 0.001
< 0.001

46.72 (5.78)
49.82 (6.03)
60.11 (60.55)
0.39 (0.21)
172.66 (15.81)
0.85 (0.34)

54.35 (5.56)
59.28 (7.34)
22.49 (26.01)
0.15 (0.12)
147.62 (10.83)
0.00 (0.00)

both original and filtered samples, r = 0.88 for both. Unlike L1-English learners, speaking rate
strongly correlated with the accent rating of the original, r = 0.72, and filtered samples, r = 0.75. In
addition, F2 in [u], r = -0.87, and closure duration of voiceless stops, r = -0.74, showed strong correlation with the original samples, while other factors mildly correlated with the accent rating.
The significant correlations between the vowel acoustics and the accent rating are illustrated in
Figure 1. The distance between the Chinese learners' and native Japanese speakers' [u] in Figure 1
is notable, and [u] in a more backward position correlated with greater accent ratings. The patterns
of stop production are illustrated in Figure 2. L1-Mandarin learners had the tendency to produce
voiceless stops with shorter closure and longer VOT than native speakers, as well as the tendency
to produce voiced stops with longer closure duration and VOT. These non-native tendencies correlated with higher accent scores. In terms of the rhythm measures, whereas VarcoV alone correlated with the accent rating for English-accented Japanese, both VarcoV and VarcoC correlated
with the accent rating for Mandarin-accented Japanese. As indicated by the mean values and direction of the correlation (Table 6), L1-Mandarin learners showed smaller variation in both vowel and
consonant duration, and this was associated with higher accent ratings. Among the fluency measures, longer and more frequent pauses and slower speech correlated with higher accent ratings.

348

Language and Speech 62(2)

Figure 2. The acoustics of voiceless and voiced stops correlating with the accent score. The measure
on the Y-axis is the normalized duration. The dark bars represent L1-Mandarin learners and the gray bars
represent native Japanese speakers. The error bars indicate 1 standard error of the mean.

An examination of correlation among these features found a few statistically significant correlations that were stronger than or close to the criterion, r  0.70. Speaking rate correlated
strongly with two other factors: F2 in [u], r = -0.68; and pause frequency, r = 0.68. F2 in [u]
additionally correlated near the criterion level with closure in voiceless stops, r = 0.68, and
above the level with pitch error score, r = 0.74. The issue of intercorrelation of the predictors is
considered in the sections below.
3.2.2 Regression modeling--prosodic analysis. The prosodic features considered here were VarcoV,
VarcoC, pause duration, pause frequency, speaking rate, and pitch accent error. Given very strong
bivariate correlations between the accent rating and two factors, pitch error score, r = 0.88, and
speaking rate, r = 0.75, a sequential regression analysis was conducted. The first model examined
all factors except speaking rate and pitch error score (Model 1), then adding speaking rate to the
model (Model 2), and finally adding pitch error score (Model 3).
Even when the two strong predictors, pitch error score and speaking rate, were not in the equation, the model with the other factors explained 70% of the variance in the rating score (Model 1
in Table 7). In this model, the coefficients for VarcoV and pause frequency were significant.
This suggests that when pitch and speaking rate are controlled for, the control of vowel duration
and speaking without pauses may be important features that affect accent perception in Mandarin
speakers' Japanese. As expected, the addition of speaking rate (Model 2) improved the model,
F(20, 1) =6.03, p = 0.02. In this model, R2 = 0.77, VarcoV remained a significant predictor.
Pause frequency was no longer significant, but speaking rate was significant. The model in which
all factors were included (Model 3) improved the fit of data over Model 2, F(19, 1) =27.43, p <
0.0001, explaining 91% of the variance in the rating score. In Model 3, the coefficients for
VarcoV and pitch error score alone were significant. Of these predictors, pitch error score

349

Idemaru et al.
Table 7. Regression model statistics for L1-Mandarin learners prosodic analysis.
Model

R2

R2

Unstandardized coefficients
Intercept V

1
VIF
Rel
2
VIF
Rel
3
VIF
Rel

0.70

0.70

3.24*

0.77

0.07

-0.11

0.91

0.14

-0.90

C

-0.04* -0.03
1.30
1.23
0.19
0.23
-0.04* -0.02
1.23
1.71
0.18
0.16
-0.00* -0.03
1.36
1.93
0.12
0.11

Pause d Pause f Rate

Pitch

0.002
1.64
0.10
0.0003
1.87
0.07
0.001
1.92
0.06

0.80*
2.35
0.35

1.27*
1.55
0.18
0.58
2.20
0.11
-0.08
2.50
0.08

0.02*
3.04
0.25
0.01
3.23
0.17

Note: Rel = relative importance of each coefficient; Pause d = pause duration; Pause f = pause frequency; Rate = Speaking rate, * = significant at p < 0.013 for Model 1, p < 0.010 for Model 2, and p < 0.008 for Model 3 based on bootstrapped estimates.

showed a stronger influence, indicated by the relative importance metrics, 0.35 for pitch error
score and 0.12 for VarcoV. Low VIF values indicate that there was little evidence of multicollinearity among the predictors.
These results show that in the domain of prosody, control of pitch accent and intonation as well
as control of vowel duration are the key features influencing the foreign accent in L1-Mandarin
learners' Japanese production, with pitch accent and intonation having a stronger influence than
vowel duration. When the effect of pitch error is absent, slow speech affects the accent rating. When
the effects of both pitch error and slow speech are absent, frequent pauses affect the accent rating.
3.2.3 Regression modeling--full analysis. The six segmental factors listed in Table 6 and two prosodic
factors, VarcoV and pitch error score, were submitted to the analyses here. The dependent measure strongly correlated with three predictors, namely, pitch error score, r = 0.88, F2 in [u] r = -0.87,
and closure duration in voiceless stops, r = -0.74. Thus, a sequential regression first examined all
factors except for the three highly correlating factors (Model 1), then adding voiceless stops (Model
2), adding F2 in [u] (Model 3), and finally adding pitch error score (Model 4).
As Table 8 reports, none of the coefficients was significant in Model 1. The addition of voiceless
stop closure in the next step improved the fit, Model 2, R2 = 0.79, R2 change: F(19, 1) = 21.87, p <
0.001. In this model, the coefficient for voiceless stop closure was the only statistically significant
predictor among the six. Whereas the addition of F2 in [u] in Model 3 seemed to slightly improve
the model, R2 = 0.88, R2 change: F(18, 1) = 12.23, p < 0.001, none of the coefficients was reliable.
We ran a follow-up model that added the factor of F2 in [u] to Model 1 to examine whether the
non-significant effect of F2 in [u] in Model 3 was due to the fact that it was entered after voiceless
closure. Recall that F2 of [u] and voiceless stops showed correlation. The results still showed a
non-significant effect of the factor, F2 in [u].
Finally, the model that included pitch error score (Model 4) indicated that the coefficient for pitch
error score was the only reliable coefficient in this model. This model explained 93% of the variance
in the accent rating, and the increase in R2 over Model 3 was statistically significant, F(17, 1) = 12.89,
p < 0.01. It is noted that the VIF of pitch error score was higher (4.85) than other cases, although it is
still within the threshold according to some criteria (O'Brien, 2007). This indicates that its effect
showed some degree of overlap with those of other variables. However, the findings that none of the

350

Language and Speech 62(2)

Table 8. Regression model statistics for L1-Mandarin learners full analysis.
Model

R2

R2 Unstandardized coefficients
C

1
VIF
Rel
2
VIF
Rel
3
VIF
Rel
4
VIF
Rel

F1.[o]

0.55 0.55 -0.97 -0.90
1.25
0.09
0.79 0.25 1.84 -0.60
1.28
0.06
0.88 0.09 1.36 -0.25
1.38
0.04
0.93 0.05 0.90 0.19
1.63
0.03

-v
VOT

+v
+v
V
closr VOT

2.48
1.41
0.10
-1.24
1.77
0.07
-1.16
1.77
0.05
0.61
2.13
0.04

5.91
1.15
0.13
6.58
1.16
0.13
3.06
1.56
0.09
-1.67
2.68
0.06

5.65
1.19
0.09
4.20
1.20
0.07
2.57
1.24
0.05
0.84
1.32
0.04

-v
closr

F2.[u]

Pitch

-0.03
1.26
0.14
-0.02
6.58*
1.31
1.66
0.10
0.35
-0.02 -3.82 -1.02
1.31
1.56
2.86
0.09
0.22
0.33
-0.02 -1.49 -0.77
1.32
3.45
3.14
0.07
0.16
0.25

0.87*
4.85
.27

Note: Rel = relative importance of each coefficient, C = intercept, -v = voiceless, +v = voiced, closr = closure, * =
significant at p < 0.010 for Model 1, p < 0.008 for Model 2, p < 0.007 for Model 3, and p < 0.006 for Model 4 based on
boot-strapped estimates.

other variables were significant in Model 3 and that pitch error score was the only significant variable
in Model 4 seem to indicate the importance of this factor in predicting the accent rating.
These results indicate that among a large number of acoustic features considered in this
study, the control of pitch accent and intonation has the most crucial influence on the accent
rating of Mandarin speakers' original, unfiltered speech samples. This finding is consistent
with the analysis of English speakers' samples. It appears that if pitch accent is controlled for,
the production of the voiceless stops, specifically their closure duration, has a strong effect on
accent perception.
3.2.4 Summary of the findings. Pitch error score emerged as the most crucial factor explaining
the degree of perceived accentedness of L1-English learners' Japanese. In the absence of pitch
error effect, a segmental feature, F2 in [e], emerged as an important factor affecting the perception of an accent. When the effects of pitch error score and segmental information were absent
in the speech (i.e., prosodic analysis), a rhythm factor, VarcoV, emerged as an important factor. In L1-Mandarin learners' Japanese too, of all factors including segmental features, pitch
error score emerged as the most predictive factor. In the absence of pitch error effect, a segmental feature, closure in voiceless stops, emerged as an important factor. When the segmental
information was absent in the speech (i.e., prosodic analysis), a rhythm factor, VarcoV,
appeared as an important factor complementing the effect of pitch error score. Only when segmental information and these two strong prosodic factors were excluded, did speech rate and
pause frequency influence the degree of perceived accent.
The relative importance metric of pitch error score in the final models was 0.43 for L1-English
speakers and 0.27 for L1-Mandarin speakers in full models, and 0.70 for L1-English speakers
and 0.35 for L1-Mandarin speakers in prosodic models. The results indicate that the relative
weight of the pitch error score was higher for L1-English learners than for L1-Mandarin
learners.

Idemaru et al.

4

351

Discussion

This study explored acoustic sources of accent in L2 Japanese produced by learners of two L1s,
English and Mandarin. One of our hypotheses was that prosodic features would strongly predict
the degree of perceived foreign accent in both English-accented and Mandarin-accented Japanese.
The current findings were partially consistent with the prediction. Not all prosodic features were
strong predictors; however, among all the features examined, one prosodic feature emerged as a
very robust and strong predictor. In both L1-English and L1-Mandarin learners' Japanese speech
samples, error in the tonal pattern (pitch accent and intonation) most strongly affected the degree
of perceived foreign accent. Its influence was stronger than that of other prosodic features, vowel
qualities, and stop features. The control of pitch accent and intonation has critical influence on
perceived accent in English-speaking learners' and Mandarin speaking learners' L2 Japanese.
We also predicted that the tonal patterns would be more predictive of the degree of accent in
L1-English learners' Japanese than in L1-Mandarin learners' Japanese. This prediction was supported. Pitch error score was weighted more heavily relative to other factors in the analysis of
L1-English learners than in the analysis of L1-Mandarin learners. This study presents a case in which
L1-L2 phonological differences/similarities can inform important acoustic sources of accent in L2.
In addition to the cross-linguistic explanation, there may also be a function-based explanation
for the current findings regarding the importance of tonal patterns. Tonal structure, which includes
pitch accent and intonation, not only provides information for lexical identity, but it also conveys
the information regarding syntactic structure (e.g., phrases) and pragmatic meaning (e.g., mood)
(Beckman & Hirshberg, 1994; Venditti, 2005). Because of this, while segmental errors may typically affect perception within the lexical domain, pitch and intonation errors may exert an influence in a broader domain, that is, at the level of phrases and utterances. This may be why errors in
pitch accent and intonation are so robustly related to accent ratings.
We also found other factors that may contribute to perceived accent in English- and Mandarinaccented Japanese. For both groups, another prosodic factor, VarcoV, was identified as one such
factor. Native Japanese speakers showed a greater degree of variation in vowel duration than either
learner group. The Japanese vowel duration is likely variable because of the presence of short and
long vowels, as well as both a single vowel mora and a CV mora taking approximately the same
duration. Lack of this durational variance apparently leads to perception of an accent.
Whereas the two L1 groups were similar with regard to the effect of prosody, namely, pitch error
and VarcoV, on their accent, we found group differences in the effect of segmental features.
L1-English learners showed a potential source of accent in a vowel: the vowel [e]. L1-Mandarin
learners showed a potential source of accent in a stop feature: closure duration in voiceless stops.
Prior literature on cross-linguistic analysis of the stops distinction focused on VOT (e.g., Riney
et al., 2007), but our findings suggest that future research needs to examine differences in closure
duration as well as VOT. We also found additional prosodic features that influenced the L1-Mandarin
learners' speech: two fluency factors, speaking rate and pause frequency, had weak effects.
We have used filtered and unfiltered speech samples to obtain accent ratings due to a concern
among researchers that issues with prosodic features may not be detected in speech stimuli that
contain segmental errors (Munro, 1995; Trofimovich & Baker, 2006; van Els & De Bot, 1987). In
spite of this concern, our findings have shown that prosodic factors, particularly pitch accent,
exerted a strong influence in our study, even in speech stimuli that contained segmental deviations.
It appears that listeners can be sensitive to segmental and prosodic issues simultaneously.
The current findings involving L2 Japanese are consistent with some of the prior studies that
examined other target languages. In particular, Torofimovich and Isaacs (2012) found that two

352

Language and Speech 62(2)

prosodic factors, word stress errors and vowel reduction ratio, explained 76% of the variance in the
accent rating of L1 French speakers' English by novice raters, the type of raters who participated
in this study. This is similar to the current finding in that prosodic features explained 86% (American
learners) and 91% (Chinese learners) of the variance in the accent ratings. These two studies
involving L2 Japanese and L2 English present cases in which prosodic factor(s) influenced the
perceived foreign accent more than the segment-related factors that were examined. The comparison of L1-L2 phonological systems seems to explain the outcome of the French-accented English
in Torofimovich and Isaacs (2012) as well: the authors explained that English and French are markedly different in their prosodic systems, English being stress-timed, with variable lexical stress,
and French being syllable-timed, with more regular stress placement. On the other hand, Winters
and O'Brien (2013) found that segments influenced the perception of foreign accent more than
prosody in English-accented German and German-accented English. While this outcome may
appear the opposite of the results of the current study and that of Torofimovich and Isaacs (2012),
the prosody of English and German are relatively similar, both being stress-timed and stressaccented. In light of this, the results are consistent with the idea that if the prosodic systems of L1
and L2 are considerably different, prosodic features are likely to be a major source of a perceived
foreign accent in learners' L2.
However, the same idea does not seem to explain the results of Sereno et al. (2016), who found
that segments contributed more than prosody to the degree of perceived accent in Korean-accented
English. English (stress-timed, stress-accented) does not seem to be any less different from
Korean--which is syllable-timed and employs an intonation system characterized at the phrasal
level rather than the lexical level--than from French. Thus, there appear to be other factors that
likely influence the acoustic source of a foreign accent in this case. The proficiency level of L2
learners may be one such factor. The 32 non-native participants in this study were not fluent speakers, and the 40 in Torofimovich and Isaacs (2012) seemed to vary in proficiency. On the other hand,
the two Korean speakers in Sereno et al. (2016) were very fluent in English. There is a possibility
that these two individuals were particularly proficient in acquiring English prosodic features.
However, if the results could be generalized to a larger group of advanced Korean learners of
English, they may indicate that even when L1 and L2 vary substantially in their prosodic systems,
their relative influence on perceived foreign accent decreases as the speaker's proficiency develops. This in turn would suggest that English prosody may be earlier developing than segments for
Korean learners.
Although the robust effect of pitch and intonation on perceived accent is evident in the current
results, we need to interpret these findings cautiously. While our analysis of prosodic factors
included a large number of measurements, our analysis of segmental features focused on singleton vowels and stops features. These segmental features were selected based on suggestions in
the prior literature (Tanaka & Kubozono, 1999; Toda, 2004); however, it is possible that other
features influenced accent ratings in a significant way. For example, there may be issues in the
ways learners produce Japanese fricatives, such as [s], and flap [r]. In addition, the test sentences
did not sample all long vowels and geminate consonants. Long vowels and geminate consonants
have been discussed as potentially problematic areas (Hirata, 2004; Hirata & Whiton, 2005), and
future research on Japanese foreign accent will need to examine the role of these segmental features on accent.
Furthermore, as an exploratory investigation, this study used naturally produced speech samples
as stimuli to be rated by native listeners. We mean by "naturally produced" that the samples did not
undergo modification of specific acoustic features to test for the effect of the selected features. As
such, acoustic features naturally covaried in the speech stimuli that were rated, and it was not possible to tease apart the effects of features to identify their independent influence on accent rating.

Idemaru et al.

353

To this end, we have provided a careful examination of correlation among acoustic features and a
discussion of features that influenced accent rating when the most highly correlated factors were
excluded in the regression equation. In future studies, L2 speech samples, such as those analyzed
in this study, can be manipulated so that pitch and intonation and certain segmental feature(s) (e.g.,
vowel and stop acoustics) vary independently. Alternatively, prosodic properties could be extracted
from the speech samples of one group and superimposed on the speech samples of another group
(e.g., de Mareuil & Vieru-Dimulescu, 2006; Jilka, 2000; Sereno et al., 2016; Winters & O'Brien,
2013). These lines of further work will contribute to the understanding of foreign accent phenomena in general, and in particular, to the debate on the relative importance of prosody and segments
on perceived accent.
Another aspect of foreign accent phenomena that merits further investigation is the nature of
and interplay among intelligibility, comprehensibility and accentedness in L2 speech (e.g., Munro
& Derwing (1999)). Research findings are clear that these constructs are related but are not necessarily highly correlated. Because the task used in this study involved naive native listeners simply
rating "degree of foreign accent" in L2 speech samples, their ratings may have focused on any of
the three dimensions: intelligibility; comprehensibility; or accentedness. It will be informative to
tease apart the effects of these dimensions in the future research and investigate what distinct linguistic features are crucially related to each.

5

Conclusion

The current study has explored the acoustic sources of a perceived foreign accent in L2 Japanese
speech produced by American learners and Mandarin-speaking learners of Japanese, focusing on
various prosodic, vowel and stop features. Prediction models relating detailed acoustic measures
and accent rating demonstrated that pitch accent and intonation is an important source of perceived
foreign accent in both English-speaking learners' and Mandarin-speaking learners' Japanese.
Additionally, control of vowel duration affects accent in both groups of learners. This study on L2
Japanese presents a case in which differences and similarities between L1 and L2 influence the
acoustic sources of perceived foreign accent. This study also provides novel findings with regard
to the characteristics of foreign accent in L2 Japanese and contributes to the understanding of the
nature of foreign accent in general.
Acknowledgements
We thank two anonymous reviewers, Robert O'Brien, Bodo Winter, and Vsevolod Kapatsinski for helpful
suggestions and Sara King for assistance with data collection. We also thank the late Dr. Susan GuionAnderson for her feedback on an earlier version of this study. Portions of this work were presented at the
165th Meeting of the Acoustical Society of America, Montreal, Canada, June 2-7, 2013 and at the 18th
International Congress of Phonetic Sciences, Glasgow, Scotland, August 14-15, 2015.

Funding
This research received no specific grant from any funding agency in the public, commercial, or not-for-profit
sectors.

Notes
1.

As reported in the Method section, the measure analyzed in this study is "foreign accents," perceived as
such by lay listeners. Defined thus, this construct does not strictly differentiate itself from intelligibility
or comprehensibility. This issue is revisited in the Discussion section.

354
2.

3.

4.

5.

Language and Speech 62(2)
The pitch pattern is lexically specified, and a maximum of one pitch accent is allowed within a lexical
item (Vance, 2008). Thus, words can be accented (/toshokan/ LHLL "library") or unaccented (/nihongo/
LHHH, "Japanese").
None of the L1-English learners learned a foreign language before age 14, except for one, who learned
Vietnamese at age 7. As the preliminary results including this participant did not differ significantly from
those excluding him/her, his/her data were retained for the analyses presented in the text.
Although it is unknown whether perception of a foreign accent in the native language is influenced by
the listener's regional variety, since the raters' rating scores showed strong inter-rater reliability, the data
from all raters were retained for the analysis. The Japanese listeners had no formal linguistic training or
Japanese language teaching experience.
Raters were divided into two groups with each rating the production of one L1-group because intrarater comparison of English accent and Mandarin accent was not part of the research question and also
because we wanted to prevent individual preferences that raters may have had for one accent over the
other from conditioning their ratings.

References
Anderson-Hsieh, J., Johnson, R., & Koehler, K. (1992). The relationship between native speaker judgments
of nonnative pronunciation and deviance in segmentals, prosody, and syllable structure. Language
Learning, 42(4), 529-555.
Beckman, M. E., & Hirschberg, J. (1994). The ToBI annotation conventions. Ohio State University. Retrieved
from https://www.ling.ohio-state.edu/~tobi/ame_tobi/annotation_conventions.html
Beckman, M. E., & Pierrehumbert, J. B. (1986). Intonational structure in Japanese and English. Phonology,
3, 255-309.
Best, C. T. (1995). A direct realist view of cross-language speech perception. In W. Strange (Ed.), Speech
perception and linguistic experience: Issues in cross-language research (pp. 171-204). Baltimore, MD:
York Press.
Best, C. T., McRoberts, G. W., & Goodell, E. (2001). Discrimination of non-native consonant contrasts varying in perceptual assimilation to the listener's native phonological system. Journal of the Acoustical
Society of America, 109(2), 775-794.
Boersma, P., & Weenink, D. (2015). Praat: Doing phonetics by computer (Version 5.2. 18) [Computer software]. Retrieved from http://www.fon.hum.uva.nl/praat/
Bosker, H. R., Pinget, A. F., Quene, H., Sanders, T., & De Jong, N. H. (2012). What makes speech sound fluent? The contributions of pauses, speed and repairs. Language Testing, 30(2), 159-175.
Chao, K. Y., & Chen, L. M. (2008). A cross-linguistic study of voice onset time in stop consonant productions. Computational Linguistics and Chinese Language Processing, 13(2), 215-232.
Chen, L. M., Chao, K. Y., & Peng, J. F. (2007). VOT productions of word-initial stops in Mandarin and English:
A cross-language study. In ROCLING. Retrieved from http://www.aclweb.org/anthology/O07-2004
Chen, Y., Robb, M., Gilbert, H., & Lerman, J. (2001). Vowel production by Mandarin speakers of English.
Clinical Linguistics & Phonetics, 15(6), 427-440.
Cheng, B., & Zhang, Y. (2015). Syllable Structure Universals and Native Language Interference in Second
Language Perception and Production: Positional Asymmetry and Perceptual Links to Accentedness.
Frontiers in Psychology, 6(6), 1801. DOI: 10.3389/fpsyg.2015.01801
Cohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003). Applied multiple regression/correlation analysis for
the behavioral sciences. New York, NY: Routledge.
Cummins, F., & Port, R. (1998). Rhythmic constraints on stress timing in English. Journal of Phonetics,
26(2), 145-171.
Dellwo, V. (2006). Rhythm and speech rate: A variation coefficient for C. In P. Karnowski & I. Szigeti
(Eds.), Language and language-processing (pp. 231-241). Frankfurt am Main, Germany: Peter Lang.
de Mareuil, P. B., & Vieru-Dimulescu, B. (2006). The contribution of prosody to the perception of foreign
accent. Phonetica, 63(4), 247-67.
Derwing, T. M., & Munro, M. J. (1997). Accent, intelligibility, and comprehensibility. Studies in Second
Language Acquisition, 19(1), 1-16.

Idemaru et al.

355

Flege, J. E. (1995). Second language speech learning: Theory, findings, and problems. In W. Strange
(Ed.), Speech perception and linguistic experience: Issues in cross-language research (pp. 233-277).
Baltimore, MD: York Press.
Flege, J. E. (1999). Age of learning and second language speech. In D. Birdsong (Ed.), Second language acquisition and the critical period hypothesis (pp. 101-131). Mahwah, NJ: Lawrence Erlbaum Associates
Publishers.
Flege, J. E., Munro, M. J., & MacKay, I. R. (1995). Factors affecting strength of perceived foreign accent in
a second language. Journal of the Acoustical Society of America, 97(5), 3125-3134.
Gay, T. (1970). A perceptual study of American English diphthongs. Language and Speech, 13(2), 65-88.
Grabe, E., & Low, E. L. (2002). Durational variability in speech and the rhythm class hypothesis. In C.
Gussenhoven & N. Warner (Eds.), Laboratory phonology, Volume 7 (pp. 515-546). Berlin, Germany:
Mouton de Gruyter.
Gromping, U. (2006). Relative importance for linear regression in R: the package relaimpo. Journal of
Statistical Software, 17(1), 1-27.
Hillenbrand, J., Getty, L. A., Clark, M. J., & Wheeler, K. (1995). Acoustic characteristics of American English
vowels. Journal of the Acoustical Society of America, 97(5), 3099-3111.
Hirata, Y. (2004). Training native English speakers to perceive Japanese length contrasts in word versus sentence contexts. Journal of the Acoustical Society of America, 116(4), 2384-2394.
Hirata, Y., & Whiton, J. (2005). Effects of speaking rate on the single/geminate stop distinction in Japanese.
Journal of the Acoustical Society of America, 118(3), 1647-1660.
Homma, Y. (1981). Durational relationship between Japanese stops and vowels. Journal of Phonetics, 9,
273-281.
Howie, J. M. (1976). Acoustical studies of Mandarin vowels and tones (Volume 6). Cambridge, NY:
Cambridge University Press.
Hyman, L. M. (2009). How (not) to do phonological typology: the case of pitch-accent. Language Sciences,
31(2), 213-238.
Isaacs, T., & Trofimovich, P. (2012). Deconstructing comprehensibility. Studies in Second Language
Acquisition, 34(3), 475-505.
Iverson, P., & Evans, B. G. (2009). Learning English vowels with different first-language vowel systems II:
Auditory training for native Spanish and German speakers. Journal of the Acoustical Society of America,
126(2), 866-877.
Jia, G., Strange, W., Wu, Y., Collado, J., & Guan, Q. (2006). Perception and production of English vowels by
Mandarin speakers: Age-related differences vary with amount of L2 exposure. Journal of the Acoustical
Society of America, 119(2), 1118-1130.
Jilka, M. (2000). The contribution of intonation to the perception of foreign accent: Identifying intonational
deviations by means of F0 generation and resynthesis. PhD Dissertation. Universitat Stuttgart, Germany.
Retrieved from https://pdfs.semanticscholar.org/f8c4/56fdce6276be06e41d4f4589a9070e35f2af.pdf
Kang, O. (2010). Relative salience of suprasegmental features on judgments of L2 comprehensibility and
accentedness. System, 38(2), 301-315.
Klatt, D. H. (1975). Voice onset time, frication, and aspiration in word-initial consonant clusters. Journal of
Speech, Language, and Hearing Research, 18(4), 686-706.
Knofczynski, G. T., & Mundfrom, D. (2008). Sample sizes when using multiple linear regression for prediction. Educational and Psychological Measurement, 68(3), 431-442.
Kong, E. J., Beckman, M. E., & Edwards, J. (2012). Voice onset time is necessary but not always sufficient
to describe acquisition of voiced stops: The cases of Greek and Japanese. Journal of Phonetics, 40(6),
725-744.
Larson-Hall, J. (2015). A guide to doing statistics in second language research using SPSS and R. New York,
NY: Routledge.
Lev-Ari, S., & Keysar, B. (2010). Why don't we believe non-native speakers? The influence of accent on
credibility. Journal of Experimental Social Psychology, 46(6), 1093-1096.
Lin, Y. H. (1989). Autosegmental treatment of segmental processes in Chinese phonology. Doctoral
Dissertation. University of Texas at Austin, USA.

356

Language and Speech 62(2)

Lin, Y. H. (2007). The Sounds of Chinese. Cambridge, UK: Cambridge University Press.
Ling, L. E., Grabe, E., & Nolan, F. (2000). Quantitative characterizations of speech rhythm: Syllable-timing
in Singapore English. Language and Speech, 43(4), 377-401.
Liu, H., Ng, M. L., Wan, M., Wang, S., & Zhang, Y. (2007). Effects of place of articulation and aspiration
on voice onset time in Mandarin esophageal speech. Folia Phoniatrica et Logopaedica, 59(3), 147-154.
Maddieson, I., & Disner, S. F. (1984). Patterns of sounds. Cambridge, UK: Cambridge University Press.
Maxwell, S. E. (2000). Sample size and multiple regression analysis. Psychological Methods, 5(4), 434-458.
Mok, P. P. (2012). Does vowel inventory density affect vowel-to-vowel coarticulation? Language and
Speech, 56(2), 191-209.
Munro, M. J. (1995). Nonsegmental factors in foreign accent: Ratings of filtered speech. Studies in Second
Language Acquisition, 17, 17-34.
Munro, M. J., & Derwing, T. M. (1995). Foreign accent, comprehensibility, and intelligibility in the speech
of second language learners. Language Learning, 45(1), 73-97.
Munro, M. J., & Derwing, T. M. (1999). Foreign accent, comprehensibility, and intelligibility in the speech
of second language learners. Language Learning, 49(Supplement 1), 285-310.
Munro, M. J., & Derwing, T. M. (2001). Modeling perceptions of the accentedness and comprehensibility of
L2 speech the role of speaking rate. Studies in Second Language Acquisition, 23(4), 451-468.
Munro, M. J., & Derwing, T. M. (2011). The foundations of accent and intelligibility in pronunciation
research. Language Teaching, 44(3), 316-327.
Munro, M. J., & Derwing, T. M. (2015). A prospectus for pronunciation research in the 21st century: A point
of view. Journal of Second Language Pronunciation, 1(1), 11-42.
Nearey, T. M. (1977). Phonetic feature systems for vowels. PhD Dissertation. University of Connecticut,
USA.
Nishi, K., Strange, W., Akahane-Yamada, R., Kubo, R., & Trent-Brown, S. A. (2008). Acoustic and perceptual similarity of Japanese and American English vowels. Journal of the Acoustical Society of America,
124(1), 576-588.
O'Brien, R. M. (2007). A caution regarding rules of thumb for variance inflation factors. Quality & Quantity,
41(5), 673-690.
Oyama, S. (1976). A sensitive period for the acquisition of a nonnative phonological system. Journal of
Psycholinguistic Research, 5(3), 261-283.
Patkowski, M. (1994). The critical age hypothesis and interlanguage phonology. In M. Javas (Ed.), First and
second language phonology (pp. 205-221). San Diego, CA: Singular Publishing Group.
Piske, T., MacKay, I. R., & Flege, J. E. (2001). Factors affecting degree of foreign accent in an L2: A review.
Journal of Phonetics, 29(2), 191-215.
Port, R. F., Al-Ani, S., & Maeda, S. (1980). Temporal compensation and universal phonetics. Phonetica,
37(4), 235-252.
Ramus, F., Nespor, M., & Mehler, J. (1999). Correlates of linguistic rhythm in the speech signal. Cognition,
73(3), 265-292.
Riney, T. J., Takagi, N., Ota, K., & Uchida, Y. (2007). The intermediate degree of VOT in Japanese initial
voiceless stops. Journal of Phonetics, 35(3), 439-443.
Saito, K., Trofimovich, P., & Isaacs, T. (2017). Using listener judgments to investigate linguistic influences
on L2 comprehensibility and accentedness: A validation and generalization study. Applied Linguistics,
38(4), 439-462.
Scovel, T. (1969). Foreign accents, language acquisition, and cerebral dominance. Language Learning, 19(3-
4), 245-253.
Sereno, J., Lammers, L., & Jongman, A. (2016). The relative contribution of segments and intonation to the
perception of foreign-accented speech. Applied Psycholinguistics, 37(2), 303-322.
Sun, C. (2006). Chinese: A linguistic introduction. Cambridge, UK: Cambridge University Press.
Tabachnick, B. G., & Fidell, L. S. (2007). Using multivariate statistics. 5th edition. Needham Height, MA:
Allyn & Bacon.
Tanaka, S., & Kubozono, H. (1999). Introduction to Japanese pronunciation: theory and practice. Tokyo,
Japan: Kuroshio.

Idemaru et al.

357

Thomas, E. R., & Kendall, T. (2015). NORM: The vowel normalization and plotting suite. Retrieved from
http://lingtools.uoregon.edu/norm/norm1
phpTilsen, S., & Johnson, K. (2008). Low-frequency Fourier analysis of speech rhythm. Journal of the
Acoustical Society of America, 124(2), EL34-EL39.
Toda, T. (2004). Komyunikeishion no tame no nihongo hatsuon ressun (Japanese pronunciation lessons for
communication). Tokyo, Japan: 3A Network. [In Japanese.]
Tohsaku, Y. (1995). Yookoso! Continuing with contemporary Japanese 1 and 2. New York, NY: McGrawHill.
Trofimovich, P., & Baker, W. (2006). Learning second language suprasegmentals: Effect of L2 experience on
prosody and fluency characteristics of L2 speech. Studies in Second Language Acquisition, 28(1), 1-30.
Trofimovich, P., & Isaacs, T. (2012). Disentangling accent from comprehensibility. Bilingualism: Language
and Cognition, 15(4), 905-916.
Urberg-Carlson, K., Munson, B., & Kaiser, E. (2009). Gradient measures of children's speech production:
Visual analog scale and equal appearing interval scale measures of fricative goodness. Journal of the
Acoustical Society of America, 125(4), 2529-2529.
Vance, T. J. (2008). The sounds of Japanese. Cambridge, UK: Cambridge University Press.
van Els, T., & de Bot, K. (1987). The role of intonation in foreign accent. The Modern Language Journal,
71(2), 147-155.
Venditti, J. J. (2005). The J_ToBI model of Japanese intonation. In S.-A. Jun (Ed.), Prosodic typology: The
phonology of intonation and phrasing (pp. 172-200). New York, NY: Oxford University Press.
Wayland, R. (1997). Non-native production of Thai: Acoustic measurements and accentedness ratings.
Applied Linguistics, 18(3), 345-373.
White, L., & Mattys, S. L. (2007). Calibrating rhythm: First language and second language studies. Journal
of Phonetics, 35(4), 501-522.
Wiese, R. (1997). Underspecification and the description of Chinese vowels. In J. Wang & N. Smith (Eds.),
Studies in Chinese phonology (pp. 219-249). Berlin, Germany: Mouton de Gruyter.
Wilcox, R. R., & Schonbrodt, F. (2009). WRS: A compiled package of RR Wilcox'robust statistics functions.
R package version 0, 1. Retrieved from https://github.com/nicebread/WRS
Winters, S., & O'Brien, M. G. (2013). Perceived accentedness and intelligibility: The relative contributions
of F0 and duration. Speech Communication, 55(3), 486-507.

Appendix
Prompts for the delayed repetition task.
(1)Question: Nihongo no kurasu wa doo desu ka? "How is your Japanese class?"
Response: Tanoshii desu yo. "It is fun."
(2) Question: Asa wa nanji ni okimasu ka? "What time do you get up in the morning?"
Response: Rokuji ni okimasu. "I get up at 6-o'clock."
(3) Question: Ima ichiban nani ga kaitaidesu ka? "What would you like to buy the most right
now?"
Response: Kuruma ga kaitai desu. "I would like to buy a car."
(4) Question: Yuubinkyoku wa doko ni arimasu ka? "Where is the post office?"
Response: Daigaku no tonari ni arimasu yo. "It is next to the university."
(5) Question: Ashita nani o shitaidesu ka? "What would you like to do tomorrow?"
Response: Ashita wa eega ga mitai desu ne. "I would like to see a movie tomorrow."
(6) Question: Ima nani ga ichiban hoshiidesu ka? "What would you like the most (as a gift)
now?"
Response: Nihongo no jisho ga hoshii desu ne. "I would like a Japanese dictionary."

