The Effect of Asymmetrical Signal
Degradation on Binaural Speech
Recognition in Children and Adults
Ann M. Rothpletz*
Anne Marie Tharpe
D. Wesley Grantham
Vanderbilt Bill Wilkerson Center
for Otolaryngology and
Communication Sciences,
Vanderbilt University,
Nashville, TN

To determine the effect of asymmetrical signal degradation on binaural speech
recognition, 28 children and 14 adults were administered a sentence recognition
task amidst multitalker babble. There were 3 listening conditions: (a) monaural,
with mild degradation in 1 ear; (b) binaural, with mild degradation in both ears
(symmetric degradation); and (c) binaural, with mild degradation in one ear and
severe degradation in the other ear (asymmetric degradation). Sentences and
babble were degraded digitally to simulate mild and severe cochlear hearing
loss. All participants demonstrated significant binaural advantage (average of 7
dB) when listening to symmetrically degraded signals as compared to when
listening monaurally. In contrast, adults and children achieved little or no binaural
benefit, on average, when listening to asymmetrically degraded signals. Moreover, overall performance of the adults was significantly worse when listening to
binaural asymmetrically degraded signals than when listening to monaural
signals, thus demonstrating evidence of binaural interference. In contrast to our
original speculations, however, children did not show an overall demonstration of
binaural interference. Relative performance in the binaural-asymmetric and the
monaural conditions was not influenced by which ear (right or left) received the
more degraded signal.
KEY WORDS: binaural hearing, asymmetrical hearing loss, binaural interference, speech perception, children

T

he notion that two ears are better than one for listening in noisy
environments has been dubbed a "psychoacoustic maxim" (Zurek,
1993, p. 255). Indeed, considerable research has demonstrated a
binaural advantage for understanding speech amidst background noise
(e.g., Bronkhorst & Plomp, 1988; Hawley, Litovsky, & Colburn, 1999;
Licklider, 1948; MacKeith & Coles, 1971). The advantages of binaural
listening include binaural summation (Scharf, 1968), improved localization ability (Humes, Allen, & Bess, 1980; Konkle & Schwartz, 1981;
Newton, 1983), and binaural release from masking (Licklider, 1948).
Despite the abundance of binaural research, little is known about
the ability of the auditory system to perceive speech when it is degraded
asymmetrically between the two ears. It is reasonable to speculate that
when the auditory system receives speech input that is degraded asymmetrically between the two ears, binaural speech perception could be
poorer than if the individual were listening monaurally to the better of
the two speech signals. That is, in cases where speech input is degraded

*Currently affiliated with the University of Colorado at Boulder

Journal of Speech, Language, and Hearing Research * Vol. 47 * 269-280 * April 2004 * (c)American Speech-Language-Hearing
Association
Rothpletz et al.: Binaural
Asymmetry
1092-4388/04/4702-0269

269

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

in one ear and more degraded in the other ear (e.g., asymmetrical hearing loss), individuals may experience more
difficulty perceiving speech with two ears than with the
better-hearing ear alone. The term "binaural interference" has been used to describe this auditory phenomenon (Jerger, Silman, Lew, & Chmiel, 1993).
A few studies have suggested that individuals are
able to derive binaural benefit when there are interaural
asymmetries (Ching, Psarros, Hill, Dillon, & Incerti, 2001;
McCullough & Abbas, 1992; Tyler, Parkinson, Wilson,
Witt, Preece, & Noble, 2002). For example, McCullough
and Abbas (1992) examined binaural syllable recognition ability in noise of 5 adults with symmetrical hearing loss who had interaural differences in speech recognition ability. Four of the 5 participants demonstrated a
slight binaural advantage over the best monaural condition. In addition, some studies have demonstrated binaural advantage in individuals with cochlear implants
when wearing a hearing aid on the ear opposite their
cochlear implant (Ching et al., 2001; Tyler et al., 2002).
These advantages were demonstrated in both adults and
children on speech perception and localization tasks.
In contrast to these studies, there have been several
examples in the literature of binaural disadvantage for
asymmetrical signals (Arkebauer, Mencher, & McCall,
1971; Bronkhorst & Plomp, 1988; Carter, Noe, & Wilson,
2001; Chmiel, Jerger, Murphy, Pirozzolo, & Tooley-Young,
1997; Jerger et al., 1993; Shinn-Cunningham, Schickler,
Kopc *o, & Litovsky, 2001). Binaural disadvantage (or binaural interference) occurs when the "poorer ear" (or more
degraded signal) has detrimental effects on perception
by the "better ear" (or less degraded signal). It has been
suggested that in some cases of bilateral sensorineural
hearing loss, the two ears may be presented with disparate cochlear distortion, causing abnormal demands
to be made on the auditory cortex (Hood & Prasher,
1990). For example, Arkebauer and colleagues observed
that 9 of 10 participants with asymmetrical hearing loss
demonstrated higher word recognition scores in the better ear under earphones than when listening with both
ears in the sound field. Furthermore, 8 of the 10 participants scored higher in sound field when the poorer ear
was occluded than when both ears were unoccluded.
Similarly, Carter et al., Chmiel et al., and Jerger et al.
reported individuals with asymmetrical speech perception abilities who demonstrated binaural interference
on unaided and aided word recognition tasks, sentence
identification tasks, topographical brain maps of the
middle latency response (MLR), and P300 evoked potentials. Binaural disadvantage has also been shown in
listeners with normal-hearing sensitivity in specific listening conditions (Bronkhorst & Plomp, 1988; Hood &
Prasher, 1990; Shinn-Cunningham et al., 2001). For example, Bronkhorst and Plomp and Shinn-Cunningham
270

et al. examined speech intelligibility in adults with normal hearing using different target signal speaker azimuths and masker speaker azimuths. The investigators
found some instances where binaural performance was
equal to or worse than the performance (or predicted
performance) of the better ear alone. Their finding was
contrary to assumptions of well-established models of binaural hearing. Hood and Prasher simulated dissimilar
cochlear distortion between ears in normal-hearing listeners. Although not reaching a level of significance, binaural performance of the listeners was, on average, inferior to the better monaural score. Participants expressed
that they found this binaural condition difficult and reported that they had to attend selectively to the ear with
the better signal in the binaural condition.
Finally, one study has demonstrated a third category
of results, "binaural indifference." Karsten and Turner
(2000) examined binaural speech discrimination ability
in adults with asymmetrical hearing losses while systematically altering the balance of presentation sensation level between the two ears. Binaural performance
of the listeners was not significantly better or worse than
monaural performance of the better ear at any of the
interaural intensity level differences.
It is possible that certain factors influence the ability to understand asymmetrically degraded speech. Two
such factors are the age of the listener and which ear
(right or left) receives the more degraded signal. With
regard to the listener's age, previous studies have demonstrated developmental effects on speech perception
tasks that appeared to be the result of both auditory
and linguistic factors. For example, Elliott, Conners,
Kille, Levin, Ball, and Katz (1979) demonstrated developmental improvements in the ability to recognize monosyllabic words in quiet in children between the ages of 5
and 10 years, even though the words were well within
the receptive vocabularies of 3-year-old children. Furthermore, Elliott (1979) found poorer performance on a
sentence recognition task in noise in children, ages 9-
13 years, than in older children and adults. Nabelek and
Robinson (1982) found that 10-year-old children required
higher presentation intensity levels than adults to
achieve maximum performance on a speech recognition
task amidst reverberation. Finally, Eisenberg, Shannon,
Martinez, Wygonski, and Boothroyd (2000) examined
speech recognition ability in children and adults using
sentences, words, syllables, and digit spans with reduced
spectral cues. Children, ages 5 to 7 years, required better spectral resolution than 10- to 12-year-old children
and adults to demonstrate similar levels of performance.
In addition to age-related differences on speech perception tasks, developmental differences in auditory
attention abilities have been demonstrated. Specifically,
studies have demonstrated that children, particularly

Journal of Speech, Language, and Hearing Research * Vol. 47 * 269-280 * April 2004

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

young children, have difficulty differentiating and
ignoring irrelevant stimuli in listening tasks compared
to older children and adults (e.g., Doyle, 1973; Lane &
Pearson, 1982).
In light of these age-related deficits in speech perception and selective attention skills, we hypothesized
that children may have more difficulty than adults on
asymmetrically degraded speech perception tasks and
may more readily demonstrate binaural interference.
We predicted that this age-related deficit would be most
evident for younger children whose selective attention
skills are not as well developed as those of older children and adults.
Left ear/right ear differences may be a second factor influencing the ability to understand asymmetrically
degraded speech. It is well accepted that a majority of
individuals (>90%) demonstrate left-hemisphere dominance for language (Kandell, Schwartz, & Jessel, 1991;
Loring et al., 1990; Rasmussen & Milner, 1977; Woods,
Dodrill, & Ojemann, 1988). In addition, numerous studies have demonstrated that most individuals show a
right-ear advantage for speech stimuli on dichotic listening tasks (Breier, Hiscock, Jahrsdoerfer, & Gray,
1998; Geffen, 1976; Hiscock & Chipuer, 1993; Morris,
Bakker, Satz, & Van der Vlugt, 1984). This right ear
advantage for verbal input has been attributed to the
right ear having privileged access to the left hemisphere.
Consistent with this notion, poorer speech recognition
performance, greater academic difficulty, and lower performance on verbal tasks has been demonstrated in children with right-ear unilateral hearing loss than in children with left-ear unilateral hearing loss (Bess, Tharpe,
& Gibler, 1986; Jensen, Borre, & Johansen, 1989; Jensen,
Johansen & Borre, 1989). Based on these studies, it was
speculated that individuals may experience greater difficulty on a binaural task if they receive a more degraded
signal in the right ear and a better signal in the left ear.
The effect of asymmetrical signal degradation on
binaural speech perception can be studied quite naturally in individuals with asymmetrical hearing loss or
in those with asymmetrical speech perception ability.
Furthermore, investigation of this effect in these clinical populations in the future may have important implications for the fitting of amplification. However, research
with these clinical populations introduces numerous extraneous variables that are rather arduous to control.
These variables include, but are not limited to, speech
perception ability of the better ear and the poorer ear,
amount of asymmetry between the two ears, duration of
deafness, duration of hearing asymmetry, and age of onset of hearing loss. For this reason, the current study
examined binaural speech perception performance in
children and adults with normal hearing sensitivity using stimuli that were degraded in a way that simulated

the effects of cochlear hearing loss. This permitted tight
control of the extraneous variables that are introduced
when investigating these clinical populations.
In this study we used digital simulations of mild
and severe cochlear hearing loss to examine the effect
of asymmetrical signal degradation on binaural speech
perception. It was expected that some listeners would
experience binaural interference or, at a minimum, lose
their binaural advantage for speech perception when
presented with asymmetrically degraded speech signals.
In addition, the current study compared the performance
of children and adults to determine if the occurrence of
binaural interference is contingent on the listener's age.
Finally, this project investigated the influence of right
ear/left ear presentation of greater signal degradation
on performance.

Method
Participants
Twenty-eight children and 14 adults with normal
hearing sensitivity were recruited to participate in this
study. Children were divided into two groups. The
younger child group consisted of 14 children (7 girls, 7
boys) between the ages of 5;0 (years; months) and 6;0
(M = 5;9). The older child group consisted of 14 children
(8 girls, 6 boys) between the ages of 10;0 and 11;5 (M =
10;5). Adults were placed in one group (9 women, 5 men)
and were between the ages of 24 and 29 years (M = 26;5).
Participants had no known language, attention, or learning disabilities, and all child participants were reported
by their parents to be performing at or above grade level.
Finally, with the exception of 1 participant in the older
child group, all participants were right-handed as demonstrated on a written task and self-report or parent
report. Left-handed individuals were excluded as much
as possible to reduce possible confounding factors related to hemispheric dominance for language. The 1
participant who was left-handed demonstrated performance on the experimental task that was equivalent to
the rest of the older child group (i.e., within 1 SD of the
older child group mean).

Preliminary Testing
All participants received a pure-tone audiologic assessment and demonstrated hearing thresholds of 20
dB HL or better for all audiometric test frequencies (500
Hz-4000 Hz), bilaterally. In addition, monosyllabic word
recognition was tested at a level of 40 dB SL relative to
the participant's speech reception threshold. Children
were administered the Phonetically Balanced-Kindergarten list (PB-K; Haskins, 1949), and adults were administered the Northwestern University Auditory List

Rothpletz et al.: Binaural Asymmetry

271

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

#6 (NU-6) word lists (Tillman & Carhart, 1966). All participants achieved 92% or greater on a list of 25 monosyllabic words in each ear.
The Peabody Picture Vocabulary Test-Third Edition
(PPVT-III; Dunn & Dunn, 1997) was administered to
all child participants to assure age-appropriate receptive vocabulary skills. The PPVT-III is a nationally standardized, individually administered measure of spoken
vocabulary for children, ages 2 to 17 years, and adults.
All children exhibited average or above average performance. For the group of younger children, standard scores
were in the range of 103-132, with a mean score of 113.8.
The range of standard scores for the group of older children was 101-143, with a mean score of 121.2. Adult
participants were not administered the PPVT-III because it was assumed that their vocabulary skills were
adequate for the experimental task. With the exception
of 1 participant, all adults who participated in this
project had at least a college degree, and the 1 participant who had not completed college demonstrated performance on the experimental task that was equivalent
to the rest of the adult group (i.e., within 1 SD of the
adult group's mean).
Because the experimental task required spoken responses, and because previous research has demonstrated that children with articulation problems tend
to have auditory perceptual deficits (e.g., Ohde & Sharf,
1988), the Arizona Articulation Proficiency Scale-Third
Revision (AAPS-3; Fudala, 2000) was administered to
all child participants to ensure age-appropriate articulation skills. The AAPS-3 is a nationally standardized
picture identification test that examines children's abilities to articulate the various phonemes of the English
language. All children demonstrated age-appropriate
abilities on this test. Because all of the adult participants were known by the investigator not to have articulation problems, this articulation test was administered only to the children who participated in this study.

Speech Perception Testing

(version 6.1; The Mathworks, Inc., 2002) programming
environment.1 Two computer programs degraded the
speech materials in a manner designed to simulate cochlear hearing loss (Moore, 1998). The audiometric
thresholds listed in Table 1 were used as a basis for the
mild and severe conditions.
In Step 1, the HINT-C sentences were processed first
through the auditory filter-broadening program. The
purpose of this program was to simulate the consequences of reduced auditory frequency selectivity, assuming impaired place coding in the cochlea. The program
required entry of an upper and lower slope filter-broadening factor for 11 different frequency bands. Using the
guidelines devised by Moore and Glasberg (1997) and
the thresholds listed in Table 1, the broadening factors
were specified for the mild and severe conditions as listed
in Table 2. These broadening factors were then applied
digitally to the speech materials (i.e., the HINT-C sentences). As described by Moore (1998), the computer algorithms simulated the consequences of reduced frequency selectivity by taking a short segment of the signal
and calculating its spectrum via fast Fourier transform
(FFT). Then the spectrum was smoothed to reduce the
contrast between the peaks and valleys, and an inverse
FFT was used to transform the modified signal back into
the temporal domain. This process was repeated for a
succession of overlapping segments and the resulting
modified segments were added together (Moore, 1998).
After the HINT-C materials were processed through
the auditory filter-broadening program, the resulting signals were processed in Step 2 through the loudness recruitment/threshold elevation program. Thresholds listed
in Table 1 were specified as the audiometric thresholds
1

Dr. Brian Moore of the University of Cambridge supplied computer
algorithms that served as the basis for two computer programs.

Table 1. Audiometric thresholds as a function of frequency and
degradation condition.
Degradation condition (dB)

Speech Materials
Sentence materials from the Hearing-in-Noise Test
for Children (HINT-C; Gelnett, Sumida, Nilsson, & Soli,
1995) were used to test sentence recognition ability for
both the child and adult participants. The HINT-C is
composed of sentences that are readily identifiable by
children (with normal hearing sensitivity) as young as
5 years of age (Gelnett et al., 1995). The sentences were
derived from the original HINT sentences for adults;
therefore, the sentences were not considered too easy
for the adult participants.
A total of 160 of the HINT-C sentences were degraded by altering the signal digitally in the MATLAB
272

Frequency (Hz)
125
250
500
750
1000
1500
2000
3000
4000
6000
8000

Mild

Severe

5
15
25
25
35
40
45
45
50
55
60

60
60
65
70
75
75
80
80
85
90
95

Journal of Speech, Language, and Hearing Research * Vol. 47 * 269-280 * April 2004

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

Table 2. Auditory filter-broadening factor as a function of
frequency and degradation condition.
Degradation condition (dB)
Frequency (Hz)
125
250
500
750
1000
1500
2000
3000
4000
6000
8000

Mild

Severe

1
1
1.04
1.04
1.69
2.07
2.54
2.54
3.10
3.80
3.80

2.73
2.98
3.41
3.70
3.80
3.80
3.80
3.80
3.80
3.80
3.80

at each frequency for the mild and severe conditions.
This later program simulated the effects of threshold
elevation and loudness recruitment by splitting the signal into 13 frequency bands and expanding the envelope
in each band before recombining the bands (Moore, 1998).
The end result of Steps 1 and 2 of the processing was 160
mildly degraded HINT-C sentences and 160 of the same
HINT-C sentences that were severely degraded.

Babble Noise
Digitized six-talker babble served as the competing
stimuli. The spectrum of the babble was shaped to match
closely the combined spectrum of the HINT-C sentences.
The digitized babble then was processed through the
auditory filter-broadening program and the loudness
recruitment/threshold elevation program in the exact
manner of the HINT-C sentences. That is, the same
broadening factors and threshold parameters were used
when processing the babble as those used for processing the HINT-C sentences, resulting in mildly and severely degraded babble. For the sake of this project, it
was desirable that input in each experimental condition be of equal intensity regardless of the degree of degradation. Therefore, all resulting speech stimuli and
babble noise were equated in terms of root mean square.

was uncorrelated in the two ears); and (c) binaural-
asymmetric, in which mildly degraded sentences and
babble were presented to Ear 1 and severely degraded
sentences were presented to Ear 2. That is, the same
sentences were presented to both ears, but the sentences
were mildly degraded in one ear and severely degraded
in the other ear. The competing babble was uncorrelated
and also was mildly degraded in Ear 1 and severely degraded in Ear 2.
Ear 1 was the right ear and Ear 2 the left ear for
half of the participants in each group, and Ear 1 was
the left ear and Ear 2 the right ear for the other half of
the participants in each group. The intensity level of
the signal remained constant at 70 dB SPL and the level
of the babble was adjusted adaptively. Twelve sentences
were administered per run. Two adaptive runs were
administered in each of the three conditions, for a total
of 72 sentences. The computer selected the order of conditions. The examiner was blind to the order of conditions until all testing was completed. The order of conditions was counterbalanced across participants to
minimize order effects. All three conditions were administered once before any of the conditions were repeated.
Participants were instructed to repeat each sentence.
To be scored as correct, sentences had to be repeated without error. Allowable exceptions were substitutions in verb
tense (is/was, have/had) and articles (a/the).
The adaptive procedure operated for the first experimental run in each condition as follows:
1.

The first sentence was presented to the participant
with a +4-dB signal-to-babble ratio (SBR). If the
participant successfully repeated the sentence, the
babble intensity level was increased by 4 dB (i.e., to
a +0-dB SBR) for the second sentence. If the participant was unable to repeat the sentence correctly,
the babble intensity level was decreased by 4 dB
(i.e., to a +8-dB SBR) and the first sentence was
repeated. The intensity level of the babble continued to decrease by 4 dB until the participant was
able to repeat the first sentence successfully.

2.

A 4-dB step size was used to adjust the babble intensity level for the first five sentences. That is, if a
sentence was successfully repeated, the babble intensity level was increased by 4 dB for the subsequent sentence. If a sentence was missed, the babble
intensity level was decreased by 4 dB for the subsequent sentence.

3.

After the first five sentences, the step size changed
to 2 dB for the remaining seven sentences in the
experimental trial.

4.

The interfacing computer calculated a signal-tobabble threshold (SBT) based on the average SBR
of presentation for Sentences 5-13 (no 13th sentence

Procedures
Sentence recognition thresholds in noise were measured with insert earphones using an adaptive psychophysical procedure that tracked 50% accuracy in three
experimental conditions as follows: (a) monaural-mild,
in which mildly degraded sentences and babble were
presented to Ear 1 only; (b) binaural-mild, in which
mildly degraded sentences and babble were presented
to both ears (in this condition the sentences presented
to the two ears were identical, but the competing babble

Rothpletz et al.: Binaural Asymmetry

273

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

was presented, but the computer included the SBR
that would have been presented if a 13th sentence
were administered in the overall average).
The second experimental run in each condition operated like the first, except that the starting SBR for
the second run was the SBT from the first run rounded
to the nearest whole number plus 4 dB, and the step
size was 2 dB for the entire adaptive run.
The average of the two SBTs was calculated and taken
as the final score for each participant. If the difference in
SBT between the two experimental runs was greater than
5 dB in any condition, then a third experimental run,
also consisting of 12 sentences, was administered in that
condition. The starting SBR for the third run was the
average SBT from the first two runs in that condition
rounded to the nearest whole number, plus 4 dB. The
step size for the third run was 2 dB for the entire run.
An average SBT from the three experimental runs was
then taken as the final score for the participant.

Practice
Prior to testing, all participants listened to five sentences in quiet in the binaural mild condition. Participants were required to repeat all five sentences correctly.
If one was missed, then the individual was re-instructed
to repeat the sentences exactly. The participant then was
administered 10 sentences in quiet binaurally and was
required to repeat 9 of the 10 sentences correctly before
being allowed to participate in the experimental task.
Subsequent to the practice sentences presented in quiet,
all participants were administered 10 practice sentences
in each of the three experimental conditions using the
adaptive procedure. The order of the practice runs was
as follows: (a) binaural-mild, (b) monaural-mild, and
(c) binaural-asymmetric. The practice runs followed
similar procedures to the experimental runs, except that
the adaptive runs were initiated with a +12-dB SBR,
rather than a +4-dB SBR. Performance on the practice
runs demonstrated to the examiner that all participants
understood the instructions and were able to complete
the experimental task.

Analysis
The dependent variable on the speech perception
task was SBT in decibels, calculated as the average presentation SBR for Sentences 5-13 for each experimental run. As a reminder, lower SBTs indicate better performance. To determine whether there were any order
effects of the experimental runs (e.g., learning effects or
list effects), a repeated-measures analysis of variance
(ANOVA) was conducted on the SBTs of the six experimental runs in order of presentation (i.e., Run 1, 2,...6)
274

for each of the three age groups. Because the orders of
the listening conditions were randomized across participants, this analysis allowed a test of order effects independently of condition. No significant differences were
found among the six experimental runs in any of the
age groups. In addition, none of the groups demonstrated
significant polynomial trends in performance according
to the order of the experimental runs.
For each participant, an overall score in each condition was taken as the average SBT from the two runs in
each condition. If a participant required a third experimental run in a particular condition, then the overall
score for that condition was taken as the average SBT
from the three experimental runs. There were a total of
10 instances (out of a possible 126) in which a third experimental run was required in a particular condition--
4 instances in the younger child group and 3 instances
in both the older child and adult groups. None of the
participants required a third experimental run in more
than one condition.

Results
Mean SBTs averaged across the three listening conditions (with ranges in parentheses) were 9.98 dB (5.92-
3.38 dB) for the younger child group, 5.12 dB (3.09-7.83
dB) for the older child group, and 1.59 dB (-0.21-3.48
dB) for the adult group. An ANOVA revealed significant
main effects of age, F(2, 39) = 106.98, p < .001, and condition, F(2, 78) = 233.91, p < .001. Planned pairwise comparisons demonstrated that the adults significantly outperformed both the younger children, F(1, 26) = 212.21,
p < .001, and the older children, F(1, 26) = 37.74, p <
.001. In addition, the older children significantly outperformed the younger children, F(1, 26) = 71.20, p < .001.
Average scores in each condition for each of the three
age groups are illustrated in Figure 1. Performance in
the three listening conditions was compared by executing planned analytical comparisons in each of the three
age groups (Keppel, 1991). Performance in the binaural-mild condition was superior to performance in the
monaural-mild condition in the adult group, F(1, 13) =
115.84, p < .001; the older child group, F(1, 13) = 176.65,
p < .001; and the younger child group, F(1, 13) = 76.44,
p < .001. In fact, all participants showed a binaural advantage (i.e., binaural-mild performance superior to
monaural-mild performance) of 1 dB or more, with the
average binaural advantage being 5.79 dB for the adults,
8.05 dB for the older children, and 7.14 dB for the
younger children.
The advantage of listening with two ears diminished
when listening to asymmetrically degraded signals. Performance in the binaural-asymmetrical condition was
significantly poorer than in the binaural-mild condition

Journal of Speech, Language, and Hearing Research * Vol. 47 * 269-280 * April 2004

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

Figure 1. Mean signal-to-babble threshold (SBT) as a function of
age group and listening condition. Error bars represent 1 SE from
the group mean. Lower SBT values correspond to better speech
perception performance.

for the adults, F(1, 13) = 88.63, p < .001; older children,
F(1, 13) = 129.24, p < .001; and younger children, F(1, 13)
= 152.41, p < .001. All participants demonstrated poorer
thresholds in the binaural-asymmetric condition than in
the binaural-symmetric condition, with the average difference being 6.73 dB for the adults, 7.65 dB for the older
children, and 7.42 dB for the younger children.
Comparisons of the monaural-mild and binaural-
asymmetric conditions did not reveal marked differences
in performance for either group of children according to
ANOVA. For the adults, however, slight evidence of
binaural interference was found. Average performance

in the monaural-mild condition was significantly better than in the binaural-asymmetric condition for the
adult group, t(13) = 2.01, p < .05 (one-tailed). On average, adults performed approximately 1 dB better in the
monaural-mild condition than in the binaural-asymmetric condition.
Comparisons of performance between the monaural-mild and binaural-asymmetrical conditions also
were examined for individual participants. Differences
in individual performance between these listening conditions are shown in Figures 2, 3, and 4 for the younger
child, older child, and adult groups, respectively. Notably in Figures 2 and 3, the relative performance between
these two conditions was quite variable for the two
groups of children. Approximately equal numbers of
children showed binaural interference and binaural-
asymmetrical advantage. In the adult group, however,
there was a tendency for participants to demonstrate
binaural interference, and this trend is apparent in Figure 4. Specifically, 11 of the 14 adults performed more
poorly in the binaural-asymmetric condition than in the
monaural condition, which was significant according to
a sign test (p < .05, one-tailed).
Finally, left versus right ear comparisons were examined by dividing participants in each group into those
who received the mildly degraded stimuli in their right
ear and those who received the mildly degraded stimuli
in the left ear. No significant differences were obtained
among participants in any age group who received mild
degradation in their right ear versus those who received
mild degradation in the left ear when comparing the
binaural-asymmetric and monaural-mild conditions. In

Figure 2. Individual differences in listener performance between the binaural-asymmetric and monaural conditions in the younger child group.

Rothpletz et al.: Binaural Asymmetry

275

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

Figure 3. Individual differences in listener performance between the binaural-asymmetric and monaural conditions in the older child group.

other words, right ear versus left ear presentation did
not influence the pattern of performance in adults or
children.

Discussion
Consistent with decades of speech perception research (e.g., Bronkhorst & Plomp, 1988; Licklider, 1948),
participants in all three age groups in the current study
exhibited a binaural advantage when the sentence

materials were degraded symmetrically in the two ears.
Comparison of performance between the monaural-mild
and binaural-mild conditions revealed an average binaural advantage of 7 dB across participants in all age
groups. This binaural benefit presumably is the result of
two effects: (a) binaural unmasking, which has been
shown in other studies that have used a diotic signal with
an interaurally uncorrelated masker to yield about 1 dB
improvement in intelligibility (Levitt & Rabiner, 1967;
Licklider, 1948) and (b) diotic summation, which has been
shown to produce about 2-3 dB improvement in speech

Figure 4. Individual differences in listener performance between the binaural-asymmetric and monaural conditions in the adult group.

276

Journal of Speech, Language, and Hearing Research * Vol. 47 * 269-280 * April 2004

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

intelligibility for low-level speech presentation, listening
in noise, and listening amidst reverberation (Davis, Haggard, & Bell, 1990; Gelfand & Hochberg, 1976; Konkle &
Schwartz, 1981; Plomp & Mimpen, 1979). Even after taking into account enhancement resulting from binaural
unmasking (approximately 1 dB) and diotic summation
(approximately 2-3 dB), the amount of binaural advantage observed in this study is large (7 dB).
We considered the possibility that our use of sixtalker babble may have contributed to the large symmetrical advantage observed in this study, such as a
masking stimulus many contribute to release from informational masking. Recent work by Arbogast, Mason,
and Kidd (2002); Freyman, Helfer, McCall, and Clifton
(1999); and Kidd, Mason, Rohtla, and Deliwala (1998)
has demonstrated greater spatial release from informational maskers (e.g., a single talker) than energetic
maskers (e.g., speech-shaped noise, Gaussian noise).
Based on their research, if the babble used in this experiment produced informational masking, then we
would expect a greater binaural release from masking
than if we had used a purely energetic masker. However, based on findings that six-talker babble produces
little, if any, additional masking compared to a random
noise masker (Bronkhorst, 2000; Miller, 1947), we may
conclude that informational masking was not a factor
in the conditions of this study.
On average, results across age groups did not reveal that listeners performed markedly worse in the binaural-asymmetric condition than in the monaural condition. Stated differently, the poorer ear did not seem to
interfere significantly with the speech recognition ability of the better ear according to the overall group data.
In Figures 2, 3, and 4, participants in all three age groups
showed examples of binaural advantage and binaural
interference; however, adult performance was skewed
toward showing binaural interference. Specifically, data
from individual participants revealed that adults tended
to perform more poorly in the binaural-asymmetric condition than in the monaural condition. This finding is
consistent with previous reports of binaural interference
(e.g., Arkebauer et al., 1971; Carter et al., 2001; Hood &
Prasher, 1990; Jerger et al., 1993; Shinn-Cunningham
et al., 2001). For some of the adults, the binaural interference effect was very small (i.e., less than 1 dB), but a
few adults demonstrated quite substantial effects (e.g.,
2-4 dB). On average, adults exhibited approximately 1
dB of binaural interference. Although a 1-dB difference
seems small, a previous study using HINT materials
demonstrated that a difference of 1 dB on this adaptive
task corresponds to an 8.9% difference in sentence intelligibility (Nilsson, Soli, & Suminda, 1996).
Unlike the pattern with adults, the two groups of
children were approximately evenly distributed between

those who demonstrated a binaural advantage and those
who demonstrated binaural interference. It is not entirely clear why evidence of binaural interference was
prevalent in the adult group but not in the two groups of
children. This finding was contrary to the original speculation that children would more readily exhibit binaural
interference than would adults. It is possible that the
relative lack of binaural interference in the children was
related to their poor performance in the monaural condition. That is, because children generally required such
a large SBR to perceive sentences in the monaural condition, adding a severely degraded signal in the opposite ear had little additional interference effect.
Although all children did not exhibit binaural interference under our laboratory conditions, it is possible
that binaural interference might emerge more obviously
in everyday listening environments where individuals
often cannot focus exclusively on speech recognition. For
example, students at school often are required to listen
to the teacher while doing other things, like taking notes
or following directions. In multitasking situations such
as these, individuals must divide their attention between
listening and a secondary task. If listening to binaural
asymmetrically degraded signals requires listeners to
ignore input from the poorer ear, then it is possible that
performance may break down in this listening situation
when effort has to be divided between listening and another task. In such real-world situations that require
greater listening effort, it is possible that more children
would exhibit a binaural interference effect. Consistent
with this speculation, previous research suggested that
children with mild-moderate sensorineural hearing impairments have more difficulty performing dual tasks that
involve listening as the primary task than do children
with normal hearing. Presumably this deficit is revealed
because the hearing-impaired children have to expend
greater effort to engage in the auditory task (Hicks &
Tharpe, 2002). Future research should investigate performances of listeners in monaural and binaural asymmetrically degraded listening conditions while they are
performing secondary (nonauditory) tasks.
It is possible that binaural interference was not observed for more children because of their high variability in performance, particularly in the monaural condition. Variability in group performance, as measured by
standard deviation, was greater in both child groups
than in the adult group for both the monaural and binaural-asymmetric conditions. In fact, variability in performance for the younger children in the monaural condition was over twice that of the adults in that same
listening condition. Post hoc power analyses indicated
that for both groups of children, our study had adequate
power (i.e., .76) to identify a 2-dB difference between
the monaural and binaural-asymmetric conditions.

Rothpletz et al.: Binaural Asymmetry

277

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

However, because of the great variability in performance
among the children, there was inadequate power (i.e.,
.45) in both age groups to identify a 1-dB difference
between these two conditions. Findings from all participants suggest that a binaural-interference effect in the
current project was small, on the order of 1 dB or less,
which was too small to detect in the two child groups. It
is possible that if larger sample sizes, different stimulus parameters (e.g., more degradation), or different
speech materials (e.g., syllables, monosyllabic words)
had been used, then a binaural interference effect might
have been detected in the performances of the children.
However, given the significant proportion of children who
demonstrated a binaural-asymmetric advantage in this
study, it is also possible that a significant interference
effect would not be seen in larger groups of children,
even under different experimental conditions.
Binaural interferences potentially may be exhibited
more in terms of perceived ease and comfort of listening
than in variations in speech recognition performance.
Surveys of individuals with symmetrical hearing losses
suggest that the use of bilateral over monaural amplification results in balanced hearing, relaxed listening, and
more natural sound quality (Erdman & Sedge, 1981).
However, less is known about these aspects of listening
when signals are asymmetrically degraded between the
two ears. Informal reports we obtained from a small
sample of adult listeners with normal hearing sensitivity revealed that although they did not rate binaural-
asymmetric listening as being significantly more difficult
than monaural listening, several listeners complained
that binaural-asymmetric listening was frustrating and
annoying.2 These types of comments suggest that future
research examining the impact of binaural asymmetry
on ease of listening may be warranted.
In this study there was a clear effect of age on speech
perception performance in all of the listening conditions.
Adults demonstrated significantly better performance
than both groups of children, and the older children
clearly outperformed the younger children in all of the
listening conditions. These differences were found even
though there were no differences between adults and
children in auditory sensitivity, as measured by puretone thresholds, and all participants achieved approximately 100% on monosyllabic word recognition tasks in
quiet. These findings are consistent with previous research that has shown that children experience greater
difficulty perceiving speech in adverse listening conditions (e.g, Eisenberg et al., 2000; Elliot, 1979; Nabelek
& Robinson, 1982). This is particularly evident when sentence materials are used, because children are not as
2

This information was obtained as part of a dissertation project of the first
author. Adult participants were asked to listen to sentences in the
monaural and binaural-asymmetric condition, rate the ease of listening,
and provide anecdotal comments.

278

skilled as adults at capitalizing on context and the linguistic rules of speech to "fill-in" what is difficult to hear.
As suggested by previous investigators, it is likely that
several sensory and nonsensory factors contribute to developmental differences in speech recognition performance. These factors include growth in vocabulary, increase in frequency of word usage, increase in phonetic
categories, better semantic and syntactic closure abilities, motivation, maturation in decision-making processes,
and improved selective attention abilities (Boothroyd,
1970; Eisenberg et al., 2000; Elliott, 1979). Casual observation of participants' responses in the current study suggested that knowledge or usage of the semantic and syntactic rules of language played a significant role in the
poorer performance of both groups of children. It was
noted that, when experiencing difficulty on the task, the
children (particularly the younger children) often responded with an incomplete sentence or nonsense words,
whereas adults typically responded with a sensible sentence, even if they were not sure of the correct response.
Finally, findings from the current study suggest that
many individuals with asymmetrical hearing loss may
not achieve binaural benefit for speech recognition. This
may have implications for the fitting of binaural amplification. One must be cautious, however, when relating
findings from this study to individuals with asymmetrical hearing loss. Even if the simulations used in the current project were perfect, these manipulations of the
speech signal cannot account for the years of experience
that one would have acquired as a listener with asymmetrical hearing loss or asymmetrical speech perception ability. Longitudinal research is needed, because
both development and experience ultimately play large
and important roles in amplification outcomes for children and adults. In the meantime, for individuals with
asymmetrical hearing loss, clinicians should make careful recommendations regarding bilateral versus monaural amplification on a case-by-case basis.

Conclusion
Although binaural hearing is largely beneficial in
most individuals when listening in background noise,
findings from the current study suggest that asymmetrical signal degradation between the two ears prevents
some listeners from capitalizing on the benefit of binaural speech understanding in noise. In addition to their
failure to achieve binaural benefit, adults performed on
average 1 dB poorer in the binaural-asymmetric condition than in the comparable monaural condition. In
contrast, children did not exhibit an overall binauralinterference effect, contrary to our original speculations.
On average, the children in this study demonstrated binaural indifference. That is, they produced no significant

Journal of Speech, Language, and Hearing Research * Vol. 47 * 269-280 * April 2004

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

Chmiel, R., Jerger, J., Murphy, E., Pirozzolo, F., &
Tooley-Young, C. (1997). Unsuccessful use of binaural
amplification by an elderly person. Journal of the American Academy of Audiology, 8, 1-10.

increment or decrement in speech recognition performance when listening binaurally to asymmetrically degraded signals (relative to listening monaurally to the
better of the two signals). The relative performance in
the binaural-asymmetric and the monaural conditions
were unrelated to which ear (right or left) received the
more degraded signal.

Davis, A., Haggard, M., & Bell, I. (1990). Magnitude of
diotic summation in speech-in-noise tasks: Performance
regions and appropriate benefits. British Journal of
Audiology, 24, 11-16.

Acknowledgments

Doyle, A. (1973). Listening to distraction: A developmental
study of selective attention. Journal of Experimental
Child Psychology, 15, 100-115.

This project was funded, in part, by a Vanderbilt
University Dissertation Enhancement Grant. We would like
to thank the review committee of the Vanderbilt University
Graduate School for providing this financial award.
We would like to thank Brian Moore of Cambridge
University for providing the computer algorithms that were
used to degrade the speech stimuli for this project. In
addition, we would like to express sincere gratitude to
Daniel Ashmead, John Grose, and Ralph Ohde for their
valuable contributions to the development and analysis of
this project as well as their helpful comments on earlier
versions of the manuscript. Finally, we thank our study
participants and their parents for their time and involvement in data collection.

References
Arbogast, T., Mason, C. R., & Kidd, G. (2002). The effect
of spatial separation on informational and energetic
masking of speech. Journal of the Acoustical Society of
America, 112, 2086-2098.
Arkebauer, H. J., Mencher, G. T., & McCall, C. (1971).
Modification of speech discrimination in patients with
binaural asymmetrical hearing loss. Journal of Speech
and Hearing Disorders, 36, 208-212.
Bess, F. H., Tharpe, A. M., & Gibler, A. M. (1986).
Auditory performance of children with unilateral sensorineural hearing loss. Ear and Hearing, 7, 20-26.

Dunn, L. M, & Dunn, L. M. (1997). Peabody Picture
Vocabulary Test-Third Edition. Circle Pines, MN: American Guidance Service.
Eisenberg, L. S., Shannon, R. V., Martinez, A. S.,
Wygonski, J., & Boothroyd, A. (2000). Speech recognition with reduced spectral cues as a function of age.
Journal of the Acoustical Society of America, 107,
2704-2710.
Elliott, L. L. (1979). Performance of children aged 9-17 on a
test of speech intelligibility in noise using sentence
material with controlled word predictability. Journal of
the Acoustical Society of America, 33, 651-653.
Elliott, L. L., Conners, S., Kille, E., Levin, S., Ball, K., &
Katz, D. (1979). Children's understanding of monosyllabic
nouns in quiet and in noise. Journal of the American
Acoustical Society, 66, 12-21.
Erdman, S., & Sedge, R. (1981). Subjective comparisons of
binaural versus monaural amplification. Ear and Hearing,
2, 225-229.
Freyman, R. L., Helfer, K. S., McCall, D. D., & Clifton,
R. K. (1999). The role of perceived spatial separation in
the unmasking of speech. Journal of the Acoustical Society
of America, 106, 3578-3588.
Fudala, J. B. (2000). Arizona Articulation Proficiency
Scale-Third Revision. Los Angeles: Western Psychological
Services.
Geffen, G. (1976). Development of hemispheric specialization for speech perception. Cortex, 12, 337-346.

Boothroyd, A. (1970). Developmental factors in speech
recognition. International Audiology, 98, 30-38.

Gelfand, S. A., & Hochberg, I. (1976). Binaural and
monaural speech discrimination under reverberation.
Audiology, 15, 72-84.

Breier, J. I., Hiscock, M., Jahrsdoerfer, R. A., & Gray, L.
(1998). Ear advantage in dichotic listening after correction
for early congenital hearing loss. Neuropsychologia, 36,
209-216.

Gelnett, D., Sumida, A., Nilsson, M., & Soli, S. D. (1995,
April). Development of the Hearing in Noise Test for
Children (HINT-C). Paper presented at the annual meeting
of the American Academy of Audiology, Dallas, TX.

Bronkhorst, A. W. (2000). The cocktail party phenomenon:
A review of research in speech intelligibility in multitalker conditions. Acustica/Acta Acustica, 86, 117-128.

Haskins, H. (1949). A phonetically balanced test of speech
discrimination for children. Unpublished master's thesis,
Northwestern University, Evanston, IL.

Bronkhorst, A. W., & Plomp, R. (1988). The effect of headinduced interaural time and level differences on speech
intelligibility in noise. Journal of the Acoustical Society of
America, 83, 1508-1516.

Hawley, M. L., Litovsky, R. Y., & Colburn, H. S. (1999).
Speech intelligibility and localization in a multi-source
environment. Journal of the Acoustical Society of America,
105, 3436-3448.

Carter, A. S., Noe, C. M., & Wilson, R. H. (2001). Listeners
who prefer monaural to binaural hearing aids. Journal of
the American Academy of Audiology, 12, 261-272.

Hicks, C., & Tharpe, A. M. (2002). Listening effort and
fatigue in school-age children with and without hearing
loss. Journal of Speech, Language, and Hearing Research,
45, 573-584.

Ching, T. Y. C., Psarros, C., Hill, M., Dillon, H., &
Incerti, P. (2001). Should children who use cochlear
implants wear hearing aids in the opposite ear? Ear and
Hearing, 22, 365-380.

Hiscock, M., & Chipuer, H. (1993). Children's ability to
shift attention from one ear to the other: Divergent results
for dichotic and monaural stimuli. Neuropsychologia, 31,
1339-1350.

Rothpletz et al.: Binaural Asymmetry

279

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

Hood, J., & Prasher, D. (1990). Effect of simulated
bilateral cochlear distortion on speech discrimination in
normal participants. Scandinavian Audiology, 19, 37-41.

Moore, B. C. J., & Glasberg, B. R. (1997). A model of
loudness perception applied to cochlear hearing loss.
Auditory Neuroscience, 3, 289-311.

Humes, L. E., Allen, S. K., & Bess, F. H. (1980). Horizontal
sound localization skills of unilaterally hearing impaired
children. Audiology, 19, 508-518.

Morris, R., Bakker, D., Satz, P., & Van der Vlugt, H.
(1984). Dichotic listening ear asymmetry: Patterns of
longitudinal development. Brain and Language, 22,
49-66.

Jensen, J. H., Borre, S., & Johansen, P. A. (1989).
Unilateral sensorineural hearing loss in children: Cognitive abilities with respect to right/left ear differences.
British Journal of Audiology, 23, 215-220.
Jensen, J. H., Johansen, P. A., & Borre, S. (1989).
Unilateral sensorineural hearing loss in children and
auditory performance with respect to right/left ear
differences. British Journal of Audiology, 23, 207-213.
Jerger, J., Silman, S., Lew, H. L., & Chmiel, R. (1993).
Case studies in binaural interference: Converging evidence
from behavioral and electrophysiologic measures. Journal
of the American Academy of Audiology, 4, 122-131.

Nabelek, A., & Robinson, P. (1982). Monaural and
binaural speech perception in reverberation for listeners
of various ages. Journal of the Acoustical Society of
America, 71, 1242-1248.
Newton, V. E. (1983). Sound localization in children with
severe unilateral hearing loss. Audiology, 22, 189-198.
Nilsson, M., Soli, S., & Sumida, A. (1996, February). A
definition of normal binaural sentence recognition in quiet
and noise [Internal Report]. House Ear Institute.

Kandell, E. R., Schwartz, J. H., & Jessel, T. M. (1991).
Principles of neuroscience. New York: Elsevier.

Ohde, R. O., & Sharf, D. L. (1988). Perceptual categorization and consistency of synthesized /r-w/ continua by
adults, normal children and /r/-misarticulating children.
Journal of Speech and Hearing Research, 31, 556-568.

Karsten, S. A., & Turner, C. W. (2000). Binaural speech
recognition and the Stenger effect. Journal of Speech,
Language, and Hearing Research, 43, 926-933.

Plomp, R., & Mimpen, A. M. (1979). Improving the
reliability of testing the speech reception thresholds for
sentences. Audiology, 18, 43-52.

Keppel, G. (1991). Design and analysis. A researcher's
handbook (3rd ed.). Englewood Cliffs, NJ: Prentice Hall.

Rasmussen, T., & Milner, B. (1977). The role of early left
brain injury in determining lateralization of cerebral
speech functions. Annals of the New York Academy of
Science, 299, 355-369.

Kidd, G., Mason, C. R., Rohtla, T. L., & Deliwala, P. S.
(1998). Release from masking due to spatial separation of
sources in the identification of nonspeech auditory
pattern. Journal of the Acoustical Society of America, 104,
422-431.
Konkle, D., & Schwartz, D. M. (1981). Binaural amplification: A paradox. In F. H. Bess, B. A. Freeman, & S.
Sinclair (Eds.), Amplification in education (pp. 342-357).
Washington, DC: Alexander Graham Bell Association for
the Deaf.
Lane, D. M., & Pearson, D. A. (1982). The development of
selective attention. Merrill-Palmer Quarterly, 28, 317-337.
Levitt, H., & Rabiner, L. R. (1967). Binaural release from
masking for speech and gain intelligibility. Journal of the
Acoustical Society of America, 42, 601-608.
Licklider, J. (1948). The influence of interaural phase
relations upon the masking of speech by white noise.
Journal of the Acoustical Society of America, 20, 150-159.
Loring, D. W., Meador, K. J., Lee, G. P., Murro, A. M.,
Smith, J. R., Flaningin, H. F., et al. (1990). Cerebral
language lateralization: Evidence from intracarotid
amobarbital testing. Neuropsychologia, 28, 831-838.
MacKeith, N. W., & Coles, R. R. A. (1971). Binaural
advantages in hearing of speech. Journal of Laryngology
and Otology, 85, 213-232.
The Mathworks, Inc. (2002). MATLAB (Version 6.1)
[Computer software]. Natick, MA: Author.
McCullough, J. A., & Abbas, P. J. (1992). Effects of
interaural speech recognition differences on binaural
advantage for speech in noise. Journal of the American
Academy of Audiology, 3, 255-261.
Miller, G. A. (1947). The masking of speech. Psychological
Bulletin, 44, 105-129.
Moore, B. C. J. (1998). Cochlear hearing loss. London:
Whurr Publishers.

280

Scharf, B. (1968). Binaural loudness summation as a
function of bandwidth. Reports of the International
Congress on Acoustics, 25-28.
Shinn-Cunningham, B., Schickler, J., Kopc*o, N., &
Litovsky, R. (2001). Spatial unmasking of nearby speech
sources in a simulated anechoic environment. Journal of
the Acoustical Society of America, 110, 1118-1129.
Tillman, T., & Carhart, R. (1966). An expanded test for
speech discrimination utilizing CNC monosyllabic words
(Northwestern University Auditory Test No. 6; Technical
Report No. SAM-TR-66-55). Brooks Air Force Base, TX
USAF School of Aerospace Medicine, Aerospace Medical
Division (AFSC).
Tyler, R. S., Parkinson, H. J., Wilson, B. S., Witt, S.,
Preece, J. P., & Noble, W. (2002). Patients utilizing a
hearing aid and cochlear implant: Speech perception and
localization. Ear and Hearing, 23, 98-105.
Woods, R. P., Dodrill, C. B., & Ojemann, G. A. (1988).
Brain injury, handedness, and speech lateralization in a
series of amobarbital studies. Annals of Neurology, 23,
510-518.
Zurek, P. M. (1993). Binaural advantages and directional
effects in speech intelligibility. In G. A. Studebaker & I.
Hochberg (Eds.), Acoustical factors affecting hearing aid
performance (2nd ed., pp. 255-275). Boston: Allyn & Bacon.
Received April 7, 2003
Accepted October 8, 2003
DOI: 10.1044/1092-4388(2004/022)
Contact author: Ann Rothpletz, PhD, Department of Speech/
Language and Hearing Sciences, University of Colorado at
Boulder, Campus Box 409, Boulder, CO 80309-0409.
E-mail: ann.rothpletz@colorado.edu

Journal of Speech, Language, and Hearing Research * Vol. 47 * 269-280 * April 2004

Downloaded from: https://pubs.asha.org Bibliotheek Der Rijksuniversiteit on 03/15/2025, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions

