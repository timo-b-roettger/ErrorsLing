Speech, Language and Hearing

ISSN: 2050-571X (Print) 2050-5728 (Online) Journal homepage: www.tandfonline.com/journals/yslh20

Using Rasch analysis to examine the item-level
psychometrics of the Infant-Toddler Meaningful Auditory
Integration Scales
Brittan A. Barker, Neila J. Donovan, Anne D. Schubert & Elizabeth A. Walker
To cite this article: Brittan A. Barker, Neila J. Donovan, Anne D. Schubert & Elizabeth A. Walker
(2017) Using Rasch analysis to examine the item-level psychometrics of the Infant-Toddler
Meaningful Auditory Integration Scales , Speech, Language and Hearing, 20:3, 130-143, DOI:
10.1080/2050571X.2016.1243747
To link to this article: https://doi.org/10.1080/2050571X.2016.1243747

Published online: 17 Oct 2016.

Submit your article to this journal

Article views: 193

View related articles

View Crossmark data

Citing articles: 1 View citing articles

Full Terms & Conditions of access and use can be found at
https://www.tandfonline.com/action/journalInformation?journalCode=yslh20

Using Rasch analysis to examine the
item-level psychometrics of the Infant-Toddler
Meaningful Auditory Integration Scales
Brittan A. Barker1 , Neila J. Donovan1 , Anne D. Schubert 1,
Elizabeth A. Walker 2
1

Department of Communication Disorders, Louisiana State University, Baton Rouge, LA, USA, 2Department of
Communication Disorders, University of Iowa, Iowa City, IA, USA

The Infant-Toddler Meaningful Auditory Integration Scales (IT-MAIS; Zimmerman-Phillips, S., Osberger, M.J.,
Robbins, A.M. 2001. Infant-toddler meaningful auditory integration scale. Sylmar, CA: Advanced Bionics
Corporation) is a popular assessment designed to measure listening skills in children with hearing loss
aged 0-3 years. For this study we analyzed the item-level psychometric properties of the IT-MAIS via
Rasch analysis to gain further understanding about its validity and reliability. We chose to analyze the
psychometric properties of the IT-MAIS because very little information exists regarding its development
and validation, although it is widely used to assess listening skills in children with sensorineural hearing
loss ages 0-3 years pre- and post-cochlear implant (CI). Our results indicated that the IT-MAIS items
demonstrated less than ideal psychometric properties and the IT-MAIS item order did not reflect the order
in which children are expected to develop functional listening skills. Our findings suggest that there is a
pressing need for further discussion among researchers and clinicians about (1) how the IT-MAIS is used,
and (2) what other valid and reliable outcome measures could be used alongside, or in place of, the
IT-MAIS to determine CI candidacy, establish treatment goals, or track progress in listening development
in very young children with hearing loss.
Keywords: Validity, Reliability, Rasch analysis, Children, Cochlear implants, Infant-Toddler Meaningful Auditory Integration Scale, Infants, Toddlers, Hearing
loss

The pediatric cochlear implant (CI) candidacy evaluation for very young children includes a battery of
testing to ensure medical and audiometric suitability.
The Infant-Toddler Meaningful Auditory Integration
Scale (IT-MAIS; Zimmerman-Phillips et al., 2001) is
a caregiver-report tool often included in this battery.
Specifically, the IT-MAIS is used to assess and
monitor functional listening pre- and post-CI in children aged 0-3 years with sensorineural hearing loss
(SNHL). Despite the fact that the IT-MAIS is the
most frequently administered caregiver-report questionnaire by pediatric CI professionals in the USA
(Uhler and Gifford, 2014), little research to date examined its validity and reliability (Zheng et al., 2009;
Zimmerman-Phillips et al., 2000). As our profession
advances, it has become increasingly important that
researchers and clinicians are knowledgeable consumers who can select the most appropriate assessment
to inform their evidence-based practice. Part of this
Correspondence to: Brittan A. Barker, Department of Communicative
Disorders and Deaf Education, Utah State University, 2620 Old Main Hill,
Logan, UT 84322-2620, USA.
Email: brittan.barker@usu.edu

130

(c) 2016 Informa UK Limited, trading as Taylor & Francis Group
DOI 10.1080/2050571X.2016.1243747

knowledge comes from determining not only how an
assessment was developed, but also its validity and
reliability (Dollaghan, 2007). Based on the limits of
the existing literature, we propose it is important to
further explore the psychometric properties of the
IT-MAIS and provide researchers and clinicians with
additional information when making decisions about
using the IT-MAIS in their research and clinical
practice.

The IT-MAIS
Across the globe, a number of pediatric CI research
and clinical programs use the IT-MAIS to help determine CI candidacy and track listening development
post-implantation in children with SNHL (e.g.
Barker et al., 2011; Cardon and Sharma, 2013). The
IT-MAIS includes 10 questions developed to
measure a child's ability to vocalize, alert to sounds,
and derive meaning from sound (ZimmermanPhillips et al., 2001). Via interview format, an experienced pediatric audiologist elicits responses from a
parent/guardian about aspects of their child's

Speech, Language and Hearing

2017

VOL.

20

NO.

3

Barker et al.

auditory development. The IT-MAIS instructions
encourage the administrating audiologist to use a `flexible' interview format to elicit optimal responses. The
caregiver's responses are then rated on a 0-4 Likert
scale reflecting the frequency of the child's behaviors
(0/never, 1/rarely, 2/occasionally, 3/frequently, 4/
always). The IT-MAIS is a criterion-referenced assessment - an assessment that provides a basis for determining an individual's skill level relative to a
theoretically motivated and operationally defined
domain of content.
The IT-MAIS was derived from the Meaningful
Auditory Integration Scales (MAIS;Robbins et al.,
1991) designed to evaluate meaningful use of sound
in children with profound SNHL aged 5 years and
older. Zimmerman-Phillips et al. (2000) revised the
MAIS for children aged 0-3 years old. During the revision, they replaced 2 MAIS items related to device
bonding with 2 items related to vocalizations, behavioral markers often associated with listening development in children with CIs (Ertmer and Jung, 2012).
The authors retained the remaining 8 MAIS items
originally identified as skills demonstrated by children
5 years and older and included them in the IT-MAIS.

IT-MAIS standardization
After development of the IT-MAIS, ZimmermanPhillips et al. (2000) validated the tool via a study
that assessed the overall scores of nine children, 18-
23 months old, based on IT-MAIS scores obtained
during pre-CI, hearing-aid trials, and again at 3
months post-CI. Pre-CI the majority of children
received scores of 0/never on all items, indicating
that the caregivers never witnessed any of the listening
or vocalization behaviors. At 3 months post-CI, all
caregivers reported an increase in frequency for at
least 7 out of 10 items' behaviors. The researchers concluded that the increases noted from pre- to post-CI
demonstrated that the IT-MAIS was a valuable tool
to measure CI candidacy and benefit. However, their
results should be interpreted with caution due to the
small sample size (N = 9), which may reflect
inadequate representation of the pediatric population
(age 0-3 years) with severe-profound SNHL.
Furthermore, considering the 3-month time lapse
between pre-CI and post-CI assessments in their
study, there is no way to know from their data
whether the increased frequency of behaviors represented post-CI benefit or typical cognitive and physical development.
Since Zimmerman-Phillips et al. (2000) validation,
no one to date has further explored the validity or
reliability of the IT-MAIS. However, two studies did
attempt to develop norms for the IT-MAIS based on
performance of children with normal hearing
(Kishon-Rabin et al., 2001; Zheng et al., 2009).

Item-level psychometrics of the IT-MAIS

Kishon-Rabin et al. established developmental
norms for the IT-MAIS based on evaluations of 109
Hebrew- and Arabic-speaking children with normal
hearing while Zheng et al. (2009) administered an
IT-MAIS translated into Mandarin-Chinese to 120
Chinese children with normal hearing thresholds,
and with native Mandarin-speaking caregivers.
Although their sample sizes are remarkable, and the
results shed light on listening development in infants
and toddlers with normal-hearing thresholds, it is difficult to generalize these data to infants and toddlers
with severe to profound SNHL who are brought up
in families utilizing spoken English.
The IT-MAIS, nonetheless, appears to have face
validity since it is widely used to establish treatment
goals and track listening development in pediatric CI
users over time (Uhler and Gifford, 2014). However,
without an operational definition of the theoretical
construct the IT-MAIS is assessing, it is difficult to
determine the assessment's validity beyond face
value. The risk of using an assessment that is not
valid or reliable could result in clinical providers
making intervention decisions based on erroneous or
missing information, thus limiting opportunities for
intervention. We propose that additional psychometric
analysis of the IT-MAIS could provide useful and
needed information to assist clinicians and researchers
in making assessment choices for very young children
with SNHL.
Since the IT-MAIS was initially validated in
Zimmerman-Phillips et al. (2000) researchers are
using a new type of psychometric analysis - item
response theory (IRT) - to develop new assessments
and analyze existing ones (Engelhard, 2013). In the
following sections, we provide our rational for using
IRT to analyze the IT-MAIS based on a sample of
infant and toddler CI users and an overview of what
the analysis entails.1

Item response theory
Historically researchers used classical test theory
(CTT) to establish the psychometric properties of
assessments' validity and reliability. However,
researchers in the field of education have used IRT
modeling (Lord and Novick, 1968) for the past four
decades to develop assessments and analyze the psychometric properties of existing assessments
(Engelhard, 2013). Researchers are particularly motivated to use IRT because the resulting data provide
information about the assessment at the item level.
This is a benefit that cannot be obtained using CTT
(Wright and Stone, 1999) because it provides
1

We simplified the statistical explanation for the current readership. For a
thorough discussion on the topic please see the tutorial written for those
in the field of Communication Sciences and Disorders by Baylor et al.
(2011).

Speech, Language and Hearing

2017

VOL.

20

NO.

3

131

Barker et al.

Item-level psychometrics of the IT-MAIS

information at the level of the overall test in its
entirety. CTT was the previous methodology used to
validate the IT-MAIS (e.g. Zheng et al., 2009). For
this study we echoed the choice of others in the field
of audiology (Ng et al., 2016) and used Rasch analysis
(Rasch 1960/1980) - one model based on IRT - to
further explore the psychometric properties of the
IT-MAIS.
Measuring a latent trait
IRT, also referred to as latent trait theory, is a paradigm used to design assessments with an emphasis
on ensuring accurate test scoring and item development (An and Yung, 2014). A latent trait is an underlying behavior that can be intuitively understood, but
not directly observable (e.g. intelligence; Baker,
1985) and must be inferred based on a theoretically
driven set of behaviors that represent the latent trait
(Wright and Stone, 1999). For the purposes of the
present study, we named the latent trait measured by
the IT-MAIS listening development. We operationally
defined listening development as the hierarchical
acquisition of sound detection, discrimination, identification, and comprehension, based on Erber's (1982)
levels of listening.
IRT models can be one-dimensional or multidimensional. The model's delineation is based on the number
of parameters a researcher wishes to investigate and
model (Lord and Novick, 1968); much of the research
in the field of IRT employs one-dimensional models.
For such one-dimensional models - referred to as a
1-parameter logistic (1-PL) IRT model - item difficulty is modeled based on person ability. At its most
basic, one type of IRT model (Rasch analysis) converts ordinal data into interval data, and transforms
person ability and item difficulty along a single interval scale. The benefits of this type of scaling are
described below.
Rasch analysis
We chose Rasch analysis to assess the item-level psychometric properties of our longitudinal data derived
from the IT-MAIS because we were most interested
in understanding the difficulty hierarchy of the
IT-MAIS items based on the sample's individual
ability levels. Rasch analysis is also a logical choice
for those working with low incidence populations
(e.g. infants and toddlers with CIs) because it
allows a researcher to study the item-level psychometric properties of an assessment using a smaller
sample size (50-100 data points) than is required by
the more complex IRT models (Linacre, 1994).
More recently Chen et al. (2014) reported that
Rasch analysis of samples between 30 and 50 participants showed robust item fit which led them to
suggest that Rasch analysis could be used in the

132

Speech, Language and Hearing

2017

VOL.

20

NO.

3

case of rare diseases (i.e. low incidence populations
such as pediatric CI users).
Rasch analysis also provides valuable information
that cannot be gleaned from CTT, by transforming
ordinal data into interval data rather than summing
raw scores or reporting percent correct. Rasch is
based on probabilistic modeling that a person of
average ability will be able to perform an item of
average difficulty 50% of the time. After much iteration the data are transformed into an interval scale
along which person ability and item difficulty are calibrated. The result is an objective scale of a latent trait
scale much as the ruler is an objective measure of
length. The ruler is an interval scale where the units
of measure are arranged smallest to largest. The unit
of measure - the inch - is invariant; meaning the
size of the unit is equal to every point along the
ruler. Furthermore, units on an interval scale are additive. Therefore, for example, if one knows an object is
3 long, they know it is more than 1 long and less than
6 long. Objective measures are also sample free;
meaning that one can measure the length of anything,
not just specific items. Consider how assessments
developed using the probabilistic modeling of Rasch
analysis differs from assessments developed using
CTT, where entire tests must be given to obtain
scores, and scores on one test will not necessarily be
obtained on a different test.
Finally, some researchers propose that Rasch analysis provides more clinical utility than CTT because the
interval scale describes the latent trait ability as
specific, observable behaviors, plotted along an item
difficulty hierarchy. The item difficulty calibrated
along the interval scale provides researchers and clinicians the ability to quantify change, compare a
patient's performance on a given set of items at different time points (e.g. pre- and post-CI), or to compare
one patient's performance to another at the same time
point in a meaningful way. For the most part,
summing raw scores or deriving percentages correct,
as done in CTT, does not provide the same information (Engelhard, 2013).
We propose that using Rasch analysis to assess the
item-level psychometric properties of the IT-MAIS is
a logical first step toward better understanding how
well the IT-MAIS assesses listening development in
young children who are deaf and use CIs. Rasch analysis is an IRT methodology that lends itself to investigating the item level psychometric properties of
existing assessments with small sample sizes. Rasch
analysis also produces an objective measure of a
latent trait (i.e. listening development) which can
provide useful information to researchers and clinicians who work with infants and toddlers pre- and
post-CI. By answering the following experimental
questions we will understand more about the validity,

Barker et al.

reliability and sensitivity of the IT-MAIS, as well as
how it conforms to our operationally defined trait - listening development.
1. Does the IT-MAIS data meet the assumptions for
Rasch analysis (i.e. unidimensionality and local
independence)?
2. Does the IT-MAIS demonstrate item-level psychometric properties to adequately measure the latent
trait: listening development?
3. Does the IT-MAIS separate the participating children into more than two levels of ability to adequately identify different functional levels of
performance?
4. Does the Rasch-modeled IT-MAIS item difficulty
hierarchy conform to the theoretical item difficulty
hierarchy established a priori?

Materials and methods
Participants
Parents of 23 CI users aged 10-36 months and receiving services from the University of Iowa Children's CI
Program completed the IT-MAIS during regular visits
to the Center for their children's CI candidacy assessments and post-CI care. All 23 children (12 male, 11
female) children were born to parents with normal
hearing, and were identified with severe to profound
bilateral SNHL within the first year of life. All
parents reported spoken, American English as the
primary language used at home. See Table 1 for the
children's demographic data.

Assessment
Pediatric CI audiologists administered the IT-MAIS to
each parent at least twice (once pre-CI and once postCI), and most children were assessed additional times
post-CI. Assessment interims ranged from 1 month to
1 year, according to scheduled administration at
2-month intervals during the first year after CI stimulation, then at 6-month intervals until 3 years post-CI.
The actual intervals between assessment dates varied
due primarily to missed visits and scheduling conflicts.
See Fig. 1 for each participant's schedule of repeated
measures. Using these repeated measures, we analyzed
a sample of 56 data points collected from the 23
parents.2 The rationale for this analysis is discussed
in the next section.
During IT-MAIS administration, the audiologist
asked/explained each question and recorded the
parents' responses on the designated response forms.
The audiologist interpreted each parent's answer by
using a Likert scale ranging from 0 (never) to 4
(always) for each question, regardless of the child's
communication modality and the absence/presence
Rasch analysis is considered ideal for analysis for small samples (N =
50-100). We anchored the initial 23 scores according to Rasch methods
and by so doing; the other 33 ratings are considered individual ratings
during the probabilistic iterations used to estimate the model (Mallinson,
2011). Our results are thus based on 56 person-level entries.
2

Item-level psychometrics of the IT-MAIS

of a listening device(s). If the question was unclear to
the parent, the audiologist was permitted to recast
the question using probes with alternative wording
provided by the IT-MAIS. Finally, the audiologist
who administered the IT-MAIS scored the IT-MAIS
after its completion.

Psychometric analyses
Exploratory factor analysis
Two assumptions - unidimensionality and local independence - must be met to perform Rasch analysis
(Wright and Linacre, 1989). To test the assumption
of unidimensionality prior to conducting Rasch analysis, we conducted an exploratory factor analysis
(EFA). Factor extraction was established at a
minimum eigenvalue > 1.0,  = .05. To meet the
local independence assumption, we transformed the
inter-item residual correlations into Fisher's z scores.
In that form, we characterized local independence
among items as 5% of the non-significant pairs
with correlations 2 SD from the mean (Smith, 2005).
Rasch analysis
We employed the Rasch polytomous rating scale using
WINSTEPS 7.5 (Linacre, 2010). The Rasch polytomous formula models the relationship between a participant's ability (i.e. trait level) and the probability
of choosing each response category (i.e. 0-4 Likert
scale of the IT-MAIS) for each item. The Rasch
model for polytomous rating scales is represented by
the following formula (Linacre, 1994):
Log(Pnik /Pni(k-1) )Bn - Di - Fk
where Pnik, the probability that person n, on encountering item I would respond (or be observed) in category k; Pni(k-1), the probability that the response
(or observation) would be in category k-1; Bn,
ability of person n; Di, difficulty of item i; Fk, a
rating scale threshold defined as the location corresponding to the equal probability of observing adjacent categories k-1 and k.
Recall that Rasch analysis permits a researcher to
examine individual items on an assessment at the
level of item difficulty and person ability rather than
at the total test score level.
The following paragraphs describe the various itemlevel psychometric information derived from Rasch
analysis used to address our research questions and
how they relate to traditional validity and reliability
terminology used in CTT.
Item infit statistics
When developing an assessment it is critical that the
questions/items are appropriate for the participants'
ability levels. In other words, do the items capture or
`fit' the behaviors of the latent trait they were
Speech, Language and Hearing

2017

VOL.

20

NO.

3

133

Barker et al.

Item-level psychometrics of the IT-MAIS

Table 1

Demographic data for the 23 pediatric CI users

ID

M/
F

Age at HL

Age at CI

CI device type

Strategy

CI
ear

HA use

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

M
F
M
M
M
M
F
F
F
M
M
F
M
F
F

0
0
0
0
0
0
0
0
0
0
0
0

11
13
12
16
14
14
12
22
13
16
13
13
12
13
9

Nucleus CI 24 RE(CA)
Nucleus CI 24 RE(CA)
Nucleus CI 24 RE(CA)
Nucleus CI 24 RE(CA)
Nucleus CI 24 RE(CA)
Nucleus CI 24 RE(CA)
Nucleus CI 24 RE(CA)
Nucleus CI 24 RE(CA)
Nucleus CI 24 RE(CA)
Nucleus CI 24 RE(CA)
Nucleus CI 24 RE(CA)
Nucleus CI 24 RE(CA)
Clarion HiRes 90K
Nucleus CI 24 RE(CA)
Nucleus CI 512(CA)

ACE
ACE
ACE
ACE
ACE
ACE
HiRes
ACE
ACE
ACE
ACE
ACE
HiRes
ACE
ACE

B
B
B
B
B
B
B
L
B
B
B
B
B
B
B

None
B 11
B6
B 10
B7
B 11
B5
None
B 12
None
B6

16
17
18
19
20
21
22
23

F
F
M
M
F
M
M
F

0
2
0
0
0

13
13
13
14
13
12
20
17

Nucleus CI 24 R(CA)
Nucleus CI 24 RE(CA)
Nucleus CI 24 RE(CA)
Nucleus CI 512(CA)
Clarion HiRes 90K
Nucleus CI 512(CA)
Nucleus CI 24 R(CA)
Nucleus CI 24 R(CA)

ACE
ACE
ACE
ACE
HiRes
ACE
ACE
ACE

B
B
B
B
B
B
R
B

B5
B 11
B7
B 10
B 14
B 11

HL
etiology
Waardenburg Syndrome
CMV
Hereditary (unspecified)
Auditory Neuropothy
Unknown
Unknown
Unknown
CMV
CMV
Unknown
Unknown
Jervell Lange-Nielsen
Syndrome
Unknown
Connexin 26
Unknown
Unknown
-

Mother's ed
coll
post-grad
HS
coll
post-grad
post-grad
coll
coll
post-grad
coll
HS+
HS+
coll
coll

Note: ID = participant identification number; M/F = male or female; age at HL = participant's age when diagnosed with bilateral
hearing loss (months); age at CI = participants' age at time of CI implantation (months); CI device type = cochlear implant device(s)
used by the participant; strategy = CI processing strategy; CI ear = implanted ear (R = right CI, L = left CI, B = bilateral CIs); CI
use = amount of time the participant used his/her CI relative to the time at testing (years; months); HA use = hearing aid use prior to
implantation (months; R = right HA, L = left HA, B = bilateral HAs); HL etiology = hearing loss etiology (CMV = Cytomegalovirus,
unknown = genetic testing completed but inconclusive); mother's ed = highest level of education self-reported from mother (HS =
high school diploma, HS+ = some college classes, coll = college degree, post-grad = post-graduate degree); - no information

misfitting items and rerun Rasch analysis until all
items fell within the established infit criteria.

Figure 1 Number and time of IT-MAIS observations
gathered from each participant. On the y-axis, each child is
represented by a single tick mark. Time is represented on the
x-axis and is measured relative to the number of months
following initial stimulation of each child's device.

developed to measure? Item fit statistics are used to
determine whether individual test items fit the proposed Rasch model.
The ideal infit statistic would be 1.0, indicating that
the Rasch-modeled responses and the actual responses
on the assessment matched perfectly. For this study, we
chose to employ a common mean square infit statistic
range of 1.4-0.6 with standardized z-scores >2.0; a
range frequently used in heathcare research (Wright
and Linacre, 1994). For our analysis, we removed

134

Speech, Language and Hearing

2017

VOL.

20

NO.

3

Item difficulty hierarchy
Since the IT-MAIS is used to document listening skill
development in young children with SNHL, we also
wanted to examine the IT-MAIS' item difficulty hierarchy. Ideally, if the item hierarchy represents a full
range of ability (i.e. from most severely impaired listening ability to normal listening ability), floor or
ceiling effects will be 10% and the items will typically
range from -2 to +2 logits.3 The logit is the interval
scale unit of measure along the interval scale that
results from Rasch analysis. It comes from a specific
calculation, but can be thought of as the inch on the
ruler example we presented in the introduction.
Therefore, for a well-developed measure the listening
development we would have items that are very easy
for the most impaired respondents and very hard for
the least impaired.
Item mean/person mean
Comparing the item M to the person M provides an
indicator of internal consistency. When the 2
3

The logit is the interval unit of measurement used in Rasch analysis. It represents the relative differences between person ability and item difficulty
that results during the log-odds transformation of the data based of the
natural logarithm. The logit is calculated at 2.718 (Wright and Stone,
1999).

Barker et al.

calibrated Ms have similar measures (i.e. 0 logits) it
indicates that the items' difficulty hierarchy captured
the range of person ability. In other words, we have
items that capture everyone's ability levels. For this
study an acceptable item M/person M match was set
as the actual item M/person M (1 SD; Wright and
Stone, 1999). Note the item difficulty M will always
be 0, which is the set point for Rasch modeling,
defined as the probability of a person of average
ability being able to complete an item of average difficulty 50% of the time (Wright and Stone).
Rating scale analysis
Because parents may reply to ordinal rating scales in
unpredictable ways, depending on their understanding
of the question, or the audiologist's interpretation of
the IT-MAIS' recommended `flexible interview
format' (Zimmerman-Phillips et al., 2001), we
employed rating scale analysis to determine whether
parents used the IT-MAIS 0-4 Likert rating scale in
a predictable way. Three criteria were established to
assess the stability of the IT-MAIS rating scale
system: (1) each rating category had to contain 10
observations; (2) the categories had to advance in a
step-wise fashion from lowest to highest, and (3)
outfit (i.e. outlier-sensitive fit) mean square < 2. If
the IT-MAIS' 0-4 rating scale met the established criteria, it would demonstrate that the parents were using
the 0-4 units in the way the developers intended
(Linacre, 2002). If the scale failed to meet the established criteria, it would indicate that parents were
not sensitive to some of the unit delineations, and
the rating scale could be collapsed to better reflect
how the parents used the units (Linacre).
Person reliability
The person reliability statistic is comparable to
Cronbach's , a measure of reliability reported in
CTT. Cronbach's  reflects a measure of the relationship among test items. Thus, a high Cronbach's 
would suggest that items have a close relationship
and should be included in the same set. An acceptable
Cronbach's  is in the range of 0.8-1.0. We established
an acceptable person reliability statistic as 0.8.
Person separation
The person separation index is similar to the concept
of sensitivity in CTT (i.e. can a test correctly identify
the person with the problem). In Rasch analysis, the
person separation index represents an estimate of
how reliably people responded to the questions based
on their ability levels and indicates the number of
different ability levels represented by the sample, in
this case, different levels of listening development. A
separation index >2 would indicate the IT-MAIS
reliably separated children into at least 3 statistically
different ability levels. A separation index 2 would

Item-level psychometrics of the IT-MAIS

indicate that the IT-MAIS items do not separate children into different levels of ability, thus it would not be
particularly sensitive to ability levels.
Content validity
Finally, we established an a priori item hierarchy
ranking to be compared to the final Rasch-modeled
item hierarchy to determine the content validity of
the IT-MAIS. This analysis is important because pediatric CI programs often use the IT-MAIS to measure
progress from pre- to post-CI, as if the assessment
were organized in accordance with order of acquisition. However, the IT-MAIS authors do not report
the assessment to be based on order of skill acquisition. Four graduate-level students studying communication sciences and disorders rank ordered the
10 IT-MAIS items based on their clinical experience
and theoretical knowledge of listening development.
All four students completed an undergraduate course
in pediatric aural rehabilitation and had clinical
experience with at least one pediatric CI user, but
were not familiar with the IT-MAIS questions.
Spearman's Rank Order correlation was used to determine the relationships among the raters' rankings
using SPSS (IBM Corp., 2013).

Results
Question 1: Does the IT-MAIS data meet the
assumptions for Rasch analysis?
First, we tested for adequate sample size using SPSS
and the Kaiser-Meyer-Olkin value. The Kaiser-
Meyer-Olkin value for the present data was 0.925
(`superb' according to Field, 2009), indicating that
we had an adequate sample to complete the EFA.
Bartlett's test of sphericity indicated that correlation
between items was sufficiently large for EFA [ 2 (45)
= 512.005, p < 0.001]. Extraction was completed for
eigenvalues > 1 with 25 iterations for convergence.
The scree plot in Fig. 2 illustrates that only one
factor (listening development) accounted for 71.36%

Figure 2 Scree plot demonstrating no points of inflection;
thus indicating there was only one factor (listening
development).

Speech, Language and Hearing

2017

VOL.

20

NO.

3

135

Barker et al.

Item-level psychometrics of the IT-MAIS

of the variance for the 10 items. We concluded that the
IT-MAIS items demonstrate unidimensionality and
met the assumptions for Rasch analysis.
Table 2 presents correlation coefficients between
each IT-MAIS item. Ideally, correlation coefficients
should be within the range of 0.3-0.9. Based on
these criteria, the correlation coefficients for the ITMAIS items were sound. We tested local independence
(i.e. no item responses are dependent on responses to
other items) by transforming inter-item residuals
(differences between observed and expected responses)
to standardized units using Fisher's z-transformation
procedure (Smith, 2005). Fisher's z-transformed
inter-item residual correlations indicated the items
demonstrated local independence based on a range
of z scores from -0.173 to +0.120 (Table 3), well
within the established criteria z  2.0. This test confirmed that our data met the second assumption for
performing Rasch analysis.

Question 2: Does the IT-MAIS demonstrate itemlevel psychometric properties to adequately
measure the latent trait (listening
development)?
The following results provided the information needed
to answer Question 2.
Item misfit
Based on misfit criteria (mean square within the range
of 0.6-1.4; z > 2.0) the results showed that item 1 [Is
the child's vocal behavior affected while wearing his/
her sensory aid (hearing aid or cochlear implant)?]
and item 10 [Does the child spontaneously associate
vocal tone (anger, excitement, anxiety) with its
meaning based on hearing alone?] exceeded these criteria. These results demonstrated that parents did not
respond predictably to the 2 items. We eliminated the
2 misfitting items and completed all subsequent
model estimates based on the 8 items that demonstrated acceptable infit criteria (see Table 4).
Person misfit
Person misfit is based on a series of iterations that
Rasch analysis computes in accordance with parents'
responses to other items around their children's
ability levels. We adopted the same misfit criteria for
persons that we used for items (1.4  mean square <
0.6; z > 2.0). Table 5 presents data from parents who
did not predictably respond to the IT-MAIS items
that were close to their children's predicted ability
levels. During initial analysis of an instrument, misfitting items and persons may be retained or deleted
depending on the researcher's needs (Wright, 1999).
Because this was a preliminary exploration of the ITMAIS, we retained all data, as we had no way of
knowing why these parents might have responded as
they did. For example, parents may have responded

136

Speech, Language and Hearing

2017

VOL.

20

NO.

3

unpredictably due to different audiologists using
different examples to elicit responses. Parents may
have responded unpredictably if they had a weak
understanding of their child's listening behaviors and
guessed on a question, but later answered that question
differently and more in line with the child's ability.
Lastly, it is possible that the IT-MAIS questions are
not well worded or do not reflect observable behaviors
parents could easily identify.
Visual representation of Rasch analysis (person-item
map)
Results showed that many of the IT-MAIS items
measured functional listening skills at the same level of
difficulty as other items. They also showed that children's listening skills measured pre-CI were significantly
lower than children's skills post-CI. In other words, the
analyses showed that the item difficulty range was
smaller than the person ability range (Fig. 3), indicating
that more difficult items are needed to assess the full
range of the children's functional listening abilities.
Fig. 3 shows a map of person ability and item difficulty where both variables are plotted on the same
scale. IT-MAIS items 2 and 7 represent medium difficulty items because they were closest to 0 logit. Two
items with the same logit measure may be considered
redundant suggesting they measure the same level of
the latent trait (i.e. listening development). The
remaining IT-MAIS items measure the latent trait of
listening development at different item difficulty
levels. Rasch analysis dictates that if an assessment is
psychometrically ideal (Wright and Stone, 1999) the
item difficulty should reflect a range of 3-4 logits (typically ranging from -2 to +2 logits). The item difficulty range for the IT-MAIS was 1.5 logits, thus
less than ideal.
Comparing person mean (M = 0.8 logits) to item
mean (M = 0 logit) indicated that the match between
item difficulty and person ability was adequate
( person M  item M  1). Note, in Fig. 3, person
ability ranges from -6.0 to +3.6 logits - a wide
range of ability represented by a relatively small
sample. Thus, it can be concluded that the children
we evaluated were a representative sample of the population the IT-MAIS purports to assess children with
SNHL pre- and post-CI ages 0-3 years.
If 10% of the sample demonstrates either floor or
ceiling effects, it is an indication that the items do
not tap the full range of person ability levels. Based
on the 10% criteria, the parents' reports did not
demonstrate significant ceiling or floor effects (0%
ceiling effect; 8.9% floor effect).
Person reliability
Person reliability represents the way in which parents
with children of a given ability level respond to the

Barker et al.

Item-level psychometrics of the IT-MAIS

Table 2 Correlation coefficients between all 10 IT-MAIS items based on the factor model
Item #

1

2

3

4

5

6

7

8

9

10

1
2
3
4
5
6
7
8
9
10

1.000
.554
.439
.471
.522
.671
.364
.513
.412
.516

.554
1.000
.679
.712
.711
.729
.701
.730
.637
.627

.439
.679
1.000
.882
.833
.719
.736
.717
.745
.667

.471
.712
.882
1.000
.824
.702
.740
.736
.675
.742

.522
.711
.833
.824
1.000
.807
.788
.793
.791
.674

.671
.729
.719
.702
.807
1.000
.690
.726
.719
.627

.364
.701
.736
.740
.788
.690
1.000
.718
.704
.679

.513
.730
.717
.736
.793
.726
.718
1.000
.743
.625

.412
.637
.745
.675
.791
.719
.704
.743
1.000
.612

.516
.627
.667
.742
.674
.627
.679
.625
.612
1.000

test items. This means that a parent whose child
demonstrated high-level listening skills reliably
responded with the highest rating category (4/
always) when responding to items of low-level listening
skills. The criterion for acceptable person reliability
index is 0.80 (comparable to Cronbach's ). In the
present study, the person reliability index was 0.92,
which is `highly acceptable' according to Rasch
analysis.

Table 3 Local independence of inter-item residual
correlations for the 8 IT-MAIS items that demonstrated
acceptable infit criteria

IT-MAIS Item

Fisher's z
transformation

2. Does the child produce well-formed
syllables and syllable sequences that
are recognized as `speech'?

0.026

3. Does the child spontaneously respond
to his/her name in quiet with auditory
cues only (no visual cues)?

-0.120

4. Does the child spontaneously respond
to his/her name in the presence of
background noise with auditory cues
only (no visual cues)?

-0.092

5. Does the child spontaneously alert to
environmental sounds in the home
without being told or prompted to do
so?

-0.059

6. Does the child spontaneously alert to
environmental sounds in new
environments?

0.121

7. Does the child RECOGNIZE auditory
signals that are part of his/her
everyday routines?

-0.173

8. Does the child demonstrate the ability
to discriminate spontaneously
between two speakers with auditory
cues only (no visual cues)?

-0.034

9. Does the child spontaneously know
the difference between speech and
non-speech stimuli with listening
alone?

-0.117

Table 4 Item infit statistics based on the established infit
criteria for mean square (MnSq) and z-score for the eight ITMAIS items that demonstrated acceptable infit criteria

Item

Measure

Model
S.E.

2. Does the child produce
well-formed syllables and
syllable sequences that
are recognized as
`speech'?

0.49A

3. Does the child
spontaneously respond
to his/her name in quiet
with auditory cues only
(no visual cues)?

Infit
Mnsq

z

0.18

1.28

1.4

0.52A

0.18

1.29

1.5

4. Does the child
spontaneously respond
to his/her name in the
presence of background
noise with auditory cues
only (no visual cues)?

0.10A

0.19

1.43

2.1

5. Does the child
spontaneously alert to
environmental sounds in
the home without being
told or prompted to do
so?

-0.26A

0.19

1.09

0.5

6. Does the child
spontaneously alert to
environmental sounds in
new environments?

-0.45A

0.20

1.07

0.4

7. Does the child
RECOGNIZE auditory
signals that are part of
his/her everyday
routines?

0.34A

0.18

1.16

0.9

8. Does the child
demonstrate the ability to
discriminate
spontaneously between
two speakers with
auditory cues only (no
visual cues)?

-0.13A

0.19

1.02

0.2

9. Does the child
spontaneously know the
difference between
speech and non-speech
stimuli with listening
alone?

1.23A

0.24

0.98

0.0

Speech, Language and Hearing

2017

VOL.

20

NO.

3

137

Barker et al.

Item-level psychometrics of the IT-MAIS

Table 5 Listing of misfitting persons based on the
established criteria for infit mean square (MnSq) and and infit
z-score
Participant ID #

Infit MnSq

Infit z

CI21
CI13
CI18
CI16
CI18
CI7
CI14
CI12
CI9

3.68
3.30
2.87
3.16
3.02
2.87
2.50
2.45
1.93

3.1
2.8
2.9
2.6
3.4
3.0
2.1
2.8
2.0

Rating scale analysis
A sound rating scale must meet three requirements: (1)
each rating scale category must contain at least 10
observations; (2) measures must advance linearly
with each category; and (3) measures must have
outfit mean square <2 (Linacre, 2002). The ITMAIS' rating scale met all 3 of these criteria. The
analysis demonstrated that parents did not consistently
use all 5 categories of the IT-MAIS' 0-4 rating scale
(see Table 6).

Question 3: Does the IT-MAIS separate the
participating children into more than two levels
of ability to adequately identify different
functional levels of performance?
Person separation was 3.41 (>2), demonstrating that
the IT-MAIS separated person ability into at least 3
statistically different levels. That is, the analyses
revealed distinct differences in listening abilities
between children with profound SNHL pre-CI as compared to the children post-CI.

Question 4: Does the Rasch-modeled IT-MAIS
item difficulty hierarchy conform to the
theoretical item difficulty hierarchy established
a priori?
There was a statistically significant, strong, positive
correlation ( = .05) between the graduate students'
rankings and the modeled hierarchy [ (6) = .903,
p < .01], which differs from the IT-MAIS item order
(see Table 7).

Discussion
Globally, children are undergoing cochlear implantation at younger and younger ages (Colletti et al.,
2012). This decline in age and the challenges associated with accurately assessing the functional hearing
of infants raises concerns regarding the tools used to
evaluate CI candidacy and post-CI progress. The
present study focused on a popular (Uhler and
Gifford, 2014) parent-report tool developed with the
intention to serve as a cohesive measurement of preand post-CI functional listening development - the
138

Speech, Language and Hearing

2017

VOL.

20

NO.

3

Figure 3 Map of Person ability and Item difficulty. Logit scale
ranges from -6.0 to +3.6 for person ability and from -1.23 to
+0.52 for item difficulty. Person ability mean is represented by
the M to the left of the logit scale; item difficulty mean is
represented by the M to the right of the logit scale (at 0 logits).
Each X represents an individual child, S = 1 SD, T = 2 SD.

IT-MAIS (Zimmerman-Phillips et al., 2001). The
aim of this study was to further explore the psychometric properties of the IT-MAIS and provide
researchers and clinicians with additional information

Barker et al.

Item-level psychometrics of the IT-MAIS

Table 6 Summary of category rating scale utilization criteria based on Category Rating Utilization Analysis for the 5-categoy
rating scale for the eight IT-MAIS items that demonstrated acceptable infit criteria (with misfitting persons removed; *indicates
category rankings exceeding criteria for each item)

Item

2. Does the child produce well-formed syllables and
syllable sequences that are recognized as `speech'?

3. Does the child spontaneously respond to his/her name
in quiet with auditory cues only (no visual cues)?

4. Does the child spontaneously respond to his/her name in the
presence of background noise with auditory cues only (no visual cues)?

5. Does the child spontaneously alert to environmental sounds in
the home without being told or prompted to do so?

6. Does the child spontaneously alert to environmental
sounds in new environments?

7. Does the child RECOGNIZE auditory signals that
are part of his/her everyday routines?

8. Does the child demonstrate the ability to discriminate spontaneously
between two speakers with auditory cues only (no visual cues)?

9. Does the child spontaneously know the difference between
speech and non-speech stimuli with listening alone?

>10 Observations
per category

Average measures
advance linearly

Outfit
MnSq < 2

NO
0 = 13
*1 = 8
*2 = 8
3 = 16
4 = 11

YES
-2.49
-1.15
0.81
2.17
2.36

NO
*-3.26
1.72
*2.00
0.58
1.59

NO
0 = 14
*1 = 2
*2 = 5
3 = 14
4 = 21

YES
-3.72
-0.64
0.21
1.64
2.21

NO
*2.11
1.49
0.21
0.71
*2.64

NO
0 = 14
*1 = 8
*2 = 8
3 = 18
*4 = 8

YES
-3.72
0.04
1.35
1.99
2.79

YES
1.89
1.28
0.60
1.58
0.39

NO
*0 = 8
*1 = 5
*2 = 7
3 = 18
4 = 18

YES
-5.41
-3.90
-0.30
1.34
2.55

YES
0.39
0.75
0.76
0.62
0.46

NO
0 = 10
*1 = 5
2 = 11
3 = 23
*4 = 7

YES
-3.10
-2.51
0.28
1.76
3.05

NO
*4.23
0.98
0.97
1.33
0.27

NO
0 = 17
*1 = 3
*2 = 6
3 = 17
4 = 13

YES
-2.73
0.70
1.07
1.59
2.68

NO
*2.74
1.38
0.46
*2.46
0.94

NO
0 = 16
*1 = 6
*2 = 8
3 = 10
4 = 16

YES
-2.89
-0.41
1.47
2.18
2.38

NO
*2.65
0.49
0.33
1.10
1.25

NO
0 = 17
*1 = 4
*2 = 6
3 = 11
4 = 18

YES
-2.63
0.04
1.08
1.78
2.40

NO
*4.22
0.75
1.28
0.71
1.05

when making decisions about using the IT-MAIS in
their research and clinical practice. The implications
of our study's findings are discussed below according
to the analyses' results.

another (local independence). Our results indicated
that the IT-MAIS met these two critical assumptions,
thus the items represented a single factor and they were
locally independent.

IT-MAIS data met the assumptions for Rasch
analysis

IT-MAIS' item-level psychometric properties are
not ideal for measuring the latent trait of
listening development

We posed our first question to ensure that the data set
met two critical assumptions important to studying a
latent trait: that the items represented a unidimensional trait and that items were independent of one

Content validity
We used Rasch analysis to analyze the item-level psychometric properties of the IT-MAIS because the

Speech, Language and Hearing

2017

VOL.

20

NO.

3

139

Barker et al.

Item-level psychometrics of the IT-MAIS

Table 7 Item order based on a priori rankings from 4 MAlevel speech-language pathology students for the 8 IT-MAIS
items that demonstrated acceptable infit criteria
Item
*5. Does the child spontaneously alert to environmental sounds
in the home without being told or prompted to do so?
6. Does the child spontaneously alert to environmental sounds
in new environments?
3. Does the child spontaneously respond to his/her name in
quiet with auditory cues only (no visual cues)?
9. Does the child spontaneously know the difference between
speech and non-speech stimuli with listening alone?
8. Does the child demonstrate the ability to discriminate
spontaneously between two speakers with auditory cues only
(no visual cues)?
7. Does the child RECOGNIZE auditory signals that are part of
his/her everyday routines?
+
4. Does the child spontaneously respond to his/her name in
the presence of background noise with auditory cues only
(no visual cues)?
2. Does the child produce well-formed syllables and syllable
sequences that are recognized as `speech'?
Note: * = item was ranked in the same position in both our a
priori ranking and via Rasch item difficulty measures;  = item
was ranked 1 rank position; and + = item was ranked +3 rank
positions in a priori hierarchy than in item difficulty order
determined by Rasch analysis.

analysis' results provide information similar to the traditional benchmarks of validity and reliability. Two of
10 IT-MAIS items (20%) were discarded from the final
analysis because they did not meet the infit criteria. As
a result, content validity was brought into question.
Misfitting items may indicate that a question is
poorly worded or that it is not relevant to the listening
development construct at all. For example, a parent's
response to misfitting item 1 [Is the child's vocal behavior affected while wearing his/her sensory aid...?] is
dependent on the young child's age at evaluation and
their degree of hearing loss. Very young children are
likely to vocalize in a manner similar to their
normal-hearing peers up until  9 months of age
(Oller and Eilers, 1988). Furthermore, a young child
with residual hearing that affords them essential audibility of the speech signal is likely to vocalize in a
manner similar to their peers with normal hearing,
with or without their listening devices (BassRingdahl, 2010). This potential variability noted
across the vocalizations of young children with
SNHL is apt to contribute to the item's weak
content validity and subsequent misfit.
Rasch analyses also revealed a number of parents
who did not respond to questions reliably, based on
person ability; specifically, nine out of 56 data points
exceeded misfit criteria. Excessive person misfit may
indicate that the questions are not applicable to what
the parents experience with their children, or that
audiologists administered the IT-MAIS in ways that
did not lead to consistent responses (e.g. used different
probes, did not probe sufficiently).

140

Speech, Language and Hearing

2017

VOL.

20

NO.

3

Person ability and item difficulty
Our analysis of person ability - in comparison with
item difficulty - also raised concerns regarding the validity of the IT-MAIS. Eleven out of 12 parents
assigned their children, pre-CI, overall scores 3.4
This marginal floor effect indicated that the items on
the IT-MAIS did not assess these children's pre-CI listening abilities. Rather, these very low scores indicated
that the children never displayed the behaviors
addressed by the items (according to parent report).
These results are not surprising given that the majority
of our participating children were diagnosed at birth
with severe-profound SNHL. The results have important implications for the future use of the IT-MAIS
with young CI candidates who have greater residual
hearing.
Prior to cochlear implantation, children are currently predicted to achieve scores of 0/never on most
of the IT-MAIS items because children with profound
SNHL have very limited listening skills. However,
there is a growing trend to implant children with
more residual hearing, thus exceeding the U. S. Food
and Drug Administration's current guidelines of bilateral pure-tone averages of 90 dB HL (e.g. moderatesevere SNHL). This research suggests that young
children with residual hearing (and greater audibility
of the speech signal) prior to implantation would
score very differently on the IT-MAIS than the children in our current study (e.g. Gantz et al., 2000).
The minimal range of sounds detectable to children
with SNHL prior to CI receipt brings into question
the use of the IT-MAIS as a measure for CI candidacy.
Specifically, how many items can a child achieve a
score greater than 0/never and still be considered
a candidate for CI surgery? Choosing CI surgery for
a child is an important decision with irreversible
effects that eliminate any residual hearing present
before surgery and limit the child's chance to utilize
future technology and/or medical advancements
(e.g. hair cell regeneration). The current analysis of
person ability in comparison with item difficulty
suggests that the current version of the IT-MAIS
does not demonstrate strong validity, and therefore,
should not be used by itself to determine CI candidacy
until the issues of validity are resolved.
Rating scale analysis
Our analysis indicated that the parents did not maximally use the IT-MAIS' 0-4 Likert scale when rating
their children's listening behaviors. Rating scales are
employed to attain information about a participant's
degree of skill rather than a basic yes/no or right/
wrong distinction (Linacre, 2002). If categories on a
rating scale are not well defined and mutually
Overall pre-CI IT-MAIS scores for our sample were as follows: 0 (n = 5), 1
(n = 2), 2 (n = 1), and 3 (n = 3), out of a possible overall score of 40.

4

Barker et al.

exclusive, the reliability of the assessment is negatively
affected (Linacre). The parents' irregular use of rating
scale categories indicates that the categories are not
properly calibrated in a step-wise manner (i.e. infrequent use of a score of 2 in the present study relative
to the frequency of use for the other 4 scores
(Linacre)). This finding is clinically relevant because
parents' ratings are used to evaluate their children's listening skills (as opposed to a professional directly eliciting behavioral responses from a child).
One solution for improving the caregivers' use of the
IT-MAIS' rating scale categories would be to alter the
rating scale (e.g. reducing it to 4, instead of 5, categories) which would echo the parents' rating behaviors in the current study. However, because we did
not obtain 10 responses per ranking category for
each item altering the rating scale is ill advised at
this point in time (Chen et al., 2014; Linacre, 2002).
A larger sample size (N  100) would increase the likelihood of obtaining the needed number of observations
per rating category (n = 10) to determine whether the
rating scale met the established criteria.

IT-MAIS adequately identified different
functional levels of listening development
Reliability
Our results indicated that, the 8 IT-MAIS items used
in the Rasch analysis were able to capture >2 levels
of person ability (3.41 levels) and represent a relative
strength of the IT-MAIS. It is critical that a measure
demonstrate sufficient person separation to track progress in skill development. Based on the 3.41 person
separation index we propose that the IT-MAIS may
be a viable starting point for the creation of a new
assessment used to track listening development in children with SNHL. Specifically, researchers could utilize
the participant separation demonstrated by the ITMAIS as a guide for constructing new assessment
items that address the full range of person ability.

IT-MAIS item order inconsistent with item order
based on Rasch difficulty measures
Further validation based on theoretical foundation
Recall that it is critical in the field of objective
measurement that the construct one is measuring has
a strong theoretical foundation. It is also important
that the assessment's questions be designed to cover
a full range of ability - from most basic behavior to
most complex - to alleviate Type 1 and Type 2
errors. In the case of the IT-MAIS, item difficulty analyses indicated the order of IT-MAIS items was inconsistent with item order based on Rasch difficulty
measures. These data suggested the current iteration
of the IT-MAIS should not be viewed as a hierarchical
progression of listening development. Thus it may not
be the most ideal instrument upon which to determine

Item-level psychometrics of the IT-MAIS

functional listening development or establish optimal
listening intervention in children with hearing loss.
Until we have more definitive results, using another
assessment, perhaps alongside the IT-MAIS might
be the wisest course of action. For example, Bagatto
and Scollie (2013) suggested to initially use the
LittlEARS Auditory Questionnaire (Coninx et al.,
2003), an assessment designed to track listening development in CI users who were implanted by 24 months
of age. Once the child reaches ceiling on the
LittlEARS they would switch to the Parents'
Evaluation of Aural/Oral Performance of Children
(PEACH; Ching and Hill 2005), a parent-report tool
designed to assess listening and communication skills
in children using hearing aids and/or CIs. Although
neither of these parent-report tools has undergone rigorous psychometric analysis, unlike the IT-MAIS a
bevy of research is emerging that supports their
strengths across a variety of validity and reliability
measures (Bagatto et al., 2011).
Alternatively, the item hierarchy we established a
priori in accordance with Erber's work (1982) had a
strong, positive relationship with the Rasch item
order. This follow-up analysis suggested that if one
were to reorder the current IT-MAIS' questions, to
reflect a developmental listening hierarchy - like that
proposed by Erber - it would likely strengthen and
broaden the assessment's usefulness. Subsequently,
making it possible not only to quantify listening development in CI users but also to account for individual
differences across users and customize their device
management and listening intervention. This finding
adds a wrinkle to the discussion about using Rasch
analysis for small sample sizes. Chen et al. (2014)
reported that larger sample sizes (100 or 250) demonstrated more stable item parameters than smaller
sample sizes (30 or 50). In fact, they reported that
item parameters painted nearly opposite pictures of
the item hierarchy. Our analysis appeared to confirm
that the item hierarchy we established in this Rasch
analysis was valid. The sample size controversy in
Rasch analysis is not new and will continue.
However, when dealing with low incidence populations, Rasch analysis may still provide valuable
information, as it appears to have done within the
present study.

Future directions
While our intent was to stimulate discussions about the
IT-MAIS, we recognize that our results could be
unsettling - particularly to pediatric CI professionals
like those of Uhler and Gifford's (2014) aforementioned study and champions of the assessment. A
change in implementation of care (or even sometimes
the suggestion of change) is a challenge for any clinical
practitioners (Cook and Odon, 2013). However, it is

Speech, Language and Hearing

2017

VOL.

20

NO.

3

141

Barker et al.

Item-level psychometrics of the IT-MAIS

our duty as researchers and clinicians alike to adhere
to the conscientious use of current best evidence in
making decisions about patient care (Dollaghan,
2007).
We can foresee possible future directions to better
understand the psychometric properties of the ITMAIS and subsequently improve the outcome
measures that are available for young children with
hearing loss. We suggest three possible paths. First,
researchers could consider revising the IT-MAIS
with two main goals: (1) develop new items and
reword the existing items to assess an appropriate
range of listening skills in pre- and post-CI users and
(2) establish a new item difficulty hierarchy to reflect
functional listening development.
Second, researchers could focus on exploring listening skills to establish a globally accepted operational
definition for listening development while conducting
more theoretically motivated research to move the
field closer to a comprehensive model of listening
and spoken language processing - for all types of listeners. Specifically, we propose including the role of
cognitive and communication skills in the definition
and understanding of listening development. This unification of cognition and listening is important given
that listening is a complex, cognitive task that is still
not fully understood (e.g. Jerger et al., 2013;
Pichora-Fuller and Singh, 2006). Furthermore, children with SNHL (and no additional disabilities) are
likely to continue developing cognitively ( pre-CI)
prior to developing most listening skills. In contrast,
children with normal hearing concurrently develop
cognitive, language, and listening skills.
Third, we would like to re-analyze the IT-MAIS
using a larger sample size (100), in addition to analyzing the item-level psychometric properties of other
assessments in pediatric CI programs' test batteries
(e.g. the LittlEARS Auditory Questionnaire and the
PEACH). Understanding more about these tools
might allow us to develop an optimal comprehensive
battery of assessments for tracking listening development pre- to post-CI.

Conclusions
In this study, we analyzed the item-level psychometric
properties of the IT-MAIS via Rasch analysis to gain
further understanding about its validity and reliability.
We chose to analyze the psychometric properties of the
IT-MAIS because very little information exists regarding its development and validation, although it is
widely used to assess listening skills in children with
SNHL ages 0-3 years pre- and post-CI. The results
indicated that the IT-MAIS items demonstrated less
than ideal psychometric properties and the IT-MAIS
item order did not reflect the order in which children
are expected to develop functional listening skills.

142

Speech, Language and Hearing

2017

VOL.

20

NO.

3

Our findings suggest that there is a pressing need for
further discussion among researchers and clinicians
about (1) how the IT-MAIS is used, and (2) what
other valid and reliable assessments could be used
alongside or in place of the IT-MAIS to determine
CI candidacy, establish treatment goals, or track progress in listening development in very young children
with hearing loss.

Disclaimer statements
Contributors None.
Funding This work was partially funded by the
National Institutes on Deafness and Other
Communication Disorders, National Institutes of
Health [2 P50 DC00242], in addition to a grant from
the General Clinical Research Centers Program,
NCRR, National Institutes of Health [RR00059]--
both awarded to the University of Iowa's Cochlear
Implant Program.
Conflict of interest None.
Ethics approval None.

Acknowledgements
The authors extend a big thank you to our colleagues
on the University of Iowa's Cochlear Implant Program
and all the families who volunteered their time for this
study. Portions of this work were presented under
the title, `An examination of the validity and reliability
of the Infant-Toddler Meaningful Auditory Integration
Scales' at The Hearing Across the Lifespan (HEAL)
Conference, Cernobbio, Lake Como, Italy in June
2014; at the American Auditory Society Annual
Meeting held in Scottsdale, AZ in March 2013; and
at the American Cochlear Implant Alliance's 2013
Symposium held in Washington, D.C. in October
2013.

ORCID
Brittan A. Barker
http://orcid.org/0000-00019327-7057
Neila J. Donovan http://orcid.org/0000-0002-72358357

References
An, X., Yung, Y.-F. 2014. Item response theory: what it is and how
you can use the IRT procedure to apply it. Paper SAS364-2014.
Cary, NC: SAS Institute Inc.
Bagatto, M.P., Moodie, S.T., Seewald, R.C., Bartlett, D.J., Scollie,
S.D. 2011. A critical review of audiological outcome measures
for infants and children. Trends in Amplification, 15: 23-33.
Bagatto, M.P., Scollie, S.D. 2013. Validation of the parents' evaluation of aural/oral performance of children (PEACH) rating
scale. Journal of the American Academy of Audiology, 24:
121-125.
Baker, F.B. 1985. The basics of item response theory. Portsmouth,
N.H: Heinemann.
Barker, B.A., Kenworthy, M.H., Walker, E.A. 2011. How we do it:
employment of listening-development criteria during assessment of infants who use cochlear implants. Cochlear Implants
International, 12: 57-59.

Barker et al.

Bass-Ringdahl, S.M. 2010. The relationship of audibility and the
development of canonical babbling in young children with
hearing impairment. Journal of Deaf Studies and Deaf
Education, 15(3): 287-310.
Baylor, C., Hula, W., Donovan, N.J., Doyle, P.J., Kendall, D.,
Yorkston, K. 2011 . An introduction to item response theory
and Rasch models for speech-language pathologists. American
Journal of Speech-Language Pathology, 20: 243-259.
Cardon, G., Sharma, A. 2013. Central auditory maturation and behavioral outcome in children with auditory neuropathy spectrum disorder who use cochlear implants. International
Journal of Audiology, 52: 577-586.
Chen, W.H., Lenderking, W., Jin, Y., Wyrwich, K.W., Gelhorn, H.,
Revicki, D.A. 2014. Is Rasch model analysis applicable in small
sample size pilot studies for assessing item characteristics? An
example using PROMIS pain behavior item bank data.
Quality of Life Research, 23: 485-493.
Ching, T.Y.C., Hill, M. 2005. The parents' evaluation of aural/oral
performance of children (PEACH) rating scale. Chatswood,
New South Wales: Australian Hearing.
Colletti, L., Mandala, M., Colletti, V. 2012. Cochlear implants in
children younger than 6 months. Otolaryngology - Head and
Neck Surgery, 147: 139-146.
Coninx, F., Weichbold, V., Tsiakpini, L. 2003. LittlEARS auditory
questionnaire. Innsbruck: MED-EL.
Cook, B.G., Odon, S.L. 2013. Evidence-based practices and
implementation science in special education. Exceptional
Children, 79: 135-144.
Dollaghan, C.A. 2007. The handbook for evidence-based practice in
communication disorders. Baltimore, MD: Brooks Publishing Co.
Engelhard, G. 2013. Invariant measurement: using Rasch models in the
social, behavioral, and health sciences. New York: Routledge.
Erber, N. 1982. Auditory training. Washington, DC: Alexander
Graham Bell Association.
Ertmer, D.J., Jung, J. 2012. Monitoring progress in vocal development in young cochlear implant recipients: relationships
between speech samples and scores from the Conditioned
Assessment of Speech Production (CASP). American Journal
of Speech-Language Pathology, 21: 313-328.
Field, A.P. 2009. Discovering statistics using SPSS. London: SAGE
Publications.
Gantz, B.J., Rubinstein, J.T., Tyler, R.S., Teagle, H.F., Cohen, N.L.,
Waltzman, S.B., et al. 2000. Long-term results of cochlear
implants in children with residual hearing. Annals of
Otolaryngology, Rhinology, and Laryngology-Supplement, 185:
33-36.
IBM Corp. Released. 2013. IBM SPSS Statistics for Windows,
Version 22.0. Armonk, NY: IBM Corp.
Jerger, S., Damian, M.F., Mills, C., Bartlett, J., Tye-Murray, N.,
Abdi, H. 2013. Effect of perceptual load on semantic access
by speech in children. Journal of Speech Language and
Hearing Research, 56: 388-403.
Kishon-Rabin, L., Taitelbaum, R., Elichai, O., Maimon, D.,
Debyiat, D., Chazan, N. et al. 2001. Developmental aspects

Item-level psychometrics of the IT-MAIS

of the IT-MAIS in normal-hearing babies. Israeli Journal of
Speech and Hearing, 23: 12-22.
Linacre, J.M. 1994. Sample size and item calibration stability. Rasch
Measurement Transactions, 7: 328.
Linacre, J.M. 2002. Optimizing rating scale category effectiveness.
Journal of Applied Measurement, 3: 85-106.
Linacre, J.M. 2010. Winsteps(R) (Version 7.5) [Computer Software].
Beaverton, Oregon: Winsteps.com. Available from http
://www.winsteps.com/
Lord, F.M., Novick, M.R. 1968. Statistical theories of mental test
scores. Reading, MA: Addison-Wesley.
Mallinson, T. 2011. Rasch analysis of repeated measures. Rasch
Measurement Transactions, 25: 1317.
Ng, I.H.Y., Lee, K.Y.S., Lam, J.H.S., van Hasselt, C.A., Tong,
M.C.F. 2016. An application of item response theory and the
Rasch model in speech recognition test materials. American
Journal of Audiology, 25: 142-152.
Oller, D.K., Eilers, R.E. 1988. The role of audition in infant babbling. Child Development, 59: 441-449.
Pichora-Fuller, M.K., Singh, G. 2006. Effects of age on auditory
and cognitive processing: implications for hearing aid fitting
and audiologic rehabilitation. Trends in Amplification, 10:
29-59.
Rasch, G. 1960/1980. Probabilistic models for some intelligence and
attainment tests. Chicago: University of Chicago Press.
Robbins, A.M., Renshaw, J.J., Berry, S.W. 1991. Evaluating meaningful auditory integration in profoundly hearing-impaired children. The American Journal of Otology, 12: 144-150.
Smith, E.V. 2005. Effect of item redundancy on rasch item and
person estimates. Journal of Applied Measurement, 6: 147-163.
Uhler, K., Gifford, R.H. 2014. Current trends in pediatric cochlear
implant candidate selection and postoperative follow-up.
American Journal of Audiology, 23: 309-325.
Wright, B.D. 1999. Fundamental measurement for psychology. In:
Embretson, SE, Hershberger, SL (eds.) The new rules of
measurement: what every psychologist and educator should
know. Mahway, NJ: Erlbaum, p. 65-104.
Wright, B.D., Linacre, J.M. 1989. Observations are always ordinal;
measurements, however, must be interval. Archives of Physical
Medicine and Rehabilitation, 70: 857-860.
Wright, B.D., Linacre, J.M. 1994. Reasonable item mean-square fit
value. Rasch Measurement Transactions, 8: 370.
Wright, B.D., Stone, M.H. 1999. Measurement essentials. 2nd ed.
Wilmington: Wide Range, Inc.
Zheng, Y., Soli, S.D., Wang, K., Meng, J., Meng, Z., Xu, K. 2009. A
normative study of early prelingual auditory development.
Audiology and Neurotology, 14: 214-222.
Zimmerman-Phillips, S., Osberger, M.J., Robbins, A.M. 2001.
Infant-toddler meaningful auditory integration scale. Sylmar,
CA: Advanced Bionics Corporation.
Zimmerman-Phillips, S., Robbins, A.M., Osberger, M.J. 2000.
Assessing cochlear implant benefit in very young children.
Annals of Otology, Rhinology, and Laryngology - Supplement,
185: 42-43.

Speech, Language and Hearing

2017

VOL.

20

NO.

3

143

